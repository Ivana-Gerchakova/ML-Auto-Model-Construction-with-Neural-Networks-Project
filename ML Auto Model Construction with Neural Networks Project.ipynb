{"cells":[{"cell_type":"markdown","id":"74100f47","metadata":{"id":"74100f47"},"source":["### HOMEWORK 5"]},{"cell_type":"markdown","id":"823fed75","metadata":{"id":"823fed75"},"source":["### WARNINGS :"]},{"cell_type":"code","execution_count":null,"id":"000323f4","metadata":{"id":"000323f4"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"3cd4b835","metadata":{"id":"3cd4b835"},"source":["### LIBRARIES :"]},{"cell_type":"code","execution_count":null,"id":"ac892a7b","metadata":{"id":"ac892a7b"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","import random\n","from keras.callbacks import EarlyStopping\n","from keras.models import Sequential\n","from keras.layers import Dense, Input\n","from tensorflow.keras import layers\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OrdinalEncoder\n","import time\n","from bayes_opt import BayesianOptimization, UtilityFunction\n","import random\n","from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn import preprocessing\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import linear_model\n","from sklearn.metrics import accuracy_score\n","from sklearn.svm import LinearSVR\n","from sklearn.svm import SVR\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.datasets import load_digits\n","from hyperopt import hp, fmin, tpe, Trials\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","from tpot import TPOTClassifier\n","from geneticalgorithm import geneticalgorithm as ga\n","from sklearn_genetic import GASearchCV\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn_genetic.space import Categorical, Integer, Continuous\n","from hyperopt import hp\n","from hyperopt.mongoexp import MongoTrials\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from timeit import default_timer as timer\n","from datetime import timedelta\n","import time\n","import pickle\n","from bayes_opt import BayesianOptimization, UtilityFunction\n","import os\n","from sklearn.neural_network import MLPRegressor\n","from keras.layers import Dense, Dropout"]},{"cell_type":"markdown","id":"3e70c085","metadata":{"id":"3e70c085"},"source":["### READ THE DATASET :"]},{"cell_type":"code","execution_count":null,"id":"c2001380","metadata":{"id":"c2001380","outputId":"cb860988-6452-4b57-a40c-2eb749582aed"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>dteday</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.81</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.2727</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>5</td>\n","      <td>27</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.2879</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   instant    dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n","0        1  1/1/2011       1   0     1   0        0        6           0   \n","1        2  1/1/2011       1   0     1   1        0        6           0   \n","2        3  1/1/2011       1   0     1   2        0        6           0   \n","3        4  1/1/2011       1   0     1   3        0        6           0   \n","4        5  1/1/2011       1   0     1   4        0        6           0   \n","\n","   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n","0           1  0.24  0.2879  0.81        0.0       3          13   16  \n","1           1  0.22  0.2727  0.80        0.0       8          32   40  \n","2           1  0.22  0.2727  0.80        0.0       5          27   32  \n","3           1  0.24  0.2879  0.75        0.0       3          10   13  \n","4           1  0.24  0.2879  0.75        0.0       0           1    1  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('hour.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"fe2a7d03","metadata":{"id":"fe2a7d03","outputId":"5632b0dc-b455-47de-95de-47240e9d77ea"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>dteday</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>17374</th>\n","      <td>17375</td>\n","      <td>12/31/2012</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.26</td>\n","      <td>0.2576</td>\n","      <td>0.60</td>\n","      <td>0.1642</td>\n","      <td>11</td>\n","      <td>108</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>17375</th>\n","      <td>17376</td>\n","      <td>12/31/2012</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.26</td>\n","      <td>0.2576</td>\n","      <td>0.60</td>\n","      <td>0.1642</td>\n","      <td>8</td>\n","      <td>81</td>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>17376</th>\n","      <td>17377</td>\n","      <td>12/31/2012</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.26</td>\n","      <td>0.2576</td>\n","      <td>0.60</td>\n","      <td>0.1642</td>\n","      <td>7</td>\n","      <td>83</td>\n","      <td>90</td>\n","    </tr>\n","    <tr>\n","      <th>17377</th>\n","      <td>17378</td>\n","      <td>12/31/2012</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.26</td>\n","      <td>0.2727</td>\n","      <td>0.56</td>\n","      <td>0.1343</td>\n","      <td>13</td>\n","      <td>48</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>17378</th>\n","      <td>17379</td>\n","      <td>12/31/2012</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>23</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.26</td>\n","      <td>0.2727</td>\n","      <td>0.65</td>\n","      <td>0.1343</td>\n","      <td>12</td>\n","      <td>37</td>\n","      <td>49</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n","17374    17375  12/31/2012       1   1    12  19        0        1   \n","17375    17376  12/31/2012       1   1    12  20        0        1   \n","17376    17377  12/31/2012       1   1    12  21        0        1   \n","17377    17378  12/31/2012       1   1    12  22        0        1   \n","17378    17379  12/31/2012       1   1    12  23        0        1   \n","\n","       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n","17374           1           2  0.26  0.2576  0.60     0.1642      11   \n","17375           1           2  0.26  0.2576  0.60     0.1642       8   \n","17376           1           1  0.26  0.2576  0.60     0.1642       7   \n","17377           1           1  0.26  0.2727  0.56     0.1343      13   \n","17378           1           1  0.26  0.2727  0.65     0.1343      12   \n","\n","       registered  cnt  \n","17374         108  119  \n","17375          81   89  \n","17376          83   90  \n","17377          48   61  \n","17378          37   49  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.tail()"]},{"cell_type":"markdown","id":"bc5f457d","metadata":{"id":"bc5f457d"},"source":["### EDA ON DATASET :"]},{"cell_type":"code","execution_count":null,"id":"3545504f","metadata":{"id":"3545504f","outputId":"1868aee7-0b29-4726-f7fa-82f535bac833"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 17379 entries, 0 to 17378\n","Data columns (total 17 columns):\n"," #   Column      Non-Null Count  Dtype  \n","---  ------      --------------  -----  \n"," 0   instant     17379 non-null  int64  \n"," 1   dteday      17379 non-null  object \n"," 2   season      17379 non-null  int64  \n"," 3   yr          17379 non-null  int64  \n"," 4   mnth        17379 non-null  int64  \n"," 5   hr          17379 non-null  int64  \n"," 6   holiday     17379 non-null  int64  \n"," 7   weekday     17379 non-null  int64  \n"," 8   workingday  17379 non-null  int64  \n"," 9   weathersit  17379 non-null  int64  \n"," 10  temp        17379 non-null  float64\n"," 11  atemp       17379 non-null  float64\n"," 12  hum         17379 non-null  float64\n"," 13  windspeed   17379 non-null  float64\n"," 14  casual      17379 non-null  int64  \n"," 15  registered  17379 non-null  int64  \n"," 16  cnt         17379 non-null  int64  \n","dtypes: float64(4), int64(12), object(1)\n","memory usage: 2.3+ MB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"id":"16b589f4","metadata":{"id":"16b589f4","outputId":"41c37277-8897-4191-add9-3eac17bb5fa2"},"outputs":[{"data":{"text/plain":["instant       0\n","dteday        0\n","season        0\n","yr            0\n","mnth          0\n","hr            0\n","holiday       0\n","weekday       0\n","workingday    0\n","weathersit    0\n","temp          0\n","atemp         0\n","hum           0\n","windspeed     0\n","casual        0\n","registered    0\n","cnt           0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"id":"63acdfc1","metadata":{"id":"63acdfc1","outputId":"319cc450-ab6d-46e8-b0e9-d3463f817562"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"id":"b2d76235","metadata":{"id":"b2d76235","outputId":"e48a7ca6-1e29-460b-b585-6e415f230139"},"outputs":[{"data":{"text/plain":["(17379, 17)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"id":"1d0fe0a9","metadata":{"id":"1d0fe0a9","outputId":"011bb744-5cc1-4b82-e111-8e7132f149dc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>min</th>\n","      <th>25%</th>\n","      <th>50%</th>\n","      <th>75%</th>\n","      <th>max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>instant</th>\n","      <td>17379.0</td>\n","      <td>8690.000000</td>\n","      <td>5017.029500</td>\n","      <td>1.00</td>\n","      <td>4345.5000</td>\n","      <td>8690.0000</td>\n","      <td>13034.5000</td>\n","      <td>17379.0000</td>\n","    </tr>\n","    <tr>\n","      <th>season</th>\n","      <td>17379.0</td>\n","      <td>2.501640</td>\n","      <td>1.106918</td>\n","      <td>1.00</td>\n","      <td>2.0000</td>\n","      <td>3.0000</td>\n","      <td>3.0000</td>\n","      <td>4.0000</td>\n","    </tr>\n","    <tr>\n","      <th>yr</th>\n","      <td>17379.0</td>\n","      <td>0.502561</td>\n","      <td>0.500008</td>\n","      <td>0.00</td>\n","      <td>0.0000</td>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>mnth</th>\n","      <td>17379.0</td>\n","      <td>6.537775</td>\n","      <td>3.438776</td>\n","      <td>1.00</td>\n","      <td>4.0000</td>\n","      <td>7.0000</td>\n","      <td>10.0000</td>\n","      <td>12.0000</td>\n","    </tr>\n","    <tr>\n","      <th>hr</th>\n","      <td>17379.0</td>\n","      <td>11.546752</td>\n","      <td>6.914405</td>\n","      <td>0.00</td>\n","      <td>6.0000</td>\n","      <td>12.0000</td>\n","      <td>18.0000</td>\n","      <td>23.0000</td>\n","    </tr>\n","    <tr>\n","      <th>holiday</th>\n","      <td>17379.0</td>\n","      <td>0.028770</td>\n","      <td>0.167165</td>\n","      <td>0.00</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weekday</th>\n","      <td>17379.0</td>\n","      <td>3.003683</td>\n","      <td>2.005771</td>\n","      <td>0.00</td>\n","      <td>1.0000</td>\n","      <td>3.0000</td>\n","      <td>5.0000</td>\n","      <td>6.0000</td>\n","    </tr>\n","    <tr>\n","      <th>workingday</th>\n","      <td>17379.0</td>\n","      <td>0.682721</td>\n","      <td>0.465431</td>\n","      <td>0.00</td>\n","      <td>0.0000</td>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weathersit</th>\n","      <td>17379.0</td>\n","      <td>1.425283</td>\n","      <td>0.639357</td>\n","      <td>1.00</td>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","      <td>2.0000</td>\n","      <td>4.0000</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>17379.0</td>\n","      <td>0.496987</td>\n","      <td>0.192556</td>\n","      <td>0.02</td>\n","      <td>0.3400</td>\n","      <td>0.5000</td>\n","      <td>0.6600</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>atemp</th>\n","      <td>17379.0</td>\n","      <td>0.475775</td>\n","      <td>0.171850</td>\n","      <td>0.00</td>\n","      <td>0.3333</td>\n","      <td>0.4848</td>\n","      <td>0.6212</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>hum</th>\n","      <td>17379.0</td>\n","      <td>0.627229</td>\n","      <td>0.192930</td>\n","      <td>0.00</td>\n","      <td>0.4800</td>\n","      <td>0.6300</td>\n","      <td>0.7800</td>\n","      <td>1.0000</td>\n","    </tr>\n","    <tr>\n","      <th>windspeed</th>\n","      <td>17379.0</td>\n","      <td>0.190098</td>\n","      <td>0.122340</td>\n","      <td>0.00</td>\n","      <td>0.1045</td>\n","      <td>0.1940</td>\n","      <td>0.2537</td>\n","      <td>0.8507</td>\n","    </tr>\n","    <tr>\n","      <th>casual</th>\n","      <td>17379.0</td>\n","      <td>35.676218</td>\n","      <td>49.305030</td>\n","      <td>0.00</td>\n","      <td>4.0000</td>\n","      <td>17.0000</td>\n","      <td>48.0000</td>\n","      <td>367.0000</td>\n","    </tr>\n","    <tr>\n","      <th>registered</th>\n","      <td>17379.0</td>\n","      <td>153.786869</td>\n","      <td>151.357286</td>\n","      <td>0.00</td>\n","      <td>34.0000</td>\n","      <td>115.0000</td>\n","      <td>220.0000</td>\n","      <td>886.0000</td>\n","    </tr>\n","    <tr>\n","      <th>cnt</th>\n","      <td>17379.0</td>\n","      <td>189.463088</td>\n","      <td>181.387599</td>\n","      <td>1.00</td>\n","      <td>40.0000</td>\n","      <td>142.0000</td>\n","      <td>281.0000</td>\n","      <td>977.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              count         mean          std   min        25%        50%  \\\n","instant     17379.0  8690.000000  5017.029500  1.00  4345.5000  8690.0000   \n","season      17379.0     2.501640     1.106918  1.00     2.0000     3.0000   \n","yr          17379.0     0.502561     0.500008  0.00     0.0000     1.0000   \n","mnth        17379.0     6.537775     3.438776  1.00     4.0000     7.0000   \n","hr          17379.0    11.546752     6.914405  0.00     6.0000    12.0000   \n","holiday     17379.0     0.028770     0.167165  0.00     0.0000     0.0000   \n","weekday     17379.0     3.003683     2.005771  0.00     1.0000     3.0000   \n","workingday  17379.0     0.682721     0.465431  0.00     0.0000     1.0000   \n","weathersit  17379.0     1.425283     0.639357  1.00     1.0000     1.0000   \n","temp        17379.0     0.496987     0.192556  0.02     0.3400     0.5000   \n","atemp       17379.0     0.475775     0.171850  0.00     0.3333     0.4848   \n","hum         17379.0     0.627229     0.192930  0.00     0.4800     0.6300   \n","windspeed   17379.0     0.190098     0.122340  0.00     0.1045     0.1940   \n","casual      17379.0    35.676218    49.305030  0.00     4.0000    17.0000   \n","registered  17379.0   153.786869   151.357286  0.00    34.0000   115.0000   \n","cnt         17379.0   189.463088   181.387599  1.00    40.0000   142.0000   \n","\n","                   75%         max  \n","instant     13034.5000  17379.0000  \n","season          3.0000      4.0000  \n","yr              1.0000      1.0000  \n","mnth           10.0000     12.0000  \n","hr             18.0000     23.0000  \n","holiday         0.0000      1.0000  \n","weekday         5.0000      6.0000  \n","workingday      1.0000      1.0000  \n","weathersit      2.0000      4.0000  \n","temp            0.6600      1.0000  \n","atemp           0.6212      1.0000  \n","hum             0.7800      1.0000  \n","windspeed       0.2537      0.8507  \n","casual         48.0000    367.0000  \n","registered    220.0000    886.0000  \n","cnt           281.0000    977.0000  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.describe().T"]},{"cell_type":"code","execution_count":null,"id":"7daf7f21","metadata":{"id":"7daf7f21","outputId":"ab20cfc5-efae-4228-e62f-d0442308815b"},"outputs":[{"data":{"text/plain":["instant       17379\n","dteday          731\n","season            4\n","yr                2\n","mnth             12\n","hr               24\n","holiday           2\n","weekday           7\n","workingday        2\n","weathersit        4\n","temp             50\n","atemp            65\n","hum              89\n","windspeed        30\n","casual          322\n","registered      776\n","cnt             869\n","dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.nunique()"]},{"cell_type":"code","execution_count":null,"id":"6fdc3f94","metadata":{"id":"6fdc3f94","outputId":"fb33f366-5194-452e-b402-8ac155d31796"},"outputs":[{"data":{"text/plain":["instant         int64\n","dteday         object\n","season          int64\n","yr              int64\n","mnth            int64\n","hr              int64\n","holiday         int64\n","weekday         int64\n","workingday      int64\n","weathersit      int64\n","temp          float64\n","atemp         float64\n","hum           float64\n","windspeed     float64\n","casual          int64\n","registered      int64\n","cnt             int64\n","dtype: object"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"code","execution_count":null,"id":"da5e5878","metadata":{"id":"da5e5878","outputId":"8438dc54-809e-495d-b7dc-2a0dc4f68a46"},"outputs":[{"data":{"text/plain":["instant       5017.029500\n","season           1.106918\n","yr               0.500008\n","mnth             3.438776\n","hr               6.914405\n","holiday          0.167165\n","weekday          2.005771\n","workingday       0.465431\n","weathersit       0.639357\n","temp             0.192556\n","atemp            0.171850\n","hum              0.192930\n","windspeed        0.122340\n","casual          49.305030\n","registered     151.357286\n","cnt            181.387599\n","dtype: float64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.std()"]},{"cell_type":"code","execution_count":null,"id":"22e838d9","metadata":{"id":"22e838d9","outputId":"55418526-b6de-4c89-d1cd-c137cf5cbe1f"},"outputs":[{"data":{"text/plain":["Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n","       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n","       'casual', 'registered', 'cnt'],\n","      dtype='object')"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"id":"d7d97085","metadata":{"id":"d7d97085","outputId":"f11ff0da-2d4c-4c50-fe29-f8139d937d80"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>atemp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>registered</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>instant</th>\n","      <td>1.00</td>\n","      <td>0.40</td>\n","      <td>0.87</td>\n","      <td>0.49</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.01</td>\n","      <td>0.14</td>\n","      <td>0.14</td>\n","      <td>0.01</td>\n","      <td>-0.07</td>\n","      <td>0.16</td>\n","      <td>0.28</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>season</th>\n","      <td>0.40</td>\n","      <td>1.00</td>\n","      <td>-0.01</td>\n","      <td>0.83</td>\n","      <td>-0.01</td>\n","      <td>-0.01</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.01</td>\n","      <td>0.31</td>\n","      <td>0.32</td>\n","      <td>0.15</td>\n","      <td>-0.15</td>\n","      <td>0.12</td>\n","      <td>0.17</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>yr</th>\n","      <td>0.87</td>\n","      <td>-0.01</td>\n","      <td>1.00</td>\n","      <td>-0.01</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.02</td>\n","      <td>0.04</td>\n","      <td>0.04</td>\n","      <td>-0.08</td>\n","      <td>-0.01</td>\n","      <td>0.14</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","    </tr>\n","    <tr>\n","      <th>mnth</th>\n","      <td>0.49</td>\n","      <td>0.83</td>\n","      <td>-0.01</td>\n","      <td>1.00</td>\n","      <td>-0.01</td>\n","      <td>0.02</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>0.20</td>\n","      <td>0.21</td>\n","      <td>0.16</td>\n","      <td>-0.14</td>\n","      <td>0.07</td>\n","      <td>0.12</td>\n","      <td>0.12</td>\n","    </tr>\n","    <tr>\n","      <th>hr</th>\n","      <td>-0.00</td>\n","      <td>-0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.01</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>0.00</td>\n","      <td>-0.02</td>\n","      <td>0.14</td>\n","      <td>0.13</td>\n","      <td>-0.28</td>\n","      <td>0.14</td>\n","      <td>0.30</td>\n","      <td>0.37</td>\n","      <td>0.39</td>\n","    </tr>\n","    <tr>\n","      <th>holiday</th>\n","      <td>0.01</td>\n","      <td>-0.01</td>\n","      <td>0.01</td>\n","      <td>0.02</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>-0.10</td>\n","      <td>-0.25</td>\n","      <td>-0.02</td>\n","      <td>-0.03</td>\n","      <td>-0.03</td>\n","      <td>-0.01</td>\n","      <td>0.00</td>\n","      <td>0.03</td>\n","      <td>-0.05</td>\n","      <td>-0.03</td>\n","    </tr>\n","    <tr>\n","      <th>weekday</th>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.10</td>\n","      <td>1.00</td>\n","      <td>0.04</td>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.01</td>\n","      <td>-0.04</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","      <td>0.02</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>workingday</th>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.00</td>\n","      <td>0.00</td>\n","      <td>-0.25</td>\n","      <td>0.04</td>\n","      <td>1.00</td>\n","      <td>0.04</td>\n","      <td>0.06</td>\n","      <td>0.05</td>\n","      <td>0.02</td>\n","      <td>-0.01</td>\n","      <td>-0.30</td>\n","      <td>0.13</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>weathersit</th>\n","      <td>-0.01</td>\n","      <td>-0.01</td>\n","      <td>-0.02</td>\n","      <td>0.01</td>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>0.00</td>\n","      <td>0.04</td>\n","      <td>1.00</td>\n","      <td>-0.10</td>\n","      <td>-0.11</td>\n","      <td>0.42</td>\n","      <td>0.03</td>\n","      <td>-0.15</td>\n","      <td>-0.12</td>\n","      <td>-0.14</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>0.14</td>\n","      <td>0.31</td>\n","      <td>0.04</td>\n","      <td>0.20</td>\n","      <td>0.14</td>\n","      <td>-0.03</td>\n","      <td>-0.00</td>\n","      <td>0.06</td>\n","      <td>-0.10</td>\n","      <td>1.00</td>\n","      <td>0.99</td>\n","      <td>-0.07</td>\n","      <td>-0.02</td>\n","      <td>0.46</td>\n","      <td>0.34</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>atemp</th>\n","      <td>0.14</td>\n","      <td>0.32</td>\n","      <td>0.04</td>\n","      <td>0.21</td>\n","      <td>0.13</td>\n","      <td>-0.03</td>\n","      <td>-0.01</td>\n","      <td>0.05</td>\n","      <td>-0.11</td>\n","      <td>0.99</td>\n","      <td>1.00</td>\n","      <td>-0.05</td>\n","      <td>-0.06</td>\n","      <td>0.45</td>\n","      <td>0.33</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>hum</th>\n","      <td>0.01</td>\n","      <td>0.15</td>\n","      <td>-0.08</td>\n","      <td>0.16</td>\n","      <td>-0.28</td>\n","      <td>-0.01</td>\n","      <td>-0.04</td>\n","      <td>0.02</td>\n","      <td>0.42</td>\n","      <td>-0.07</td>\n","      <td>-0.05</td>\n","      <td>1.00</td>\n","      <td>-0.29</td>\n","      <td>-0.35</td>\n","      <td>-0.27</td>\n","      <td>-0.32</td>\n","    </tr>\n","    <tr>\n","      <th>windspeed</th>\n","      <td>-0.07</td>\n","      <td>-0.15</td>\n","      <td>-0.01</td>\n","      <td>-0.14</td>\n","      <td>0.14</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>-0.01</td>\n","      <td>0.03</td>\n","      <td>-0.02</td>\n","      <td>-0.06</td>\n","      <td>-0.29</td>\n","      <td>1.00</td>\n","      <td>0.09</td>\n","      <td>0.08</td>\n","      <td>0.09</td>\n","    </tr>\n","    <tr>\n","      <th>casual</th>\n","      <td>0.16</td>\n","      <td>0.12</td>\n","      <td>0.14</td>\n","      <td>0.07</td>\n","      <td>0.30</td>\n","      <td>0.03</td>\n","      <td>0.03</td>\n","      <td>-0.30</td>\n","      <td>-0.15</td>\n","      <td>0.46</td>\n","      <td>0.45</td>\n","      <td>-0.35</td>\n","      <td>0.09</td>\n","      <td>1.00</td>\n","      <td>0.51</td>\n","      <td>0.69</td>\n","    </tr>\n","    <tr>\n","      <th>registered</th>\n","      <td>0.28</td>\n","      <td>0.17</td>\n","      <td>0.25</td>\n","      <td>0.12</td>\n","      <td>0.37</td>\n","      <td>-0.05</td>\n","      <td>0.02</td>\n","      <td>0.13</td>\n","      <td>-0.12</td>\n","      <td>0.34</td>\n","      <td>0.33</td>\n","      <td>-0.27</td>\n","      <td>0.08</td>\n","      <td>0.51</td>\n","      <td>1.00</td>\n","      <td>0.97</td>\n","    </tr>\n","    <tr>\n","      <th>cnt</th>\n","      <td>0.28</td>\n","      <td>0.18</td>\n","      <td>0.25</td>\n","      <td>0.12</td>\n","      <td>0.39</td>\n","      <td>-0.03</td>\n","      <td>0.03</td>\n","      <td>0.03</td>\n","      <td>-0.14</td>\n","      <td>0.40</td>\n","      <td>0.40</td>\n","      <td>-0.32</td>\n","      <td>0.09</td>\n","      <td>0.69</td>\n","      <td>0.97</td>\n","      <td>1.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            instant  season    yr  mnth    hr  holiday  weekday  workingday  \\\n","instant        1.00    0.40  0.87  0.49 -0.00     0.01     0.00       -0.00   \n","season         0.40    1.00 -0.01  0.83 -0.01    -0.01    -0.00        0.01   \n","yr             0.87   -0.01  1.00 -0.01 -0.00     0.01    -0.00       -0.00   \n","mnth           0.49    0.83 -0.01  1.00 -0.01     0.02     0.01       -0.00   \n","hr            -0.00   -0.01 -0.00 -0.01  1.00     0.00    -0.00        0.00   \n","holiday        0.01   -0.01  0.01  0.02  0.00     1.00    -0.10       -0.25   \n","weekday        0.00   -0.00 -0.00  0.01 -0.00    -0.10     1.00        0.04   \n","workingday    -0.00    0.01 -0.00 -0.00  0.00    -0.25     0.04        1.00   \n","weathersit    -0.01   -0.01 -0.02  0.01 -0.02    -0.02     0.00        0.04   \n","temp           0.14    0.31  0.04  0.20  0.14    -0.03    -0.00        0.06   \n","atemp          0.14    0.32  0.04  0.21  0.13    -0.03    -0.01        0.05   \n","hum            0.01    0.15 -0.08  0.16 -0.28    -0.01    -0.04        0.02   \n","windspeed     -0.07   -0.15 -0.01 -0.14  0.14     0.00     0.01       -0.01   \n","casual         0.16    0.12  0.14  0.07  0.30     0.03     0.03       -0.30   \n","registered     0.28    0.17  0.25  0.12  0.37    -0.05     0.02        0.13   \n","cnt            0.28    0.18  0.25  0.12  0.39    -0.03     0.03        0.03   \n","\n","            weathersit  temp  atemp   hum  windspeed  casual  registered   cnt  \n","instant          -0.01  0.14   0.14  0.01      -0.07    0.16        0.28  0.28  \n","season           -0.01  0.31   0.32  0.15      -0.15    0.12        0.17  0.18  \n","yr               -0.02  0.04   0.04 -0.08      -0.01    0.14        0.25  0.25  \n","mnth              0.01  0.20   0.21  0.16      -0.14    0.07        0.12  0.12  \n","hr               -0.02  0.14   0.13 -0.28       0.14    0.30        0.37  0.39  \n","holiday          -0.02 -0.03  -0.03 -0.01       0.00    0.03       -0.05 -0.03  \n","weekday           0.00 -0.00  -0.01 -0.04       0.01    0.03        0.02  0.03  \n","workingday        0.04  0.06   0.05  0.02      -0.01   -0.30        0.13  0.03  \n","weathersit        1.00 -0.10  -0.11  0.42       0.03   -0.15       -0.12 -0.14  \n","temp             -0.10  1.00   0.99 -0.07      -0.02    0.46        0.34  0.40  \n","atemp            -0.11  0.99   1.00 -0.05      -0.06    0.45        0.33  0.40  \n","hum               0.42 -0.07  -0.05  1.00      -0.29   -0.35       -0.27 -0.32  \n","windspeed         0.03 -0.02  -0.06 -0.29       1.00    0.09        0.08  0.09  \n","casual           -0.15  0.46   0.45 -0.35       0.09    1.00        0.51  0.69  \n","registered       -0.12  0.34   0.33 -0.27       0.08    0.51        1.00  0.97  \n","cnt              -0.14  0.40   0.40 -0.32       0.09    0.69        0.97  1.00  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 2000x2000 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# plot za korelacija, sakam da vidam kakva povrzanost imam megu kolonite\n","\n","plt.figure(figsize=(20,20))\n","c= df.corr().round(2)\n","sns.heatmap(c,cmap=\"BrBG\",annot=True)\n","c"]},{"cell_type":"code","execution_count":null,"id":"db41aa11","metadata":{"id":"db41aa11"},"outputs":[],"source":["# Gledam od plotot deka korelacijata pomegu kolonite atemp/temp i registered/cnt mi se so\n","# golema korelacija, pa ke gi izbrisam\n","\n","col_with_big_corr = ['atemp','registered']\n","df.drop(columns = col_with_big_corr, inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"7d173fae","metadata":{"id":"7d173fae","outputId":"d0bbd549-af8a-4cab-b378-24f00ff237bb"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>season</th>\n","      <th>yr</th>\n","      <th>mnth</th>\n","      <th>hr</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weathersit</th>\n","      <th>temp</th>\n","      <th>hum</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>cnt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>instant</th>\n","      <td>1.00</td>\n","      <td>0.40</td>\n","      <td>0.87</td>\n","      <td>0.49</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.01</td>\n","      <td>0.14</td>\n","      <td>0.01</td>\n","      <td>-0.07</td>\n","      <td>0.16</td>\n","      <td>0.28</td>\n","    </tr>\n","    <tr>\n","      <th>season</th>\n","      <td>0.40</td>\n","      <td>1.00</td>\n","      <td>-0.01</td>\n","      <td>0.83</td>\n","      <td>-0.01</td>\n","      <td>-0.01</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.01</td>\n","      <td>0.31</td>\n","      <td>0.15</td>\n","      <td>-0.15</td>\n","      <td>0.12</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>yr</th>\n","      <td>0.87</td>\n","      <td>-0.01</td>\n","      <td>1.00</td>\n","      <td>-0.01</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.02</td>\n","      <td>0.04</td>\n","      <td>-0.08</td>\n","      <td>-0.01</td>\n","      <td>0.14</td>\n","      <td>0.25</td>\n","    </tr>\n","    <tr>\n","      <th>mnth</th>\n","      <td>0.49</td>\n","      <td>0.83</td>\n","      <td>-0.01</td>\n","      <td>1.00</td>\n","      <td>-0.01</td>\n","      <td>0.02</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>0.20</td>\n","      <td>0.16</td>\n","      <td>-0.14</td>\n","      <td>0.07</td>\n","      <td>0.12</td>\n","    </tr>\n","    <tr>\n","      <th>hr</th>\n","      <td>-0.00</td>\n","      <td>-0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.01</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>0.00</td>\n","      <td>-0.02</td>\n","      <td>0.14</td>\n","      <td>-0.28</td>\n","      <td>0.14</td>\n","      <td>0.30</td>\n","      <td>0.39</td>\n","    </tr>\n","    <tr>\n","      <th>holiday</th>\n","      <td>0.01</td>\n","      <td>-0.01</td>\n","      <td>0.01</td>\n","      <td>0.02</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>-0.10</td>\n","      <td>-0.25</td>\n","      <td>-0.02</td>\n","      <td>-0.03</td>\n","      <td>-0.01</td>\n","      <td>0.00</td>\n","      <td>0.03</td>\n","      <td>-0.03</td>\n","    </tr>\n","    <tr>\n","      <th>weekday</th>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.10</td>\n","      <td>1.00</td>\n","      <td>0.04</td>\n","      <td>0.00</td>\n","      <td>-0.00</td>\n","      <td>-0.04</td>\n","      <td>0.01</td>\n","      <td>0.03</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>workingday</th>\n","      <td>-0.00</td>\n","      <td>0.01</td>\n","      <td>-0.00</td>\n","      <td>-0.00</td>\n","      <td>0.00</td>\n","      <td>-0.25</td>\n","      <td>0.04</td>\n","      <td>1.00</td>\n","      <td>0.04</td>\n","      <td>0.06</td>\n","      <td>0.02</td>\n","      <td>-0.01</td>\n","      <td>-0.30</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>weathersit</th>\n","      <td>-0.01</td>\n","      <td>-0.01</td>\n","      <td>-0.02</td>\n","      <td>0.01</td>\n","      <td>-0.02</td>\n","      <td>-0.02</td>\n","      <td>0.00</td>\n","      <td>0.04</td>\n","      <td>1.00</td>\n","      <td>-0.10</td>\n","      <td>0.42</td>\n","      <td>0.03</td>\n","      <td>-0.15</td>\n","      <td>-0.14</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>0.14</td>\n","      <td>0.31</td>\n","      <td>0.04</td>\n","      <td>0.20</td>\n","      <td>0.14</td>\n","      <td>-0.03</td>\n","      <td>-0.00</td>\n","      <td>0.06</td>\n","      <td>-0.10</td>\n","      <td>1.00</td>\n","      <td>-0.07</td>\n","      <td>-0.02</td>\n","      <td>0.46</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>hum</th>\n","      <td>0.01</td>\n","      <td>0.15</td>\n","      <td>-0.08</td>\n","      <td>0.16</td>\n","      <td>-0.28</td>\n","      <td>-0.01</td>\n","      <td>-0.04</td>\n","      <td>0.02</td>\n","      <td>0.42</td>\n","      <td>-0.07</td>\n","      <td>1.00</td>\n","      <td>-0.29</td>\n","      <td>-0.35</td>\n","      <td>-0.32</td>\n","    </tr>\n","    <tr>\n","      <th>windspeed</th>\n","      <td>-0.07</td>\n","      <td>-0.15</td>\n","      <td>-0.01</td>\n","      <td>-0.14</td>\n","      <td>0.14</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>-0.01</td>\n","      <td>0.03</td>\n","      <td>-0.02</td>\n","      <td>-0.29</td>\n","      <td>1.00</td>\n","      <td>0.09</td>\n","      <td>0.09</td>\n","    </tr>\n","    <tr>\n","      <th>casual</th>\n","      <td>0.16</td>\n","      <td>0.12</td>\n","      <td>0.14</td>\n","      <td>0.07</td>\n","      <td>0.30</td>\n","      <td>0.03</td>\n","      <td>0.03</td>\n","      <td>-0.30</td>\n","      <td>-0.15</td>\n","      <td>0.46</td>\n","      <td>-0.35</td>\n","      <td>0.09</td>\n","      <td>1.00</td>\n","      <td>0.69</td>\n","    </tr>\n","    <tr>\n","      <th>cnt</th>\n","      <td>0.28</td>\n","      <td>0.18</td>\n","      <td>0.25</td>\n","      <td>0.12</td>\n","      <td>0.39</td>\n","      <td>-0.03</td>\n","      <td>0.03</td>\n","      <td>0.03</td>\n","      <td>-0.14</td>\n","      <td>0.40</td>\n","      <td>-0.32</td>\n","      <td>0.09</td>\n","      <td>0.69</td>\n","      <td>1.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            instant  season    yr  mnth    hr  holiday  weekday  workingday  \\\n","instant        1.00    0.40  0.87  0.49 -0.00     0.01     0.00       -0.00   \n","season         0.40    1.00 -0.01  0.83 -0.01    -0.01    -0.00        0.01   \n","yr             0.87   -0.01  1.00 -0.01 -0.00     0.01    -0.00       -0.00   \n","mnth           0.49    0.83 -0.01  1.00 -0.01     0.02     0.01       -0.00   \n","hr            -0.00   -0.01 -0.00 -0.01  1.00     0.00    -0.00        0.00   \n","holiday        0.01   -0.01  0.01  0.02  0.00     1.00    -0.10       -0.25   \n","weekday        0.00   -0.00 -0.00  0.01 -0.00    -0.10     1.00        0.04   \n","workingday    -0.00    0.01 -0.00 -0.00  0.00    -0.25     0.04        1.00   \n","weathersit    -0.01   -0.01 -0.02  0.01 -0.02    -0.02     0.00        0.04   \n","temp           0.14    0.31  0.04  0.20  0.14    -0.03    -0.00        0.06   \n","hum            0.01    0.15 -0.08  0.16 -0.28    -0.01    -0.04        0.02   \n","windspeed     -0.07   -0.15 -0.01 -0.14  0.14     0.00     0.01       -0.01   \n","casual         0.16    0.12  0.14  0.07  0.30     0.03     0.03       -0.30   \n","cnt            0.28    0.18  0.25  0.12  0.39    -0.03     0.03        0.03   \n","\n","            weathersit  temp   hum  windspeed  casual   cnt  \n","instant          -0.01  0.14  0.01      -0.07    0.16  0.28  \n","season           -0.01  0.31  0.15      -0.15    0.12  0.18  \n","yr               -0.02  0.04 -0.08      -0.01    0.14  0.25  \n","mnth              0.01  0.20  0.16      -0.14    0.07  0.12  \n","hr               -0.02  0.14 -0.28       0.14    0.30  0.39  \n","holiday          -0.02 -0.03 -0.01       0.00    0.03 -0.03  \n","weekday           0.00 -0.00 -0.04       0.01    0.03  0.03  \n","workingday        0.04  0.06  0.02      -0.01   -0.30  0.03  \n","weathersit        1.00 -0.10  0.42       0.03   -0.15 -0.14  \n","temp             -0.10  1.00 -0.07      -0.02    0.46  0.40  \n","hum               0.42 -0.07  1.00      -0.29   -0.35 -0.32  \n","windspeed         0.03 -0.02 -0.29       1.00    0.09  0.09  \n","casual           -0.15  0.46 -0.35       0.09    1.00  0.69  \n","cnt              -0.14  0.40 -0.32       0.09    0.69  1.00  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 2000x2000 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# proverka\n","\n","plt.figure(figsize=(20,20))\n","c= df.corr().round(2)\n","sns.heatmap(c,cmap=\"BrBG\",annot=True)\n","c"]},{"cell_type":"code","execution_count":null,"id":"373a1305","metadata":{"id":"373a1305","outputId":"f61f92d9-49c7-4e9a-95b5-7cd4e8989384"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instant</th>\n","      <th>dteday</th>\n","      <th>season</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>hour</th>\n","      <th>holiday</th>\n","      <th>weekday</th>\n","      <th>workingday</th>\n","      <th>weather</th>\n","      <th>temperature</th>\n","      <th>humidity</th>\n","      <th>windspeed</th>\n","      <th>casual</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.81</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.22</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>5</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1/1/2011</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.24</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   instant    dteday  season  year  month  hour  holiday  weekday  workingday  \\\n","0        1  1/1/2011       1     0      1     0        0        6           0   \n","1        2  1/1/2011       1     0      1     1        0        6           0   \n","2        3  1/1/2011       1     0      1     2        0        6           0   \n","3        4  1/1/2011       1     0      1     3        0        6           0   \n","4        5  1/1/2011       1     0      1     4        0        6           0   \n","\n","   weather  temperature  humidity  windspeed  casual  count  \n","0        1         0.24      0.81        0.0       3     16  \n","1        1         0.22      0.80        0.0       8     40  \n","2        1         0.22      0.80        0.0       5     32  \n","3        1         0.24      0.75        0.0       3     13  \n","4        1         0.24      0.75        0.0       0      1  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Gi preimenuvam kolonite, da mi bidat pocitki\n","\n","df = df.rename(columns={'yr':'year',\n","                        'mnth':'month',\n","                        'hr':'hour',\n","                        'weathersit':'weather',\n","                        'temp':'temperature',\n","                        'hum':'humidity',\n","                        'cnt':'count'})\n","df.head()"]},{"cell_type":"code","execution_count":null,"id":"d7532f2b","metadata":{"id":"d7532f2b"},"outputs":[],"source":["# Ovaa kolona na index i datumite ne ni se potrebni, pa zatoa gi brisam.\n","\n","df.drop(['instant','dteday'], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":null,"id":"fa1deb4e","metadata":{"id":"fa1deb4e","outputId":"1fb0b9aa-df51-444a-db9b-66f2e5bd1a10"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 17379 entries, 0 to 17378\n","Data columns (total 13 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   season       17379 non-null  int64  \n"," 1   year         17379 non-null  int64  \n"," 2   month        17379 non-null  int64  \n"," 3   hour         17379 non-null  int64  \n"," 4   holiday      17379 non-null  int64  \n"," 5   weekday      17379 non-null  int64  \n"," 6   workingday   17379 non-null  int64  \n"," 7   weather      17379 non-null  int64  \n"," 8   temperature  17379 non-null  float64\n"," 9   humidity     17379 non-null  float64\n"," 10  windspeed    17379 non-null  float64\n"," 11  casual       17379 non-null  int64  \n"," 12  count        17379 non-null  int64  \n","dtypes: float64(3), int64(10)\n","memory usage: 1.7 MB\n"]}],"source":["# Proverka\n","\n","df.info()"]},{"cell_type":"code","execution_count":null,"id":"b5f5eb70","metadata":{"id":"b5f5eb70","outputId":"e4bde8a5-b1d8-430d-a9e3-9d61c7803193"},"outputs":[{"name":"stdout","output_type":"stream","text":["season [1 2 3 4]\n","year [0 1]\n","month [ 1  2  3  4  5  6  7  8  9 10 11 12]\n","hour [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n","holiday [0 1]\n","weekday [6 0 1 2 3 4 5]\n","workingday [0 1]\n","weather [1 2 3 4]\n","casual [  3   8   5   0   2   1  12  26  29  47  35  40  41  15   9   6  11   4\n","   7  16  20  19  10  13  14  18  17  21  33  23  22  24  28  48  52  42\n","  30  27  32  58  62  51  25  31  59  45  73  55  68  34  38 102  84  39\n","  36  72  76 108  66  60  57  53  61  90 105  98  43  46  80  83  74  37\n","  70  81 100  99  54  88  97 144 149 124  50  71  67  95 126 174 168 170\n"," 175 138  92 120 145 172  44  75  94  93 110 118  64  56 111  89  69 139\n"," 166 219 240 147 148  78  63  79 114  85 128 121 156 135 103  49  91 119\n"," 167 181 179 161 143 182 171 180 205 197 162 142  96  65  77 178 185 184\n"," 217 191 134 150 109 123 113  86  82 132 129 196 122 106 107 195 183 206\n"," 158 137 173 222 187 232 204 117 164 146 125 201  87 130 216 237 221 194\n"," 214 151 141 116 153 133 101 115 188 193 127 154 112 169 131 176 210 159\n"," 140 157 152 136 177 215 198 248 225 242 235 224 236 160 104 234 200 155\n"," 186 245 218 256 251 262 189 212 272 223 208 192 165 229 199 226 286 352\n"," 357 367 291 233 264 213 202 263 265 275 243 238 190 283 295 320 355 326\n"," 321 354 299 227 254 260 207 274 308 288 311 253 163 298 282 266 278 267\n"," 259 281 279 220 241 230 293 257 269 255 228 276 332 361 356 331 203 258\n"," 247 244 246 209 307 261 268 301 270 317 290 250 297 239 231 289 287 249\n"," 284 327 325 312 350 273 302 271 362 310 294 335 347 280 292 304]\n","count [ 16  40  32  13   1   2   3   8  14  36  56  84  94 106 110  93  67  35\n","  37  34  28  39  17   9   6  20  53  70  75  59  74  76  65  30  22  31\n","   5  64 154  88  44  51  61  77  72 157  52  12   4 179 100  42  57  78\n","  97  63  83 212 182 112  54  48  11  33 195 115  46  79  71  62  89 190\n"," 169 132  43  19  95 219 122  45  86 172 163  69  23   7 210 134  73  50\n","  87 187 123  15  25  98 102  55  10  49  82  92  41  38 188  47 178 155\n","  24  18  27  99 217 130 136  29 128  81  68 139 137 202  60 162 144 158\n"," 117  90 159 101 118 129  26 104  91 113 105  21  80 125 133 197 109 161\n"," 249 143 215 185 152 126 166 120  96 103  58 116 177 184 153 108 238 222\n"," 225 146 119 149 107 156 111 135 176 168 175 147 220 127 205 174 121 230\n","  66 114 216 243 199 170 165 160 140 211 145 256 223  85 206 124 255 285\n"," 274 272 191 232 327 224 196 171 198 167 235 209 141 252 189 183 193 259\n"," 282 261 268 142 131 214 242 148 201 150 228 204 164 233 257 151 248 194\n"," 244 213 181 221 250 304 241 271 253 237 299 313 310 207 138 280 173 332\n"," 331 267 301 312 278 203 279 308 226 276 336 307 273 227 239 254 287 294\n"," 263 192 281 367 349 292 303 339 366 386 325 356 314 343 333 297 288 236\n"," 240 452 383 284 291 309 321 337 388 300 200 180 354 361 306 277 428 362\n"," 286 351 411 421 396 432 441 365 481 324 346 391 397 426 376 283 289 317\n"," 420 369 359 270 353 521 499 382 449 186 528 328 234 246 444 218 412 260\n"," 398 455 530 404 269 508 439 416 464 407 371 387 264 266 537 518 265 459\n"," 517 544 290 410 296 440 533 520 258 450 344 553 470 298 347 373 436 378\n"," 342 340 390 358 385 374 598 524 384 425 611 550 434 318 442 401 594 527\n"," 364 491 295 322 456 437 392 231 394 453 604 480 565 489 487 302 547 513\n"," 319 330 554 473 323 418 493 462 506 471 305 316 409 429 548 564 355 531\n"," 601 405 494 478 419 399 402 341 251 229 350 311 406 495 417 454 486 467\n"," 572 525 379 502 558 293 247 451 335 363 357 438 579 556 334 477 539 551\n"," 424 466 326 463 380 275 315 360 476 586 423 569 538 370 498 638 607 552\n"," 208 468 381 377 431 536 529 540 400 352 557 375 443 403 447 591 504 570\n"," 588 320 555 492 427 461 422 414 408 457 545 496 368 245 596 563 562 372\n"," 514 472 511 488 595 578 348 587 497 433 475 430 262 485 546 541 483 338\n"," 543 413 435 523 532 585 584 559 582 571 516 465 329 600 609 651 519 567\n"," 621 484 469 576 608 446 628 389 505 460 590 599 566 482 568 415 589 345\n"," 593 393 500 479 620 625 614 395 445 512 490 515 526 509 448 560 610 522\n"," 549 501 612 597 644 712 676 734 662 782 749 623 713 746 686 690 679 685\n"," 648 503 721 801 750 535 729 779 649 810 957 830 657 664 684 458 581 658\n"," 641 654 703 681 606 605 561 573 618 757 800 744 759 822 698 655 643 626\n"," 615 617 632 646 692 704 624 656 738 671 678 660 635 616 673 781 775 677\n"," 748 776 700 580 819 668 640 639 691 732 709 592 702 653 603 683 743 666\n"," 813 627 706 575 769 680 717 710 622 705 630 770 659 602 733 650 873 846\n"," 474 634 852 868 745 812 669 642 730 672 645 637 577 785 719 798 752 583\n"," 839 796 507 693 827 694 647 665 834 850 790 724 869 793 723 534 831 613\n"," 857 867 823 542 811 795 833 791 900 824 687 843 804 697 747 722 689 849\n"," 872 631 674 814 633 825 629 835 667 755 794 661 772 771 777 715 847 741\n"," 877 788 913 891 688 699 751 760 820 837 652 739 865 767 858 737 862 818\n"," 854 682 851 848 897 832 893 815 878 740 783 707 941 736 845 864 808 870\n"," 754 844 853 856 725 863 792 696 701 871 968 970 925 977 758 884 766 894\n"," 842 774 797 886 892 976 805 898 967 838 953 905 899 663 727 784 809 917\n"," 901 887 761 806 948 670 619 943 817 888 890 714 711 731 675 728 922 786\n"," 938 826 963 708 636]\n"]}],"source":["# # Gledam kakvi mi se unikatnite vrednosti samo za int vo site koloni.\n","\n","for column in df.columns:\n","    if df[column].dtype == 'int64':\n","        unique_values = df[column].unique()\n","        print(column, unique_values)"]},{"cell_type":"code","execution_count":null,"id":"0a3ab74e","metadata":{"id":"0a3ab74e"},"outputs":[],"source":["# Ovaa kolona ke ja izbrisam, bidejki istite informacii mi gi sodrzi vo kolonata workingday i poradi toa ne mi e potrebna.\n","\n","df.drop(['holiday'], axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":null,"id":"d93631ae","metadata":{"scrolled":true,"id":"d93631ae","outputId":"2868d824-b288-480f-c8f7-1d7dec0dcfb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 17379 entries, 0 to 17378\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   season       17379 non-null  int64  \n"," 1   year         17379 non-null  int64  \n"," 2   month        17379 non-null  int64  \n"," 3   hour         17379 non-null  int64  \n"," 4   weekday      17379 non-null  int64  \n"," 5   workingday   17379 non-null  int64  \n"," 6   weather      17379 non-null  int64  \n"," 7   temperature  17379 non-null  float64\n"," 8   humidity     17379 non-null  float64\n"," 9   windspeed    17379 non-null  float64\n"," 10  casual       17379 non-null  int64  \n"," 11  count        17379 non-null  int64  \n","dtypes: float64(3), int64(9)\n","memory usage: 1.6 MB\n"]}],"source":["# Proverka\n","\n","df.info()"]},{"cell_type":"code","execution_count":null,"id":"6346b196","metadata":{"id":"6346b196"},"outputs":[],"source":["# for columns in df.columns:\n","#     df[columns] = pd.to_numeric(df[columns],errors='coerce').astype(float)"]},{"cell_type":"code","execution_count":null,"id":"f9f37117","metadata":{"id":"f9f37117"},"outputs":[],"source":["# # Proverka\n","\n","# df.info()"]},{"cell_type":"code","execution_count":null,"id":"aceb1869","metadata":{"id":"aceb1869"},"outputs":[],"source":["# Definiranje na target/label kolona i koloni atrubuti vo data setot\n","# atrubut ni e X\n","# labela/target kolona ni e y\n","\n","label_column = 'count'\n","\n","X = df.drop(columns=[label_column])\n","y = df[label_column]"]},{"cell_type":"code","execution_count":null,"id":"3e0ac574","metadata":{"id":"3e0ac574"},"outputs":[],"source":["# Tuka generirame podatoci za train_valid i testiranje\n","\n","X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.3, shuffle=True,random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"6d109cba","metadata":{"id":"6d109cba"},"outputs":[],"source":["# Tuka podatoci od train-valid gi delime na train i na valid\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.3,shuffle=True,random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"5fe0a778","metadata":{"id":"5fe0a778","outputId":"3d2b1dce-9587-4826-8a76-ae2cbea8b66d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Whole dataset : 17379\n","X Train size 8515\n","y Train size 8515\n","X Valid size 3650\n","y Valid size 3650\n","X Test size 5214\n","y Test size 5214\n"]}],"source":["# Tuka gledame kako ni se podeleni podatocite spored train, valid i test.\n","\n","print(\"Whole dataset :\", len(df))\n","print(\"X Train size\", len(X_train))\n","print(\"y Train size\", len(y_train))\n","print(\"X Valid size\", len(X_valid))\n","print(\"y Valid size\", len(y_valid))\n","print(\"X Test size\", len(X_test))\n","print(\"y Test size\", len(y_test))"]},{"cell_type":"code","execution_count":null,"id":"698ff9a0","metadata":{"id":"698ff9a0"},"outputs":[],"source":["# Tuka gi standardizirame podatocite vo ist opseg so min/max sclaer-ot\n","\n","minmax_scaler = preprocessing.MinMaxScaler() \n","X_train_scal = minmax_scaler.fit_transform(X_train)\n","X_valid_scal = minmax_scaler.transform(X_valid)\n","X_test_scal = minmax_scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"id":"493e29ce","metadata":{"id":"493e29ce","outputId":"93136168-7cba-4eb9-82a4-8a64cbdc630e"},"outputs":[{"data":{"text/plain":["array([[0.33333333, 0.        , 0.36363636, ..., 0.59      , 0.1346476 ,\n","        0.08310249],\n","       [0.        , 1.        , 0.18181818, ..., 0.94      , 0.21157067,\n","        0.0166205 ],\n","       [0.66666667, 1.        , 0.54545455, ..., 0.89      , 0.24996779,\n","        0.01939058],\n","       ...,\n","       [0.        , 0.        , 0.18181818, ..., 0.25      , 0.21157067,\n","        0.07202216],\n","       [0.        , 0.        , 0.        , ..., 0.49      , 0.38461538,\n","        0.00554017],\n","       [1.        , 0.        , 0.81818182, ..., 0.87      , 0.        ,\n","        0.04155125]])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["X_train_scal"]},{"cell_type":"code","execution_count":null,"id":"03dafc47","metadata":{"id":"03dafc47","outputId":"174a1e11-b764-463a-c65f-580bc3dc38a4"},"outputs":[{"data":{"text/plain":["array([[0.        , 1.        , 0.09090909, ..., 0.54      , 0.1346476 ,\n","        0.00277008],\n","       [0.        , 0.        , 1.        , ..., 0.87      , 0.1346476 ,\n","        0.01385042],\n","       [1.        , 1.        , 1.        , ..., 0.88      , 0.        ,\n","        0.00277008],\n","       ...,\n","       [0.        , 1.        , 0.        , ..., 0.77      , 0.21157067,\n","        0.06648199],\n","       [0.66666667, 0.        , 0.72727273, ..., 0.72      , 0.21157067,\n","        0.03878116],\n","       [1.        , 0.        , 0.90909091, ..., 0.94      , 0.        ,\n","        0.        ]])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["X_valid_scal"]},{"cell_type":"code","execution_count":null,"id":"df09c175","metadata":{"id":"df09c175","outputId":"cb3e3e37-9349-427c-9e2b-03f88e60f91f"},"outputs":[{"data":{"text/plain":["array([[0.66666667, 1.        , 0.45454545, ..., 0.27      , 0.24996779,\n","        0.51246537],\n","       [0.        , 1.        , 0.        , ..., 0.41      , 0.28849375,\n","        0.01385042],\n","       [1.        , 0.        , 0.81818182, ..., 0.66      , 0.36541683,\n","        0.00277008],\n","       ...,\n","       [0.66666667, 1.        , 0.45454545, ..., 0.33      , 0.28849375,\n","        0.62880886],\n","       [1.        , 1.        , 1.        , ..., 0.68      , 0.24996779,\n","        0.10803324],\n","       [0.        , 1.        , 0.09090909, ..., 0.86      , 0.1346476 ,\n","        0.        ]])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["X_test_scal"]},{"cell_type":"markdown","id":"647e7819","metadata":{"id":"647e7819"},"source":["### BAYESIAN OPTIMIZATION FOR RANDOM FOREST, SVR REGRESSION MODELS (TRAIN AND VALID)"]},{"cell_type":"code","execution_count":null,"id":"ab8eee71","metadata":{"id":"ab8eee71","outputId":"916863e1-eec4-4604-d0bb-2e47769e3f8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n","-------------------------------------------------------------------------\n","| \u001b[0m1        \u001b[0m | \u001b[0m-30.53   \u001b[0m | \u001b[0m8.368    \u001b[0m | \u001b[0m1.071    \u001b[0m | \u001b[0m8.971    \u001b[0m | \u001b[0m14.25    \u001b[0m |\n","| \u001b[0m2        \u001b[0m | \u001b[0m-64.05   \u001b[0m | \u001b[0m4.773    \u001b[0m | \u001b[0m4.576    \u001b[0m | \u001b[0m5.443    \u001b[0m | \u001b[0m17.61    \u001b[0m |\n","| \u001b[0m3        \u001b[0m | \u001b[0m-81.31   \u001b[0m | \u001b[0m2.493    \u001b[0m | \u001b[0m3.147    \u001b[0m | \u001b[0m3.53     \u001b[0m | \u001b[0m15.0     \u001b[0m |\n","| \u001b[95m4        \u001b[0m | \u001b[95m-25.62   \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m12.07    \u001b[0m |\n","| \u001b[95m5        \u001b[0m | \u001b[95m-25.2    \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m20.0     \u001b[0m |\n","=========================================================================\n","|   iter    |  target   |     C     |  epsilon  |   gamma   |\n","-------------------------------------------------------------\n","| \u001b[0m1        \u001b[0m | \u001b[0m-106.6   \u001b[0m | \u001b[0m2.164    \u001b[0m | \u001b[0m0.8012   \u001b[0m | \u001b[0m0.03604  \u001b[0m |\n","| \u001b[0m2        \u001b[0m | \u001b[0m-115.8   \u001b[0m | \u001b[0m9.815    \u001b[0m | \u001b[0m0.5839   \u001b[0m | \u001b[0m0.003945 \u001b[0m |\n","| \u001b[95m3        \u001b[0m | \u001b[95m-93.98   \u001b[0m | \u001b[95m3.53     \u001b[0m | \u001b[95m0.1932   \u001b[0m | \u001b[95m0.06374  \u001b[0m |\n","| \u001b[95m4        \u001b[0m | \u001b[95m-78.42   \u001b[0m | \u001b[95m8.565    \u001b[0m | \u001b[95m0.5513   \u001b[0m | \u001b[95m0.0885   \u001b[0m |\n","| \u001b[0m5        \u001b[0m | \u001b[0m-124.1   \u001b[0m | \u001b[0m0.6764   \u001b[0m | \u001b[0m0.8947   \u001b[0m | \u001b[0m0.03338  \u001b[0m |\n","=============================================================\n","Best hyperparameters for Random Forest: {'max_depth': 10.0, 'min_samples_leaf': 1.0, 'min_samples_split': 10.0, 'n_estimators': 20.0}\n","Best score for Random Forest: -25.204435687154103\n","---------------------------------------------------------------\n","Best hyperparameters for SVR: {'C': 8.564876531445446, 'epsilon': 0.5513051228493534, 'gamma': 0.08850184107596745}\n","Best score for SVR: -78.42430411125248\n","Elapsed time: 0 minutes 43 seconds\n"]}],"source":["start_time = time.time()\n","\n","rf_space = {'n_estimators': (10, 20),\n","            'max_depth': (2, 10),\n","            'min_samples_split': (2, 10),\n","            'min_samples_leaf': (1, 5)}\n","\n","svr_space = {'C': (0.1, 10),\n","             'epsilon': (0.01, 1),\n","             'gamma': (0.001, 0.1)}\n","\n","def optimize_rf(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","    model_rf = RandomForestRegressor(n_estimators=int(n_estimators),\n","                                   max_depth=int(max_depth),\n","                                   min_samples_split=int(min_samples_split),\n","                                   min_samples_leaf=int(min_samples_leaf),\n","                                   random_state=42)\n","    \n","    model_rf.fit(X_train_scal, y_train)\n","    y_pred = model_rf.predict(X_valid_scal)\n","    return -mean_absolute_error(y_valid, y_pred)\n","\n","def optimize_svr(C, epsilon, gamma):\n","    model_svr = SVR(C=C,\n","                epsilon=epsilon,\n","                gamma=gamma)\n","    \n","    model_svr.fit(X_train_scal, y_train)\n","    y_pred = model_svr.predict(X_valid_scal)\n","    return -mean_absolute_error(y_valid, y_pred)\n","\n","rf_bayes = BayesianOptimization(f=optimize_rf, pbounds=rf_space)\n","svr_bayes = BayesianOptimization(f=optimize_svr, pbounds=svr_space)\n","\n","rf_bayes.maximize(init_points=2, n_iter=3)\n","svr_bayes.maximize(init_points=2, n_iter=3)\n","\n","best_params = rf_bayes.max['params']\n","best_score = rf_bayes.max['target']\n","print(\"Best hyperparameters for Random Forest:\", best_params)\n","print(\"Best score for Random Forest:\", best_score)\n","print(\"---------------------------------------------------------------\")\n","best_params = svr_bayes.max['params']\n","best_score = svr_bayes.max['target']\n","print(\"Best hyperparameters for SVR:\", best_params)\n","print(\"Best score for SVR:\", best_score)\n","\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","\n","minutes = int(elapsed_time // 60)\n","seconds = int(elapsed_time % 60)\n","\n","print(f\"Elapsed time: {minutes} minutes {seconds} seconds\")\n","\n","data = {optimize_rf,optimize_svr}\n","\n","for value in data:\n","    if isinstance(value, str):\n","        data.remove(value)\n","        data.add(value.encode(\"utf-8\"))\n","\n","with open(\"data.pickle\", \"wb\") as f:\n","    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","with open(\"data.pickle\", \"rb\") as f:\n","    loaded_data = pickle.load(f)\n","\n","for value in loaded_data:\n","    if isinstance(value, bytes):\n","        loaded_data.remove(value)\n","        loaded_data.add(value.decode(\"utf-8\"))"]},{"cell_type":"markdown","id":"72e06580","metadata":{"id":"72e06580"},"source":["### BEST MODEL FOR RANDOM FOREST AND SVR ON TEST DATA WITH BAYESIAN OPTIMIZATION"]},{"cell_type":"code","execution_count":null,"id":"52b43e69","metadata":{"id":"52b43e69","outputId":"b31aa64b-95b9-45fa-ff9e-6eda9f1e503a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test score for Random Forest: 24.40319485160074\n","Test score for SVR: 74.81636019805848\n","Elapsed time: 0 minutes 9 seconds\n"]}],"source":["start_time = time.time()\n","\n","best_rf_model = RandomForestRegressor(n_estimators=int(rf_bayes.max['params']['n_estimators']),\n","                                      max_depth=int(rf_bayes.max['params']['max_depth']),\n","                                      min_samples_split=int(rf_bayes.max['params']['min_samples_split']),\n","                                      min_samples_leaf=int(rf_bayes.max['params']['min_samples_leaf']),\n","                                      random_state=42)\n","\n","best_rf_model.fit(X_train_scal, y_train)\n","y_pred_rf = best_rf_model.predict(X_test_scal)\n","test_score_rf = mean_absolute_error(y_test, y_pred_rf)\n","print(\"Test score for Random Forest:\", test_score_rf)\n","\n","best_svr_model = SVR(C=svr_bayes.max['params']['C'],\n","                     epsilon=svr_bayes.max['params']['epsilon'],\n","                     gamma=svr_bayes.max['params']['gamma'])\n","\n","best_svr_model.fit(X_train_scal, y_train)\n","y_pred_svr = best_svr_model.predict(X_test_scal)\n","test_score_svr = mean_absolute_error(y_test, y_pred_svr)\n","print(\"Test score for SVR:\", test_score_svr)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","\n","minutes = int(elapsed_time // 60)\n","seconds = int(elapsed_time % 60)\n","\n","print(f\"Elapsed time: {minutes} minutes {seconds} seconds\")"]},{"cell_type":"markdown","id":"d9160c82","metadata":{"id":"d9160c82"},"source":["### NEURAL NETWORK FOR RANDOM FOREST, SVR REGRESSION MODELS FOR BAYESIAN OPTIMIZATION "]},{"cell_type":"code","execution_count":null,"id":"89292f51","metadata":{"id":"89292f51","outputId":"5d2f7bfd-0bf6-479a-e965-288d947d5e98"},"outputs":[{"name":"stdout","output_type":"stream","text":["Neural Network MSE: 1485.5566448742031\n","Elapsed time: 0 minutes 0 seconds\n"]}],"source":["start_time = time.time()\n","\n","nn_model = MLPRegressor(hidden_layer_sizes=(10, 30), max_iter=50, random_state=42)\n","\n","combined_inputs = pd.concat([pd.DataFrame(y_pred_rf), pd.DataFrame(y_pred_svr)], axis=1)\n","\n","nn_model.fit(combined_inputs, y_test)\n","\n","y_pred_nn = nn_model.predict(combined_inputs)\n","\n","mse_nn = mean_squared_error(y_test, y_pred_nn)\n","print(\"Neural Network MSE:\", mse_nn)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","\n","minutes = int(elapsed_time // 60)\n","seconds = int(elapsed_time % 60)\n","\n","print(f\"Elapsed time: {minutes} minutes {seconds} seconds\")"]},{"cell_type":"markdown","id":"5000fc96","metadata":{"id":"5000fc96"},"source":["### GENETIC ALGORITHM OPTIMIZATION FOR RANDOM FOREST, SVR REGRESSSION MODELS (TRAIN, VALID AND TEST)"]},{"cell_type":"code","execution_count":null,"id":"c1dae9d8","metadata":{"id":"c1dae9d8","outputId":"71a78656-2d84-4d90-c99c-406bc3654127"},"outputs":[{"name":"stdout","output_type":"stream","text":["gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n","0  \t5     \t-2379.22\t481.954    \t-1773.95   \t-2987.65   \n","1  \t10    \t-3413.8 \t2735.42    \t-1773.95   \t-8861.9    \n","2  \t10    \t-1873.17\t243.955    \t-1717.5    \t-2359.21   \n","3  \t10    \t-1759.58\t45.3461    \t-1717.5    \t-1834.8    \n","4  \t10    \t-1709.87\t6.22521    \t-1704.79   \t-1717.5    \n","5  \t10    \t-1692.1 \t2.08054    \t-1690.85   \t-1696.24   \n","gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n","0  \t5     \t-18666.1\t1356.12    \t-16288.5   \t-20464.8   \n","1  \t10    \t-16808.2\t1100.54    \t-16134.1   \t-18993.2   \n","2  \t10    \t-16700.5\t1071.58    \t-16122     \t-18840.3   \n","3  \t10    \t-16363.4\t485.014    \t-16120.6   \t-17333.5   \n","4  \t10    \t-16101.3\t37.7151    \t-16025.9   \t-16120.6   \n","5  \t10    \t-16104.7\t40.0034    \t-16025.9   \t-16138     \n","Random Forest:\n","Best parameters: {'n_estimators': 40, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}\n","Best score (validation): -1686.1039755032139\n","MSE on test data: 1449.9474896471168\n","\n","SVR:\n","Best parameters: {'C': 9.146016486911865, 'epsilon': 0.8533428985760747, 'gamma': 0.09425327096825889}\n","Best score (validation): -16025.922642814421\n","MSE on test data: 14544.778120145116\n","Elapsed time: 21 minutes 36 seconds\n"]}],"source":["start_time = time.time()\n","\n","rf_space = {'n_estimators': Integer(10, 50),\n","            'max_depth': Integer(2, 10),\n","            'min_samples_split': Integer(2, 10),\n","            'min_samples_leaf': Integer(1, 5)}\n","\n","svr_space = {'C': Continuous(0.1, 10),\n","             'epsilon': Continuous(0.01, 1),\n","             'gamma': Continuous(0.001, 0.1)}\n","\n","rf_model = RandomForestRegressor(random_state=42)\n","svr_model = SVR()\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","rf_opt = GASearchCV(estimator=rf_model,\n","                     param_grid=rf_space,\n","                     cv=cv,\n","                     scoring='neg_mean_squared_error',\n","                     n_jobs=-1,\n","                     verbose=True,\n","                     population_size=5,\n","                     generations=5)\n","\n","svr_opt = GASearchCV(estimator=svr_model,\n","                      param_grid=svr_space,\n","                      cv=cv,\n","                      scoring='neg_mean_squared_error',\n","                      n_jobs=-1,\n","                      verbose=True,\n","                      population_size=5,\n","                      generations=5)\n","\n","rf_opt.fit(X_train_scal, y_train)\n","y_pred_rf_valid = rf_opt.predict(X_valid_scal)\n","y_pred_rf_test = rf_opt.predict(X_test_scal)\n","\n","svr_opt.fit(X_train_scal, y_train)\n","y_pred_svr_valid = svr_opt.predict(X_valid_scal)\n","y_pred_svr_test = svr_opt.predict(X_test_scal)\n","\n","print(\"Random Forest:\")\n","print(\"Best parameters:\", rf_opt.best_params_)\n","print(\"Best score (validation):\", rf_opt.best_score_)\n","print(\"MSE on test data:\", mean_squared_error(y_test, y_pred_rf_test))\n","\n","print(\"\\nSVR:\")\n","print(\"Best parameters:\", svr_opt.best_params_)\n","print(\"Best score (validation):\", svr_opt.best_score_)\n","print(\"MSE on test data:\", mean_squared_error(y_test, y_pred_svr_test))\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","\n","minutes = int(elapsed_time // 60)\n","seconds = int(elapsed_time % 60)\n","\n","print(f\"Elapsed time: {minutes} minutes {seconds} seconds\")"]},{"cell_type":"markdown","id":"a3930130","metadata":{"id":"a3930130"},"source":["### AUTO MODEL CONSTRUCTION NEURAL NETWORKS"]},{"cell_type":"code","execution_count":null,"id":"cc522646","metadata":{"id":"cc522646","outputId":"db7bc650-5f35-4be4-d5e5-6f81cd9d6dd1"},"outputs":[{"data":{"text/plain":["(8515, 11)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"id":"c065eabf","metadata":{"id":"c065eabf"},"outputs":[],"source":["input_dim = X_train.shape[1]  "]},{"cell_type":"code","execution_count":null,"id":"bc467caf","metadata":{"id":"bc467caf","outputId":"d01d4505-192f-48c5-824f-36ba59b57559"},"outputs":[{"data":{"text/plain":["11"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["input_dim"]},{"cell_type":"code","execution_count":null,"id":"f86a183f","metadata":{"id":"f86a183f","outputId":"32e6ab69-7b6b-479f-c474-d4c9d80a2d73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 64)                768       \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 42605.2578 - mse: 42605.2578 - mae: 146.6821 - val_loss: 28090.7656 - val_mse: 28090.7656 - val_mae: 128.4386\n","163/163 [==============================] - 0s 877us/step\n","Epoch 1/1\n","8/8 loss: 42605.2578 mean_squared_error: 42605.2578 mean_absolute_error: 146.6821 val_loss: 28090.7656 val_mean_squared_error: 28090.7656 val_mean_absolute_error: 128.4386\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 64)                768       \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 2s 2ms/step - loss: 55580.9844 - mse: 55580.9844 - mae: 163.1861 - val_loss: 46891.7812 - val_mse: 46891.7812 - val_mae: 148.9809\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 55580.9844 mean_squared_error: 55580.9844 mean_absolute_error: 163.1861 val_loss: 46891.7812 val_mean_squared_error: 46891.7812 val_mean_absolute_error: 148.9809\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_4 (Dense)             (None, 64)                768       \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 2s 2ms/step - loss: 42111.9727 - mse: 42111.9727 - mae: 145.5134 - val_loss: 28878.7422 - val_mse: 28878.7422 - val_mae: 130.9133\n","163/163 [==============================] - 0s 909us/step\n","Epoch 1/1\n","8/8 loss: 42111.9727 mean_squared_error: 42111.9727 mean_absolute_error: 145.5134 val_loss: 28878.7422 val_mean_squared_error: 28878.7422 val_mean_absolute_error: 130.9133\n","Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 64)                768       \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 42567.3008 - mse: 42567.3008 - mae: 145.9576 - val_loss: 27930.2090 - val_mse: 27930.2090 - val_mae: 127.4534\n","163/163 [==============================] - 0s 899us/step\n","Epoch 1/1\n","8/8 loss: 42567.3008 mean_squared_error: 42567.3008 mean_absolute_error: 145.9576 val_loss: 27930.2090 val_mean_squared_error: 27930.2090 val_mean_absolute_error: 127.4534\n","Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 64)                768       \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 2s 2ms/step - loss: 40288.5664 - mse: 40288.5664 - mae: 144.0777 - val_loss: 27563.4258 - val_mse: 27563.4258 - val_mae: 128.2601\n","163/163 [==============================] - 0s 896us/step\n","Epoch 1/1\n","8/8 loss: 40288.5664 mean_squared_error: 40288.5664 mean_absolute_error: 144.0777 val_loss: 27563.4258 val_mean_squared_error: 27563.4258 val_mean_absolute_error: 128.2601\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_10 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_11 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense_12 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 26497.3789 - mse: 26497.3789 - mae: 117.9057 - val_loss: 16094.1182 - val_mse: 16094.1182 - val_mae: 88.9947\n","163/163 [==============================] - 0s 940us/step\n","Epoch 1/1\n","8/8 loss: 26497.3789 mean_squared_error: 26497.3789 mean_absolute_error: 117.9057 val_loss: 16094.1182 val_mean_squared_error: 16094.1182 val_mean_absolute_error: 88.9947\n","Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_13 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_15 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 56334.5781 - mse: 56334.5781 - mae: 164.3640 - val_loss: 48921.0625 - val_mse: 48921.0625 - val_mae: 152.0238\n","163/163 [==============================] - 0s 924us/step\n","Epoch 1/1\n","8/8 loss: 56334.5781 mean_squared_error: 56334.5781 mean_absolute_error: 164.3640 val_loss: 48921.0625 val_mean_squared_error: 48921.0625 val_mean_absolute_error: 152.0238\n","Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_16 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_17 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_18 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24676.8965 - mse: 24676.8965 - mae: 113.9169 - val_loss: 15053.4463 - val_mse: 15053.4463 - val_mae: 91.1722\n","163/163 [==============================] - 0s 920us/step\n","Epoch 1/1\n","8/8 loss: 24676.8965 mean_squared_error: 24676.8965 mean_absolute_error: 113.9169 val_loss: 15053.4463 val_mean_squared_error: 15053.4463 val_mean_absolute_error: 91.1722\n","Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_19 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_20 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_21 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 25540.8281 - mse: 25540.8281 - mae: 116.2961 - val_loss: 15490.7988 - val_mse: 15490.7988 - val_mae: 87.2687\n","163/163 [==============================] - 0s 911us/step\n","Epoch 1/1\n","8/8 loss: 25540.8281 mean_squared_error: 25540.8281 mean_absolute_error: 116.2961 val_loss: 15490.7988 val_mean_squared_error: 15490.7988 val_mean_absolute_error: 87.2687\n","Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_22 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_23 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_4 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_24 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 23583.0703 - mse: 23583.0703 - mae: 112.3990 - val_loss: 15305.0020 - val_mse: 15305.0020 - val_mae: 87.0201\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 23583.0703 mean_squared_error: 23583.0703 mean_absolute_error: 112.3990 val_loss: 15305.0020 val_mean_squared_error: 15305.0020 val_mean_absolute_error: 87.0201\n","Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_25 (Dense)            (None, 256)               3072      \n","                                                                 \n"," dense_26 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dropout_5 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_27 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_6 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_28 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 19087.2891 - mse: 19087.2891 - mae: 96.6013 - val_loss: 14017.1445 - val_mse: 14017.1445 - val_mae: 91.2824\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 19087.2891 mean_squared_error: 19087.2891 mean_absolute_error: 96.6013 val_loss: 14017.1445 val_mean_squared_error: 14017.1445 val_mean_absolute_error: 91.2824\n","Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_29 (Dense)            (None, 256)               3072      \n","                                                                 \n"," dense_30 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dropout_7 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_31 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_8 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_32 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 56361.5898 - mse: 56361.5898 - mae: 164.6613 - val_loss: 49058.5625 - val_mse: 49058.5625 - val_mae: 152.2307\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 56361.5898 mean_squared_error: 56361.5898 mean_absolute_error: 164.6613 val_loss: 49058.5625 val_mean_squared_error: 49058.5625 val_mean_absolute_error: 152.2307\n","Model: \"sequential_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_33 (Dense)            (None, 256)               3072      \n","                                                                 \n"," dense_34 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dropout_9 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_35 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_10 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_36 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 18547.0957 - mse: 18547.0957 - mae: 94.9285 - val_loss: 12796.0771 - val_mse: 12796.0771 - val_mae: 75.8201\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 18547.0957 mean_squared_error: 18547.0957 mean_absolute_error: 94.9285 val_loss: 12796.0771 val_mean_squared_error: 12796.0771 val_mean_absolute_error: 75.8201\n","Model: \"sequential_13\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_37 (Dense)            (None, 256)               3072      \n","                                                                 \n"," dense_38 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dropout_11 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_39 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_12 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_40 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 19327.7656 - mse: 19327.7656 - mae: 96.8977 - val_loss: 12868.0947 - val_mse: 12868.0947 - val_mae: 80.0853\n","163/163 [==============================] - 1s 2ms/step\n","Epoch 1/1\n","8/8 loss: 19327.7656 mean_squared_error: 19327.7656 mean_absolute_error: 96.8977 val_loss: 12868.0947 val_mean_squared_error: 12868.0947 val_mean_absolute_error: 80.0853\n","Model: \"sequential_14\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_41 (Dense)            (None, 256)               3072      \n","                                                                 \n"," dense_42 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dropout_13 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_43 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_14 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_44 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 18102.1055 - mse: 18102.1055 - mae: 94.3632 - val_loss: 13192.9521 - val_mse: 13192.9521 - val_mae: 79.2686\n","163/163 [==============================] - 1s 2ms/step\n","Epoch 1/1\n","8/8 loss: 18102.1055 mean_squared_error: 18102.1055 mean_absolute_error: 94.3632 val_loss: 13192.9521 val_mean_squared_error: 13192.9521 val_mean_absolute_error: 79.2686\n","Model: \"sequential_15\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_45 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_46 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_15 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_47 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 31279.7676 - mse: 31279.7676 - mae: 128.8478 - val_loss: 18913.1406 - val_mse: 18913.1406 - val_mae: 101.5258\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 31279.7676 mean_squared_error: 31279.7676 mean_absolute_error: 128.8478 val_loss: 18913.1406 val_mean_squared_error: 18913.1406 val_mean_absolute_error: 101.5258\n","Model: \"sequential_16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_48 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_49 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_16 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_50 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 61824.4922 - mse: 61824.4922 - mae: 173.7747 - val_loss: 57417.5352 - val_mse: 57417.5352 - val_mae: 165.1072\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 61824.4922 mean_squared_error: 61824.4922 mean_absolute_error: 173.7747 val_loss: 57417.5352 val_mean_squared_error: 57417.5352 val_mean_absolute_error: 165.1072\n","Model: \"sequential_17\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_51 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_52 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_17 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_53 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 30139.7793 - mse: 30139.7793 - mae: 127.2351 - val_loss: 18017.2188 - val_mse: 18017.2188 - val_mae: 93.1145\n","163/163 [==============================] - 0s 918us/step\n","Epoch 1/1\n","8/8 loss: 30139.7793 mean_squared_error: 30139.7793 mean_absolute_error: 127.2351 val_loss: 18017.2188 val_mean_squared_error: 18017.2188 val_mean_absolute_error: 93.1145\n","Model: \"sequential_18\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_54 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_55 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_18 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_56 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 30665.2617 - mse: 30665.2617 - mae: 128.0730 - val_loss: 17995.3984 - val_mse: 17995.3984 - val_mae: 98.2302\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","8/8 loss: 30665.2617 mean_squared_error: 30665.2617 mean_absolute_error: 128.0730 val_loss: 17995.3984 val_mean_squared_error: 17995.3984 val_mean_absolute_error: 98.2302\n","Model: \"sequential_19\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_57 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_58 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_19 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_59 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 29068.4668 - mse: 29068.4668 - mae: 125.7018 - val_loss: 18646.8633 - val_mse: 18646.8633 - val_mae: 100.3375\n","163/163 [==============================] - 0s 964us/step\n","Epoch 1/1\n","8/8 loss: 29068.4668 mean_squared_error: 29068.4668 mean_absolute_error: 125.7018 val_loss: 18646.8633 val_mean_squared_error: 18646.8633 val_mean_absolute_error: 100.3375\n","Model: \"sequential_20\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_60 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_61 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_20 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_62 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_21 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_63 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 5s 2ms/step - loss: 22887.8730 - mse: 22887.8730 - mae: 105.8814 - val_loss: 13451.8672 - val_mse: 13451.8672 - val_mae: 83.8823\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 22887.8730 mean_squared_error: 22887.8730 mean_absolute_error: 105.8814 val_loss: 13451.8672 val_mean_squared_error: 13451.8672 val_mean_absolute_error: 83.8823\n","Model: \"sequential_21\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_64 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_65 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_22 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_66 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_23 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_67 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 5s 3ms/step - loss: 61516.0781 - mse: 61516.0781 - mae: 173.2030 - val_loss: 57222.4922 - val_mse: 57222.4922 - val_mae: 164.7873\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 61516.0781 mean_squared_error: 61516.0781 mean_absolute_error: 173.2030 val_loss: 57222.4922 val_mean_squared_error: 57222.4922 val_mean_absolute_error: 164.7873\n","Model: \"sequential_22\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_68 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_69 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_24 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_70 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_25 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_71 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 5s 3ms/step - loss: 21006.4141 - mse: 21006.4141 - mae: 102.5652 - val_loss: 13436.4648 - val_mse: 13436.4648 - val_mae: 78.8599\n","163/163 [==============================] - 0s 997us/step\n","Epoch 1/1\n","8/8 loss: 21006.4141 mean_squared_error: 21006.4141 mean_absolute_error: 102.5652 val_loss: 13436.4648 val_mean_squared_error: 13436.4648 val_mean_absolute_error: 78.8599\n","Model: \"sequential_23\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_72 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_73 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_26 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_74 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_27 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_75 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 5s 3ms/step - loss: 23045.3164 - mse: 23045.3164 - mae: 106.7838 - val_loss: 13585.6221 - val_mse: 13585.6221 - val_mae: 80.7930\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 23045.3164 mean_squared_error: 23045.3164 mean_absolute_error: 106.7838 val_loss: 13585.6221 val_mean_squared_error: 13585.6221 val_mean_absolute_error: 80.7930\n","Model: \"sequential_24\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_76 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_77 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_28 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_78 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dropout_29 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_79 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 5s 3ms/step - loss: 19653.0664 - mse: 19653.0664 - mae: 100.1643 - val_loss: 13501.8916 - val_mse: 13501.8916 - val_mae: 80.6258\n","163/163 [==============================] - 0s 990us/step\n","Epoch 1/1\n","8/8 loss: 19653.0664 mean_squared_error: 19653.0664 mean_absolute_error: 100.1643 val_loss: 13501.8916 val_mean_squared_error: 13501.8916 val_mean_absolute_error: 80.6258\n","Model: \"sequential_25\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_80 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_81 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 43759.6055 - mse: 43759.6055 - mae: 147.8781 - val_loss: 28298.2734 - val_mse: 28298.2734 - val_mae: 128.2250\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25262.5684 - mse: 25262.5684 - mae: 121.6091 - val_loss: 22734.9238 - val_mse: 22734.9238 - val_mae: 113.9997\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20358.6816 - mse: 20358.6816 - mae: 106.7501 - val_loss: 18690.4141 - val_mse: 18690.4141 - val_mae: 101.9976\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 17364.0137 - mse: 17364.0137 - mae: 96.2662 - val_loss: 16568.5410 - val_mse: 16568.5410 - val_mae: 93.9514\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15770.5732 - mse: 15770.5732 - mae: 90.3947 - val_loss: 15386.2480 - val_mse: 15386.2480 - val_mae: 88.5132\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14828.2217 - mse: 14828.2217 - mae: 86.4022 - val_loss: 14591.8447 - val_mse: 14591.8447 - val_mae: 85.7516\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14215.9150 - mse: 14215.9150 - mae: 83.8060 - val_loss: 14044.8691 - val_mse: 14044.8691 - val_mae: 83.8687\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13771.0781 - mse: 13771.0781 - mae: 82.2041 - val_loss: 13659.1621 - val_mse: 13659.1621 - val_mae: 82.6741\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13494.5527 - mse: 13494.5527 - mae: 81.2000 - val_loss: 13409.5146 - val_mse: 13409.5146 - val_mae: 80.9910\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13287.5234 - mse: 13287.5234 - mae: 80.4618 - val_loss: 13206.0039 - val_mse: 13206.0039 - val_mae: 80.4951\n","163/163 [==============================] - 0s 962us/step\n","Epoch 10/10\n","8/8 loss: 13287.5234 mean_squared_error: 13287.5234 mean_absolute_error: 80.4618 val_loss: 13206.0039 val_mean_squared_error: 13206.0039 val_mean_absolute_error: 80.4951\n","Model: \"sequential_26\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_82 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_83 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 55739.9570 - mse: 55739.9570 - mae: 163.8312 - val_loss: 46745.9375 - val_mse: 46745.9375 - val_mae: 148.7646\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 41163.1758 - mse: 41163.1758 - mae: 142.4602 - val_loss: 38078.1250 - val_mse: 38078.1250 - val_mae: 139.0567\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 34455.1875 - mse: 34455.1875 - mae: 131.7245 - val_loss: 31593.8848 - val_mse: 31593.8848 - val_mae: 121.0148\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 27997.4609 - mse: 27997.4609 - mae: 112.8481 - val_loss: 26014.3848 - val_mse: 26014.3848 - val_mae: 106.9302\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 23482.9863 - mse: 23482.9863 - mae: 101.7637 - val_loss: 22310.8184 - val_mse: 22310.8184 - val_mae: 99.3592\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20276.0859 - mse: 20276.0859 - mae: 94.4445 - val_loss: 19435.4043 - val_mse: 19435.4043 - val_mae: 93.7734\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 1ms/step - loss: 17717.1270 - mse: 17717.1270 - mae: 88.1166 - val_loss: 17153.8047 - val_mse: 17153.8047 - val_mae: 89.4953\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 1ms/step - loss: 15739.1807 - mse: 15739.1807 - mae: 83.1406 - val_loss: 15371.7207 - val_mse: 15371.7207 - val_mae: 84.1181\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14277.0068 - mse: 14277.0068 - mae: 79.1427 - val_loss: 14102.3164 - val_mse: 14102.3164 - val_mae: 79.2426\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13253.8574 - mse: 13253.8574 - mae: 76.2560 - val_loss: 13195.5566 - val_mse: 13195.5566 - val_mae: 78.3875\n","163/163 [==============================] - 0s 926us/step\n","Epoch 10/10\n","8/8 loss: 13253.8574 mean_squared_error: 13253.8574 mean_absolute_error: 76.2560 val_loss: 13195.5566 val_mean_squared_error: 13195.5566 val_mean_absolute_error: 78.3875\n","Model: \"sequential_27\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_84 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_85 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 42275.6406 - mse: 42275.6406 - mae: 146.8937 - val_loss: 28726.2031 - val_mse: 28726.2031 - val_mae: 130.1264\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25694.9531 - mse: 25694.9531 - mae: 122.5244 - val_loss: 22630.7402 - val_mse: 22630.7402 - val_mae: 115.1822\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20051.4531 - mse: 20051.4531 - mae: 105.7435 - val_loss: 18177.7207 - val_mse: 18177.7207 - val_mae: 100.8908\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16736.4355 - mse: 16736.4355 - mae: 93.8399 - val_loss: 15843.2461 - val_mse: 15843.2461 - val_mae: 92.4877\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15054.6221 - mse: 15054.6221 - mae: 87.3564 - val_loss: 14652.6064 - val_mse: 14652.6064 - val_mae: 86.6905\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14206.3652 - mse: 14206.3652 - mae: 83.8433 - val_loss: 13973.0322 - val_mse: 13973.0322 - val_mae: 84.4946\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13683.4893 - mse: 13683.4893 - mae: 81.8455 - val_loss: 13532.2783 - val_mse: 13532.2783 - val_mae: 82.7635\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13360.3311 - mse: 13360.3311 - mae: 80.6620 - val_loss: 13239.7773 - val_mse: 13239.7773 - val_mae: 82.1092\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13113.2061 - mse: 13113.2061 - mae: 79.8471 - val_loss: 13073.5576 - val_mse: 13073.5576 - val_mae: 82.5919\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12950.5049 - mse: 12950.5049 - mae: 79.2812 - val_loss: 12869.6602 - val_mse: 12869.6602 - val_mae: 79.3667\n","163/163 [==============================] - 0s 890us/step\n","Epoch 10/10\n","8/8 loss: 12950.5049 mean_squared_error: 12950.5049 mean_absolute_error: 79.2812 val_loss: 12869.6602 val_mean_squared_error: 12869.6602 val_mean_absolute_error: 79.3667\n","Model: \"sequential_28\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_86 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_87 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 47030.5469 - mse: 47030.5469 - mae: 151.7131 - val_loss: 29243.7773 - val_mse: 29243.7773 - val_mae: 128.5253\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25991.2754 - mse: 25991.2754 - mae: 122.6637 - val_loss: 23140.9336 - val_mse: 23140.9336 - val_mae: 115.8056\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20532.3379 - mse: 20532.3379 - mae: 106.6502 - val_loss: 18790.2480 - val_mse: 18790.2480 - val_mae: 101.1141\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17350.0352 - mse: 17350.0352 - mae: 95.8544 - val_loss: 16519.4980 - val_mse: 16519.4980 - val_mae: 93.3358\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15700.4492 - mse: 15700.4492 - mae: 89.9267 - val_loss: 15323.9102 - val_mse: 15323.9102 - val_mae: 88.3456\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14741.1553 - mse: 14741.1553 - mae: 85.9889 - val_loss: 14495.6660 - val_mse: 14495.6660 - val_mae: 87.0711\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14101.0400 - mse: 14101.0400 - mae: 83.6587 - val_loss: 13944.0947 - val_mse: 13944.0947 - val_mae: 84.1889\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13670.6973 - mse: 13670.6973 - mae: 81.9334 - val_loss: 13595.3691 - val_mse: 13595.3691 - val_mae: 81.4983\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13380.5654 - mse: 13380.5654 - mae: 80.6865 - val_loss: 13285.7412 - val_mse: 13285.7412 - val_mae: 81.7313\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13147.0479 - mse: 13147.0479 - mae: 79.9013 - val_loss: 13081.0195 - val_mse: 13081.0195 - val_mae: 80.1894\n","163/163 [==============================] - 0s 892us/step\n","Epoch 10/10\n","8/8 loss: 13147.0479 mean_squared_error: 13147.0479 mean_absolute_error: 79.9013 val_loss: 13081.0195 val_mean_squared_error: 13081.0195 val_mean_absolute_error: 80.1894\n","Model: \"sequential_29\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_88 (Dense)            (None, 64)                768       \n","                                                                 \n"," dense_89 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 39722.6406 - mse: 39722.6406 - mae: 142.4603 - val_loss: 27374.1387 - val_mse: 27374.1387 - val_mae: 129.5627\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25329.1660 - mse: 25329.1660 - mae: 123.6519 - val_loss: 23700.9824 - val_mse: 23700.9824 - val_mae: 119.2551\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 21848.8965 - mse: 21848.8965 - mae: 113.4186 - val_loss: 20401.9980 - val_mse: 20401.9980 - val_mae: 109.0932\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18912.8984 - mse: 18912.8984 - mae: 103.2071 - val_loss: 17926.0234 - val_mse: 17926.0234 - val_mae: 99.0735\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16888.5879 - mse: 16888.5879 - mae: 95.0861 - val_loss: 16294.4463 - val_mse: 16294.4463 - val_mae: 93.8030\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15642.0908 - mse: 15642.0908 - mae: 89.9040 - val_loss: 15336.5039 - val_mse: 15336.5039 - val_mae: 88.7134\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14851.3721 - mse: 14851.3721 - mae: 86.3384 - val_loss: 14647.3223 - val_mse: 14647.3223 - val_mae: 86.4094\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14329.3750 - mse: 14329.3750 - mae: 84.1749 - val_loss: 14174.8242 - val_mse: 14174.8242 - val_mae: 85.5150\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13952.0537 - mse: 13952.0537 - mae: 83.0105 - val_loss: 13928.7656 - val_mse: 13928.7656 - val_mae: 81.7729\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13710.2705 - mse: 13710.2705 - mae: 81.6004 - val_loss: 13618.3779 - val_mse: 13618.3779 - val_mae: 83.5450\n","163/163 [==============================] - 0s 945us/step\n","Epoch 10/10\n","8/8 loss: 13710.2705 mean_squared_error: 13710.2705 mean_absolute_error: 81.6004 val_loss: 13618.3779 val_mean_squared_error: 13618.3779 val_mean_absolute_error: 83.5450\n","Model: \"sequential_30\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_90 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_91 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_30 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_92 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 27228.8242 - mse: 27228.8242 - mae: 120.0698 - val_loss: 16230.3926 - val_mse: 16230.3926 - val_mae: 89.7342\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15095.0264 - mse: 15095.0264 - mae: 85.3041 - val_loss: 13594.5342 - val_mse: 13594.5342 - val_mae: 79.2525\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13939.0225 - mse: 13939.0225 - mae: 80.9595 - val_loss: 13090.6826 - val_mse: 13090.6826 - val_mae: 83.0896\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13457.6582 - mse: 13457.6582 - mae: 79.6482 - val_loss: 12667.6357 - val_mse: 12667.6357 - val_mae: 76.5259\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13254.7217 - mse: 13254.7217 - mae: 78.5487 - val_loss: 12481.6562 - val_mse: 12481.6562 - val_mae: 74.5004\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12916.8896 - mse: 12916.8896 - mae: 77.3779 - val_loss: 12115.0908 - val_mse: 12115.0908 - val_mae: 74.4055\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12849.9951 - mse: 12849.9951 - mae: 76.8245 - val_loss: 11910.9531 - val_mse: 11910.9531 - val_mae: 73.6089\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12437.1240 - mse: 12437.1240 - mae: 75.3519 - val_loss: 11671.6152 - val_mse: 11671.6152 - val_mae: 72.5694\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12370.1992 - mse: 12370.1992 - mae: 74.7038 - val_loss: 11867.3027 - val_mse: 11867.3027 - val_mae: 69.7024\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12238.1523 - mse: 12238.1523 - mae: 73.8624 - val_loss: 11324.2490 - val_mse: 11324.2490 - val_mae: 72.4800\n","163/163 [==============================] - 0s 931us/step\n","Epoch 10/10\n","8/8 loss: 12238.1523 mean_squared_error: 12238.1523 mean_absolute_error: 73.8624 val_loss: 11324.2490 val_mean_squared_error: 11324.2490 val_mean_absolute_error: 72.4800\n","Model: \"sequential_31\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_93 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_94 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_31 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_95 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 56427.8750 - mse: 56427.8750 - mae: 164.3696 - val_loss: 48979.8867 - val_mse: 48979.8867 - val_mae: 152.1057\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 42390.5273 - mse: 42390.5273 - mae: 139.2321 - val_loss: 37072.6094 - val_mse: 37072.6094 - val_mae: 123.5733\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 32027.6855 - mse: 32027.6855 - mae: 112.3386 - val_loss: 28423.8535 - val_mse: 28423.8535 - val_mae: 102.6915\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 24689.5469 - mse: 24689.5469 - mae: 94.0333 - val_loss: 22412.1406 - val_mse: 22412.1406 - val_mae: 88.4516\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19930.8750 - mse: 19930.8750 - mae: 84.2008 - val_loss: 18469.7344 - val_mse: 18469.7344 - val_mae: 80.3142\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 16812.6660 - mse: 16812.6660 - mae: 78.5595 - val_loss: 15774.6514 - val_mse: 15774.6514 - val_mae: 75.4961\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14613.3770 - mse: 14613.3770 - mae: 74.2506 - val_loss: 14234.1250 - val_mse: 14234.1250 - val_mae: 74.0805\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13280.0654 - mse: 13280.0654 - mae: 72.0991 - val_loss: 12653.5537 - val_mse: 12653.5537 - val_mae: 70.2089\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12224.5391 - mse: 12224.5391 - mae: 70.3552 - val_loss: 11666.1621 - val_mse: 11666.1621 - val_mae: 67.9139\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11576.2637 - mse: 11576.2637 - mae: 69.1293 - val_loss: 11054.0449 - val_mse: 11054.0449 - val_mae: 67.5491\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","8/8 loss: 11576.2637 mean_squared_error: 11576.2637 mean_absolute_error: 69.1293 val_loss: 11054.0449 val_mean_squared_error: 11054.0449 val_mean_absolute_error: 67.5491\n","Model: \"sequential_32\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_96 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_97 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_32 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_98 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24361.9883 - mse: 24361.9883 - mae: 112.5348 - val_loss: 14663.4189 - val_mse: 14663.4189 - val_mae: 87.4789\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14102.4346 - mse: 14102.4346 - mae: 83.0141 - val_loss: 12990.4932 - val_mse: 12990.4932 - val_mae: 77.9676\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13113.2529 - mse: 13113.2529 - mae: 79.3719 - val_loss: 12243.4209 - val_mse: 12243.4209 - val_mae: 78.3100\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12617.2178 - mse: 12617.2178 - mae: 76.6255 - val_loss: 11641.4189 - val_mse: 11641.4189 - val_mae: 73.9595\n","Epoch 5/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 11695.4561 - mse: 11695.4561 - mae: 73.0736 - val_loss: 11270.1826 - val_mse: 11270.1826 - val_mae: 76.4681\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11331.3877 - mse: 11331.3877 - mae: 71.1192 - val_loss: 10752.3086 - val_mse: 10752.3086 - val_mae: 71.2909\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11170.2500 - mse: 11170.2500 - mae: 70.3113 - val_loss: 10631.0205 - val_mse: 10631.0205 - val_mae: 67.2219\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10941.2383 - mse: 10941.2383 - mae: 69.6526 - val_loss: 10599.9121 - val_mse: 10599.9121 - val_mae: 67.4799\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10722.0859 - mse: 10722.0859 - mae: 68.8910 - val_loss: 10800.6025 - val_mse: 10800.6025 - val_mae: 75.2178\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10778.7812 - mse: 10778.7812 - mae: 68.9929 - val_loss: 10648.8809 - val_mse: 10648.8809 - val_mae: 68.9469\n","163/163 [==============================] - 0s 985us/step\n","Epoch 10/10\n","8/8 loss: 10778.7812 mean_squared_error: 10778.7812 mean_absolute_error: 68.9929 val_loss: 10648.8809 val_mean_squared_error: 10648.8809 val_mean_absolute_error: 68.9469\n","Model: \"sequential_33\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_99 (Dense)            (None, 128)               1536      \n","                                                                 \n"," dense_100 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_33 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_101 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 26711.5938 - mse: 26711.5938 - mae: 117.7906 - val_loss: 15659.6650 - val_mse: 15659.6650 - val_mae: 90.7184\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14777.3594 - mse: 14777.3594 - mae: 84.5546 - val_loss: 13521.3613 - val_mse: 13521.3613 - val_mae: 78.7349\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13862.0039 - mse: 13862.0039 - mae: 81.1251 - val_loss: 12859.5596 - val_mse: 12859.5596 - val_mae: 78.3625\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13379.2773 - mse: 13379.2773 - mae: 79.3264 - val_loss: 12531.7686 - val_mse: 12531.7686 - val_mae: 76.2174\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13096.9619 - mse: 13096.9619 - mae: 78.2452 - val_loss: 12300.3291 - val_mse: 12300.3291 - val_mae: 74.2568\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 12854.4219 - mse: 12854.4219 - mae: 77.0111 - val_loss: 11949.6172 - val_mse: 11949.6172 - val_mae: 74.7889\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12552.7197 - mse: 12552.7197 - mae: 76.1087 - val_loss: 11930.4121 - val_mse: 11930.4121 - val_mae: 72.0266\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12253.3125 - mse: 12253.3125 - mae: 74.6730 - val_loss: 11528.2002 - val_mse: 11528.2002 - val_mae: 72.1085\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11977.2021 - mse: 11977.2021 - mae: 73.5322 - val_loss: 11436.2363 - val_mse: 11436.2363 - val_mae: 69.6487\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11732.8916 - mse: 11732.8916 - mae: 72.7912 - val_loss: 11036.4424 - val_mse: 11036.4424 - val_mae: 72.7651\n","163/163 [==============================] - 0s 935us/step\n","Epoch 10/10\n","8/8 loss: 11732.8916 mean_squared_error: 11732.8916 mean_absolute_error: 72.7912 val_loss: 11036.4424 val_mean_squared_error: 11036.4424 val_mean_absolute_error: 72.7651\n","Model: \"sequential_34\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_102 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_103 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_34 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_104 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24178.7168 - mse: 24178.7168 - mae: 113.6036 - val_loss: 15392.6299 - val_mse: 15392.6299 - val_mae: 89.5834\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14314.9697 - mse: 14314.9697 - mae: 84.4340 - val_loss: 13477.3730 - val_mse: 13477.3730 - val_mae: 84.2115\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13565.1992 - mse: 13565.1992 - mae: 81.1959 - val_loss: 13100.9062 - val_mse: 13100.9062 - val_mae: 82.7627\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13478.7744 - mse: 13478.7744 - mae: 81.0421 - val_loss: 13249.5879 - val_mse: 13249.5879 - val_mae: 77.5024\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13423.0625 - mse: 13423.0625 - mae: 80.8432 - val_loss: 12994.1523 - val_mse: 12994.1523 - val_mae: 79.2485\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13322.1562 - mse: 13322.1562 - mae: 80.5485 - val_loss: 12925.0674 - val_mse: 12925.0674 - val_mae: 80.5663\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13361.2217 - mse: 13361.2217 - mae: 80.4718 - val_loss: 13121.6465 - val_mse: 13121.6465 - val_mae: 84.5970\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13318.4688 - mse: 13318.4688 - mae: 80.6175 - val_loss: 12905.7139 - val_mse: 12905.7139 - val_mae: 80.9593\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13389.0156 - mse: 13389.0156 - mae: 80.8542 - val_loss: 12914.6904 - val_mse: 12914.6904 - val_mae: 79.8614\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13412.2002 - mse: 13412.2002 - mae: 80.5441 - val_loss: 12964.3623 - val_mse: 12964.3623 - val_mae: 81.8568\n","163/163 [==============================] - 0s 962us/step\n","Epoch 10/10\n","8/8 loss: 13412.2002 mean_squared_error: 13412.2002 mean_absolute_error: 80.5441 val_loss: 12964.3623 val_mean_squared_error: 12964.3623 val_mean_absolute_error: 81.8568\n","Model: \"sequential_35\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_105 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_106 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_35 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_107 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_36 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_108 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 20375.8789 - mse: 20375.8789 - mae: 98.6716 - val_loss: 14795.5488 - val_mse: 14795.5488 - val_mae: 75.6286\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13461.4746 - mse: 13461.4746 - mae: 78.9922 - val_loss: 11963.7041 - val_mse: 11963.7041 - val_mae: 76.9701\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12529.7207 - mse: 12529.7207 - mae: 75.7474 - val_loss: 11216.9062 - val_mse: 11216.9062 - val_mae: 68.7634\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11922.1172 - mse: 11922.1172 - mae: 72.2293 - val_loss: 10261.8506 - val_mse: 10261.8506 - val_mae: 67.5160\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11015.6094 - mse: 11015.6094 - mae: 69.3968 - val_loss: 10209.1016 - val_mse: 10209.1016 - val_mae: 62.8052\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10697.3311 - mse: 10697.3311 - mae: 67.8941 - val_loss: 11211.9121 - val_mse: 11211.9121 - val_mae: 77.1375\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10387.4658 - mse: 10387.4658 - mae: 66.8459 - val_loss: 9674.5811 - val_mse: 9674.5811 - val_mae: 61.0853\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10227.9053 - mse: 10227.9053 - mae: 65.9277 - val_loss: 9019.1758 - val_mse: 9019.1758 - val_mae: 60.4537\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 9851.6387 - mse: 9851.6387 - mae: 64.2480 - val_loss: 8793.3398 - val_mse: 8793.3398 - val_mae: 64.9354\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 9618.2373 - mse: 9618.2373 - mae: 62.7821 - val_loss: 8413.3574 - val_mse: 8413.3574 - val_mae: 57.9071\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 9618.2373 mean_squared_error: 9618.2373 mean_absolute_error: 62.7821 val_loss: 8413.3574 val_mean_squared_error: 8413.3574 val_mean_absolute_error: 57.9071\n","Model: \"sequential_36\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_109 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_110 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_37 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_111 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_38 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_112 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 56134.8906 - mse: 56134.8906 - mae: 163.9657 - val_loss: 48935.9492 - val_mse: 48935.9492 - val_mae: 152.0560\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 43174.1289 - mse: 43174.1289 - mae: 145.0488 - val_loss: 39489.1445 - val_mse: 39489.1445 - val_mae: 136.4156\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 33068.3164 - mse: 33068.3164 - mae: 115.8536 - val_loss: 28844.5371 - val_mse: 28844.5371 - val_mae: 103.2292\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25042.9844 - mse: 25042.9844 - mae: 94.4733 - val_loss: 22734.8164 - val_mse: 22734.8164 - val_mae: 88.8861\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20246.9043 - mse: 20246.9043 - mae: 84.4039 - val_loss: 18398.5938 - val_mse: 18398.5938 - val_mae: 78.1798\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16784.1094 - mse: 16784.1094 - mae: 77.4747 - val_loss: 15304.1553 - val_mse: 15304.1553 - val_mae: 72.3247\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14113.1328 - mse: 14113.1328 - mae: 70.2642 - val_loss: 12486.0557 - val_mse: 12486.0557 - val_mae: 64.9787\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11637.7725 - mse: 11637.7725 - mae: 63.7893 - val_loss: 10776.3389 - val_mse: 10776.3389 - val_mae: 59.9410\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10090.8613 - mse: 10090.8613 - mae: 60.0597 - val_loss: 8424.6318 - val_mse: 8424.6318 - val_mae: 49.7967\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 8688.6455 - mse: 8688.6455 - mae: 56.6970 - val_loss: 7145.5859 - val_mse: 7145.5859 - val_mae: 47.2851\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 8688.6455 mean_squared_error: 8688.6455 mean_absolute_error: 56.6970 val_loss: 7145.5859 val_mean_squared_error: 7145.5859 val_mean_absolute_error: 47.2851\n","Model: \"sequential_37\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_113 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_114 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_39 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_115 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_40 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_116 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 19301.7129 - mse: 19301.7129 - mae: 95.9905 - val_loss: 12941.9385 - val_mse: 12941.9385 - val_mae: 77.5921\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13163.1338 - mse: 13163.1338 - mae: 77.8461 - val_loss: 12689.6240 - val_mse: 12689.6240 - val_mae: 69.3192\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11911.3555 - mse: 11911.3555 - mae: 72.8138 - val_loss: 10420.1982 - val_mse: 10420.1982 - val_mae: 69.0317\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10979.0752 - mse: 10979.0752 - mae: 69.6946 - val_loss: 11228.1357 - val_mse: 11228.1357 - val_mae: 66.7009\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10702.8857 - mse: 10702.8857 - mae: 68.6028 - val_loss: 9806.5137 - val_mse: 9806.5137 - val_mae: 68.4221\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10330.0596 - mse: 10330.0596 - mae: 67.0915 - val_loss: 9382.5293 - val_mse: 9382.5293 - val_mae: 64.2316\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10218.2910 - mse: 10218.2910 - mae: 66.4853 - val_loss: 9967.7100 - val_mse: 9967.7100 - val_mae: 63.6084\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10340.8242 - mse: 10340.8242 - mae: 66.6193 - val_loss: 10193.1738 - val_mse: 10193.1738 - val_mae: 68.2088\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10212.9854 - mse: 10212.9854 - mae: 65.8597 - val_loss: 9315.7119 - val_mse: 9315.7119 - val_mae: 61.2460\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 9822.8408 - mse: 9822.8408 - mae: 64.6119 - val_loss: 9595.4424 - val_mse: 9595.4424 - val_mae: 65.2145\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 9822.8408 mean_squared_error: 9822.8408 mean_absolute_error: 64.6119 val_loss: 9595.4424 val_mean_squared_error: 9595.4424 val_mean_absolute_error: 65.2145\n","Model: \"sequential_38\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_117 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_118 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_41 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_119 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_42 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_120 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 2ms/step - loss: 20251.8438 - mse: 20251.8438 - mae: 99.0101 - val_loss: 13696.3369 - val_mse: 13696.3369 - val_mae: 88.7579\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13751.5811 - mse: 13751.5811 - mae: 80.1172 - val_loss: 12139.0322 - val_mse: 12139.0322 - val_mae: 78.2016\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12853.2764 - mse: 12853.2764 - mae: 76.8228 - val_loss: 11489.1992 - val_mse: 11489.1992 - val_mae: 75.3153\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12268.7637 - mse: 12268.7637 - mae: 74.0997 - val_loss: 10831.3291 - val_mse: 10831.3291 - val_mae: 70.9399\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11752.1201 - mse: 11752.1201 - mae: 71.8903 - val_loss: 10300.9336 - val_mse: 10300.9336 - val_mae: 69.6125\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10995.6641 - mse: 10995.6641 - mae: 69.4802 - val_loss: 10099.6143 - val_mse: 10099.6143 - val_mae: 63.6860\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10820.7041 - mse: 10820.7041 - mae: 68.3006 - val_loss: 9779.1924 - val_mse: 9779.1924 - val_mae: 69.0999\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10426.8682 - mse: 10426.8682 - mae: 66.8421 - val_loss: 9486.1338 - val_mse: 9486.1338 - val_mae: 63.0463\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10293.5986 - mse: 10293.5986 - mae: 66.7260 - val_loss: 9170.3652 - val_mse: 9170.3652 - val_mae: 61.6575\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10136.0137 - mse: 10136.0137 - mae: 65.7689 - val_loss: 8964.4375 - val_mse: 8964.4375 - val_mae: 60.0503\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 10136.0137 mean_squared_error: 10136.0137 mean_absolute_error: 65.7689 val_loss: 8964.4375 val_mean_squared_error: 8964.4375 val_mean_absolute_error: 60.0503\n","Model: \"sequential_39\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_121 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_122 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_43 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_123 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_44 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_124 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 3ms/step - loss: 17967.4844 - mse: 17967.4844 - mae: 94.6409 - val_loss: 13331.1631 - val_mse: 13331.1631 - val_mae: 79.7159\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13907.6074 - mse: 13907.6074 - mae: 82.2133 - val_loss: 13388.2949 - val_mse: 13388.2949 - val_mae: 78.0397\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13985.1113 - mse: 13985.1113 - mae: 82.1999 - val_loss: 12989.3711 - val_mse: 12989.3711 - val_mae: 79.7249\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13816.3887 - mse: 13816.3887 - mae: 82.2200 - val_loss: 13293.8232 - val_mse: 13293.8232 - val_mae: 77.2470\n","Epoch 5/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13833.4033 - mse: 13833.4033 - mae: 81.6048 - val_loss: 13060.2598 - val_mse: 13060.2598 - val_mae: 81.1532\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13850.5596 - mse: 13850.5596 - mae: 81.9096 - val_loss: 13093.9746 - val_mse: 13093.9746 - val_mae: 83.1141\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13818.9287 - mse: 13818.9287 - mae: 81.7259 - val_loss: 12988.0596 - val_mse: 12988.0596 - val_mae: 79.4691\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13718.1758 - mse: 13718.1758 - mae: 81.5973 - val_loss: 13091.3643 - val_mse: 13091.3643 - val_mae: 83.5117\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13720.2178 - mse: 13720.2178 - mae: 81.3090 - val_loss: 13232.4941 - val_mse: 13232.4941 - val_mae: 79.3624\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13894.5791 - mse: 13894.5791 - mae: 81.9155 - val_loss: 13167.9346 - val_mse: 13167.9346 - val_mae: 84.6420\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 13894.5791 mean_squared_error: 13894.5791 mean_absolute_error: 81.9155 val_loss: 13167.9346 val_mean_squared_error: 13167.9346 val_mean_absolute_error: 84.6420\n","Model: \"sequential_40\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_125 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_126 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_45 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_127 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 31348.3398 - mse: 31348.3398 - mae: 129.7507 - val_loss: 18896.8848 - val_mse: 18896.8848 - val_mae: 101.2477\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17120.7031 - mse: 17120.7031 - mae: 92.8613 - val_loss: 15209.4834 - val_mse: 15209.4834 - val_mae: 82.3683\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 15129.5156 - mse: 15129.5156 - mae: 84.9109 - val_loss: 13453.6250 - val_mse: 13453.6250 - val_mae: 80.9126\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14396.8018 - mse: 14396.8018 - mae: 82.5503 - val_loss: 13160.2832 - val_mse: 13160.2832 - val_mae: 77.0440\n","Epoch 5/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14139.7051 - mse: 14139.7051 - mae: 81.4528 - val_loss: 12774.5947 - val_mse: 12774.5947 - val_mae: 78.3080\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13807.0225 - mse: 13807.0225 - mae: 80.2969 - val_loss: 12581.3428 - val_mse: 12581.3428 - val_mae: 76.5830\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13711.6631 - mse: 13711.6631 - mae: 79.5353 - val_loss: 12535.5273 - val_mse: 12535.5273 - val_mae: 73.9821\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13362.1416 - mse: 13362.1416 - mae: 78.6430 - val_loss: 12175.8984 - val_mse: 12175.8984 - val_mae: 74.0534\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13041.1270 - mse: 13041.1270 - mae: 77.6163 - val_loss: 12007.8145 - val_mse: 12007.8145 - val_mae: 73.4134\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12957.3438 - mse: 12957.3438 - mae: 76.9789 - val_loss: 11799.6494 - val_mse: 11799.6494 - val_mae: 73.6658\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 12957.3438 mean_squared_error: 12957.3438 mean_absolute_error: 76.9789 val_loss: 11799.6494 val_mean_squared_error: 11799.6494 val_mean_absolute_error: 73.6658\n","Model: \"sequential_41\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_128 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_129 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_46 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_130 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 61359.8242 - mse: 61359.8242 - mae: 172.9945 - val_loss: 56955.0039 - val_mse: 56955.0039 - val_mae: 164.3446\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 52113.4219 - mse: 52113.4219 - mae: 157.2901 - val_loss: 49128.0234 - val_mse: 49128.0234 - val_mae: 152.3229\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 45303.2344 - mse: 45303.2344 - mae: 145.9115 - val_loss: 42469.1406 - val_mse: 42469.1406 - val_mae: 135.2030\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 38688.6133 - mse: 38688.6133 - mae: 127.0900 - val_loss: 36451.1992 - val_mse: 36451.1992 - val_mae: 120.6283\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 33342.4414 - mse: 33342.4414 - mae: 113.9927 - val_loss: 31355.5898 - val_mse: 31355.5898 - val_mae: 107.9694\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 28747.9297 - mse: 28747.9297 - mae: 102.4081 - val_loss: 27148.8184 - val_mse: 27148.8184 - val_mae: 97.4159\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25050.0000 - mse: 25050.0000 - mae: 94.3571 - val_loss: 23819.1094 - val_mse: 23819.1094 - val_mae: 89.6730\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 22017.5527 - mse: 22017.5527 - mae: 87.7904 - val_loss: 21074.5664 - val_mse: 21074.5664 - val_mae: 84.4893\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19799.9160 - mse: 19799.9160 - mae: 83.5567 - val_loss: 18882.2402 - val_mse: 18882.2402 - val_mae: 80.1448\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17751.8398 - mse: 17751.8398 - mae: 79.7166 - val_loss: 17143.2969 - val_mse: 17143.2969 - val_mae: 77.4516\n","163/163 [==============================] - 0s 967us/step\n","Epoch 10/10\n","8/8 loss: 17751.8398 mean_squared_error: 17751.8398 mean_absolute_error: 79.7166 val_loss: 17143.2969 val_mean_squared_error: 17143.2969 val_mean_absolute_error: 77.4516\n","Model: \"sequential_42\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_131 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_132 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_47 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_133 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 31301.9199 - mse: 31301.9199 - mae: 128.5102 - val_loss: 17892.6250 - val_mse: 17892.6250 - val_mae: 94.5504\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16166.9561 - mse: 16166.9561 - mae: 90.1991 - val_loss: 13906.6123 - val_mse: 13906.6123 - val_mae: 86.4538\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14775.6201 - mse: 14775.6201 - mae: 84.8373 - val_loss: 12950.1992 - val_mse: 12950.1992 - val_mae: 77.8467\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13720.6738 - mse: 13720.6738 - mae: 81.1234 - val_loss: 12594.0068 - val_mse: 12594.0068 - val_mae: 81.2589\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13213.9863 - mse: 13213.9863 - mae: 79.1666 - val_loss: 11938.1904 - val_mse: 11938.1904 - val_mae: 76.8764\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13037.2373 - mse: 13037.2373 - mae: 77.6893 - val_loss: 11488.5811 - val_mse: 11488.5811 - val_mae: 74.6021\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12327.0088 - mse: 12327.0088 - mae: 74.7023 - val_loss: 11198.4248 - val_mse: 11198.4248 - val_mae: 68.8553\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12098.1045 - mse: 12098.1045 - mae: 73.0070 - val_loss: 10754.9697 - val_mse: 10754.9697 - val_mae: 71.5273\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11417.0410 - mse: 11417.0410 - mae: 70.8855 - val_loss: 10653.8926 - val_mse: 10653.8926 - val_mae: 69.4955\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11460.2988 - mse: 11460.2988 - mae: 70.8726 - val_loss: 10493.9385 - val_mse: 10493.9385 - val_mae: 68.2033\n","163/163 [==============================] - 0s 896us/step\n","Epoch 10/10\n","8/8 loss: 11460.2988 mean_squared_error: 11460.2988 mean_absolute_error: 70.8726 val_loss: 10493.9385 val_mean_squared_error: 10493.9385 val_mean_absolute_error: 68.2033\n","Model: \"sequential_43\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_134 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_135 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_48 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_136 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 31364.8320 - mse: 31364.8320 - mae: 130.2250 - val_loss: 18547.2754 - val_mse: 18547.2754 - val_mae: 101.8849\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16725.5820 - mse: 16725.5820 - mae: 91.9335 - val_loss: 14558.9209 - val_mse: 14558.9209 - val_mae: 81.2922\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14654.5859 - mse: 14654.5859 - mae: 83.5307 - val_loss: 13294.5078 - val_mse: 13294.5078 - val_mae: 78.7984\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13980.2686 - mse: 13980.2686 - mae: 81.0129 - val_loss: 12893.7383 - val_mse: 12893.7383 - val_mae: 82.2773\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13670.2041 - mse: 13670.2041 - mae: 80.5301 - val_loss: 12470.8750 - val_mse: 12470.8750 - val_mae: 76.2518\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13250.9307 - mse: 13250.9307 - mae: 79.2167 - val_loss: 12130.9707 - val_mse: 12130.9707 - val_mae: 77.3275\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13061.9258 - mse: 13061.9258 - mae: 78.3349 - val_loss: 11906.4355 - val_mse: 11906.4355 - val_mae: 73.6034\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12788.5039 - mse: 12788.5039 - mae: 77.2575 - val_loss: 11748.9775 - val_mse: 11748.9775 - val_mae: 71.9982\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12593.9072 - mse: 12593.9072 - mae: 75.8564 - val_loss: 11470.5713 - val_mse: 11470.5713 - val_mae: 71.5579\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12470.5430 - mse: 12470.5430 - mae: 75.1798 - val_loss: 11326.7773 - val_mse: 11326.7773 - val_mae: 70.5143\n","163/163 [==============================] - 0s 968us/step\n","Epoch 10/10\n","8/8 loss: 12470.5430 mean_squared_error: 12470.5430 mean_absolute_error: 75.1798 val_loss: 11326.7773 val_mean_squared_error: 11326.7773 val_mean_absolute_error: 70.5143\n","Model: \"sequential_44\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_137 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_138 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_49 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_139 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 28176.7246 - mse: 28176.7246 - mae: 124.2749 - val_loss: 17982.7676 - val_mse: 17982.7676 - val_mae: 98.7920\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15984.8789 - mse: 15984.8789 - mae: 89.8942 - val_loss: 14417.3809 - val_mse: 14417.3809 - val_mae: 84.3287\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14394.5762 - mse: 14394.5762 - mae: 84.3001 - val_loss: 13916.3662 - val_mse: 13916.3662 - val_mae: 78.5940\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13837.5420 - mse: 13837.5420 - mae: 82.0852 - val_loss: 13159.9404 - val_mse: 13159.9404 - val_mae: 82.6206\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13550.8135 - mse: 13550.8135 - mae: 81.2091 - val_loss: 13037.7822 - val_mse: 13037.7822 - val_mae: 82.2714\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13564.4238 - mse: 13564.4238 - mae: 81.2346 - val_loss: 12971.7510 - val_mse: 12971.7510 - val_mae: 80.9389\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13689.5088 - mse: 13689.5088 - mae: 81.1087 - val_loss: 12980.6152 - val_mse: 12980.6152 - val_mae: 81.6991\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13591.6885 - mse: 13591.6885 - mae: 81.2622 - val_loss: 12961.7412 - val_mse: 12961.7412 - val_mae: 82.2335\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13592.7197 - mse: 13592.7197 - mae: 81.1897 - val_loss: 12996.2480 - val_mse: 12996.2480 - val_mae: 78.3563\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13501.1377 - mse: 13501.1377 - mae: 80.7327 - val_loss: 12925.7119 - val_mse: 12925.7119 - val_mae: 81.2932\n","163/163 [==============================] - 0s 913us/step\n","Epoch 10/10\n","8/8 loss: 13501.1377 mean_squared_error: 13501.1377 mean_absolute_error: 80.7327 val_loss: 12925.7119 val_mean_squared_error: 12925.7119 val_mean_absolute_error: 81.2932\n","Model: \"sequential_45\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_140 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_141 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_50 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_142 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_51 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_143 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 22476.8438 - mse: 22476.8438 - mae: 105.5690 - val_loss: 13334.8975 - val_mse: 13334.8975 - val_mae: 81.8700\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13912.2559 - mse: 13912.2559 - mae: 80.3314 - val_loss: 12884.5527 - val_mse: 12884.5527 - val_mae: 85.8982\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13118.2686 - mse: 13118.2686 - mae: 77.0529 - val_loss: 11187.6924 - val_mse: 11187.6924 - val_mae: 70.7381\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12359.8643 - mse: 12359.8643 - mae: 74.2997 - val_loss: 10475.4414 - val_mse: 10475.4414 - val_mae: 68.6431\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11649.0752 - mse: 11649.0752 - mae: 71.3052 - val_loss: 10078.0684 - val_mse: 10078.0684 - val_mae: 65.5157\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11004.9414 - mse: 11004.9414 - mae: 69.4012 - val_loss: 9624.8604 - val_mse: 9624.8604 - val_mae: 63.5915\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10984.5820 - mse: 10984.5820 - mae: 68.6587 - val_loss: 9390.5742 - val_mse: 9390.5742 - val_mae: 61.8142\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10851.5020 - mse: 10851.5020 - mae: 67.6277 - val_loss: 9640.1230 - val_mse: 9640.1230 - val_mae: 68.3828\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10523.4355 - mse: 10523.4355 - mae: 66.7487 - val_loss: 9026.5869 - val_mse: 9026.5869 - val_mae: 63.2807\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10207.7285 - mse: 10207.7285 - mae: 65.6189 - val_loss: 8910.4268 - val_mse: 8910.4268 - val_mae: 60.1582\n","163/163 [==============================] - 0s 959us/step\n","Epoch 10/10\n","8/8 loss: 10207.7285 mean_squared_error: 10207.7285 mean_absolute_error: 65.6189 val_loss: 8910.4268 val_mean_squared_error: 8910.4268 val_mean_absolute_error: 60.1582\n","Model: \"sequential_46\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_144 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_145 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_52 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_146 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_53 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_147 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 3ms/step - loss: 61684.4766 - mse: 61684.4766 - mae: 173.5227 - val_loss: 57397.5820 - val_mse: 57397.5820 - val_mae: 165.0771\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 52445.3281 - mse: 52445.3281 - mae: 157.8036 - val_loss: 49464.3359 - val_mse: 49464.3359 - val_mae: 152.8091\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 45783.4180 - mse: 45783.4180 - mae: 148.1626 - val_loss: 43721.2422 - val_mse: 43721.2422 - val_mae: 145.2275\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 40958.7617 - mse: 40958.7617 - mae: 142.5968 - val_loss: 39670.5898 - val_mse: 39670.5898 - val_mae: 141.0269\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 35814.8008 - mse: 35814.8008 - mae: 126.5368 - val_loss: 33066.7031 - val_mse: 33066.7031 - val_mae: 115.4228\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 30029.1758 - mse: 30029.1758 - mae: 106.6021 - val_loss: 28100.5664 - val_mse: 28100.5664 - val_mae: 99.4370\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25839.8184 - mse: 25839.8184 - mae: 96.4410 - val_loss: 24467.2129 - val_mse: 24467.2129 - val_mae: 92.2618\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 22845.6426 - mse: 22845.6426 - mae: 90.1968 - val_loss: 22279.8320 - val_mse: 22279.8320 - val_mae: 91.7829\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20409.4922 - mse: 20409.4922 - mae: 85.3160 - val_loss: 19224.7363 - val_mse: 19224.7363 - val_mae: 80.4496\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 18444.0586 - mse: 18444.0586 - mae: 81.6465 - val_loss: 17469.5898 - val_mse: 17469.5898 - val_mae: 79.0633\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 18444.0586 mean_squared_error: 18444.0586 mean_absolute_error: 81.6465 val_loss: 17469.5898 val_mean_squared_error: 17469.5898 val_mean_absolute_error: 79.0633\n","Model: \"sequential_47\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_148 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_149 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_54 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_150 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_55 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_151 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 21513.9531 - mse: 21513.9531 - mae: 103.4316 - val_loss: 14957.5537 - val_mse: 14957.5537 - val_mae: 78.1197\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13923.8555 - mse: 13923.8555 - mae: 80.5672 - val_loss: 12191.7139 - val_mse: 12191.7139 - val_mae: 77.0818\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13077.7422 - mse: 13077.7422 - mae: 77.6334 - val_loss: 12290.6006 - val_mse: 12290.6006 - val_mae: 68.3021\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11901.5820 - mse: 11901.5820 - mae: 72.9136 - val_loss: 10853.6777 - val_mse: 10853.6777 - val_mae: 75.3801\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11307.3848 - mse: 11307.3848 - mae: 71.0313 - val_loss: 10558.2510 - val_mse: 10558.2510 - val_mae: 74.6346\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10948.2305 - mse: 10948.2305 - mae: 70.1970 - val_loss: 10149.9121 - val_mse: 10149.9121 - val_mae: 66.0094\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10926.6055 - mse: 10926.6055 - mae: 69.9226 - val_loss: 9907.5283 - val_mse: 9907.5283 - val_mae: 68.2661\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10779.6787 - mse: 10779.6787 - mae: 69.3686 - val_loss: 9671.5166 - val_mse: 9671.5166 - val_mae: 65.5349\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10792.5352 - mse: 10792.5352 - mae: 69.1522 - val_loss: 9549.7041 - val_mse: 9549.7041 - val_mae: 65.8750\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10674.2666 - mse: 10674.2666 - mae: 68.6507 - val_loss: 9575.1787 - val_mse: 9575.1787 - val_mae: 65.0716\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 10674.2666 mean_squared_error: 10674.2666 mean_absolute_error: 68.6507 val_loss: 9575.1787 val_mean_squared_error: 9575.1787 val_mean_absolute_error: 65.0716\n","Model: \"sequential_48\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_152 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_153 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_56 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_154 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_57 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_155 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 23634.8105 - mse: 23634.8105 - mae: 108.6018 - val_loss: 13737.9756 - val_mse: 13737.9756 - val_mae: 79.3635\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14860.8457 - mse: 14860.8457 - mae: 83.5185 - val_loss: 12700.7617 - val_mse: 12700.7617 - val_mae: 76.6114\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13923.0430 - mse: 13923.0430 - mae: 80.5821 - val_loss: 12256.8721 - val_mse: 12256.8721 - val_mae: 72.4304\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 13758.2041 - mse: 13758.2041 - mae: 79.0157 - val_loss: 11690.9932 - val_mse: 11690.9932 - val_mae: 72.0121\n","Epoch 5/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 12735.0107 - mse: 12735.0107 - mae: 76.0472 - val_loss: 10989.1221 - val_mse: 10989.1221 - val_mae: 71.6965\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12429.0273 - mse: 12429.0273 - mae: 74.5128 - val_loss: 10664.0752 - val_mse: 10664.0752 - val_mae: 67.4284\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12074.8691 - mse: 12074.8691 - mae: 73.0581 - val_loss: 10289.5342 - val_mse: 10289.5342 - val_mae: 65.7714\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11484.8564 - mse: 11484.8564 - mae: 70.4254 - val_loss: 10692.4453 - val_mse: 10692.4453 - val_mae: 63.2559\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11378.7627 - mse: 11378.7627 - mae: 69.5025 - val_loss: 9639.2441 - val_mse: 9639.2441 - val_mae: 63.3716\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11253.2920 - mse: 11253.2920 - mae: 68.9612 - val_loss: 9485.7559 - val_mse: 9485.7559 - val_mae: 66.3315\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 11253.2920 mean_squared_error: 11253.2920 mean_absolute_error: 68.9612 val_loss: 9485.7559 val_mean_squared_error: 9485.7559 val_mean_absolute_error: 66.3315\n","Model: \"sequential_49\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_156 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_157 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_58 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_158 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_59 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_159 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 3ms/step - loss: 20186.5586 - mse: 20186.5586 - mae: 101.5892 - val_loss: 13466.2217 - val_mse: 13466.2217 - val_mae: 83.3140\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14133.4326 - mse: 14133.4326 - mae: 83.0257 - val_loss: 13168.2031 - val_mse: 13168.2031 - val_mae: 84.1828\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14106.1963 - mse: 14106.1963 - mae: 82.4578 - val_loss: 13354.3350 - val_mse: 13354.3350 - val_mae: 76.2505\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13968.0059 - mse: 13968.0059 - mae: 82.0275 - val_loss: 13802.2754 - val_mse: 13802.2754 - val_mae: 75.6591\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14043.1836 - mse: 14043.1836 - mae: 81.9977 - val_loss: 12968.2402 - val_mse: 12968.2402 - val_mae: 82.1238\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13986.5791 - mse: 13986.5791 - mae: 82.0867 - val_loss: 13273.0938 - val_mse: 13273.0938 - val_mae: 85.9618\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13904.3340 - mse: 13904.3340 - mae: 81.8586 - val_loss: 13334.1406 - val_mse: 13334.1406 - val_mae: 78.2362\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13958.4541 - mse: 13958.4541 - mae: 81.9607 - val_loss: 13067.1572 - val_mse: 13067.1572 - val_mae: 78.8772\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13968.4082 - mse: 13968.4082 - mae: 82.4130 - val_loss: 13147.2100 - val_mse: 13147.2100 - val_mae: 84.8006\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13758.6641 - mse: 13758.6641 - mae: 81.7369 - val_loss: 13096.8955 - val_mse: 13096.8955 - val_mae: 77.2547\n","Epoch 10: early stopping\n","163/163 [==============================] - 0s 911us/step\n","Epoch 10/10\n","8/8 loss: 13758.6641 mean_squared_error: 13758.6641 mean_absolute_error: 81.7369 val_loss: 13096.8955 val_mean_squared_error: 13096.8955 val_mean_absolute_error: 77.2547\n","Model: \"sequential_50\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_160 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_161 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 50875.3516 - mse: 50875.3516 - mae: 157.3303 - val_loss: 31271.1016 - val_mse: 31271.1016 - val_mae: 128.2322\n","163/163 [==============================] - 0s 914us/step\n","Epoch 1/1\n","12/12 loss: 50875.3516 mean_squared_error: 50875.3516 mean_absolute_error: 157.3303 val_loss: 31271.1016 val_mean_squared_error: 31271.1016 val_mean_absolute_error: 128.2322\n","Model: \"sequential_51\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_162 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_163 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 59304.6328 - mse: 59304.6289 - mae: 169.7150 - val_loss: 51822.4141 - val_mse: 51822.4141 - val_mae: 156.0841\n","163/163 [==============================] - 0s 857us/step\n","Epoch 1/1\n","12/12 loss: 59304.6328 mean_squared_error: 59304.6289 mean_absolute_error: 169.7150 val_loss: 51822.4141 val_mean_squared_error: 51822.4141 val_mean_absolute_error: 156.0841\n","Model: \"sequential_52\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_164 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_165 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 48172.1641 - mse: 48172.1641 - mae: 153.1798 - val_loss: 31150.0254 - val_mse: 31150.0254 - val_mae: 129.7139\n","163/163 [==============================] - 0s 870us/step\n","Epoch 1/1\n","12/12 loss: 48172.1641 mean_squared_error: 48172.1641 mean_absolute_error: 153.1798 val_loss: 31150.0254 val_mean_squared_error: 31150.0254 val_mean_absolute_error: 129.7139\n","Model: \"sequential_53\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_166 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_167 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 50959.6719 - mse: 50959.6719 - mae: 157.8523 - val_loss: 31422.1367 - val_mse: 31422.1367 - val_mae: 128.3293\n","163/163 [==============================] - 0s 924us/step\n","Epoch 1/1\n","12/12 loss: 50959.6719 mean_squared_error: 50959.6719 mean_absolute_error: 157.8523 val_loss: 31422.1367 val_mean_squared_error: 31422.1367 val_mean_absolute_error: 128.3293\n","Model: \"sequential_54\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_168 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_169 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 45309.5586 - mse: 45309.5586 - mae: 149.8771 - val_loss: 28781.6328 - val_mse: 28781.6367 - val_mae: 129.9627\n","163/163 [==============================] - 0s 912us/step\n","Epoch 1/1\n","12/12 loss: 45309.5586 mean_squared_error: 45309.5586 mean_absolute_error: 149.8771 val_loss: 28781.6328 val_mean_squared_error: 28781.6367 val_mean_absolute_error: 129.9627\n","Model: \"sequential_55\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_170 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_171 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_60 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_172 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 28998.9590 - mse: 28998.9590 - mae: 124.3990 - val_loss: 16893.1973 - val_mse: 16893.1973 - val_mae: 94.7107\n","163/163 [==============================] - 0s 957us/step\n","Epoch 1/1\n","12/12 loss: 28998.9590 mean_squared_error: 28998.9590 mean_absolute_error: 124.3990 val_loss: 16893.1973 val_mean_squared_error: 16893.1973 val_mean_absolute_error: 94.7107\n","Model: \"sequential_56\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_173 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_174 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_61 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_175 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 59223.2266 - mse: 59223.2266 - mae: 169.2249 - val_loss: 53500.1016 - val_mse: 53500.1016 - val_mae: 158.8175\n","163/163 [==============================] - 0s 920us/step\n","Epoch 1/1\n","12/12 loss: 59223.2266 mean_squared_error: 59223.2266 mean_absolute_error: 169.2249 val_loss: 53500.1016 val_mean_squared_error: 53500.1016 val_mean_absolute_error: 158.8175\n","Model: \"sequential_57\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_176 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_177 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_62 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_178 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 27829.5098 - mse: 27829.5098 - mae: 122.0403 - val_loss: 16343.5576 - val_mse: 16343.5576 - val_mae: 92.2406\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 27829.5098 mean_squared_error: 27829.5098 mean_absolute_error: 122.0403 val_loss: 16343.5576 val_mean_squared_error: 16343.5576 val_mean_absolute_error: 92.2406\n","Model: \"sequential_58\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_179 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_180 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_63 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_181 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 29493.4336 - mse: 29493.4336 - mae: 125.5586 - val_loss: 17364.9238 - val_mse: 17364.9238 - val_mae: 98.9075\n","163/163 [==============================] - 0s 933us/step\n","Epoch 1/1\n","12/12 loss: 29493.4336 mean_squared_error: 29493.4336 mean_absolute_error: 125.5586 val_loss: 17364.9238 val_mean_squared_error: 17364.9238 val_mean_absolute_error: 98.9075\n","Model: \"sequential_59\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_182 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_183 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_64 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_184 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 26434.4922 - mse: 26434.4922 - mae: 119.5778 - val_loss: 16726.2363 - val_mse: 16726.2363 - val_mae: 94.9885\n","163/163 [==============================] - 0s 970us/step\n","Epoch 1/1\n","12/12 loss: 26434.4922 mean_squared_error: 26434.4922 mean_absolute_error: 119.5778 val_loss: 16726.2363 val_mean_squared_error: 16726.2363 val_mean_absolute_error: 94.9885\n","Model: \"sequential_60\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_185 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_186 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_65 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_187 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_66 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_188 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 21843.2773 - mse: 21843.2773 - mae: 102.9659 - val_loss: 13544.2881 - val_mse: 13544.2881 - val_mae: 76.3083\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 21843.2773 mean_squared_error: 21843.2773 mean_absolute_error: 102.9659 val_loss: 13544.2881 val_mean_squared_error: 13544.2881 val_mean_absolute_error: 76.3083\n","Model: \"sequential_61\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_189 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_190 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_67 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_191 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_68 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_192 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 59242.1328 - mse: 59242.1328 - mae: 169.3217 - val_loss: 53672.9336 - val_mse: 53672.9336 - val_mae: 159.0958\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 59242.1328 mean_squared_error: 59242.1328 mean_absolute_error: 169.3217 val_loss: 53672.9336 val_mean_squared_error: 53672.9336 val_mean_absolute_error: 159.0958\n","Model: \"sequential_62\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_193 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_194 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_69 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_195 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_70 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_196 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 19932.9688 - mse: 19932.9688 - mae: 99.4027 - val_loss: 13120.5391 - val_mse: 13120.5391 - val_mae: 77.0277\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 19932.9688 mean_squared_error: 19932.9688 mean_absolute_error: 99.4027 val_loss: 13120.5391 val_mean_squared_error: 13120.5391 val_mean_absolute_error: 77.0277\n","Model: \"sequential_63\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_197 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_198 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_71 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_199 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_72 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_200 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 21779.8379 - mse: 21779.8379 - mae: 103.9521 - val_loss: 13382.8701 - val_mse: 13382.8701 - val_mae: 79.3924\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 21779.8379 mean_squared_error: 21779.8379 mean_absolute_error: 103.9521 val_loss: 13382.8701 val_mean_squared_error: 13382.8701 val_mean_absolute_error: 79.3924\n","Model: \"sequential_64\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_201 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_202 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_73 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_203 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_74 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_204 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 19570.1465 - mse: 19570.1465 - mae: 98.3223 - val_loss: 13277.4434 - val_mse: 13277.4424 - val_mae: 81.7541\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 19570.1465 mean_squared_error: 19570.1465 mean_absolute_error: 98.3223 val_loss: 13277.4434 val_mean_squared_error: 13277.4424 val_mean_absolute_error: 81.7541\n","Model: \"sequential_65\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_205 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_206 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_75 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_207 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 33194.8828 - mse: 33194.8906 - mae: 133.8468 - val_loss: 20344.3906 - val_mse: 20344.3906 - val_mae: 108.9646\n","163/163 [==============================] - 0s 938us/step\n","Epoch 1/1\n","12/12 loss: 33194.8828 mean_squared_error: 33194.8906 mean_absolute_error: 133.8468 val_loss: 20344.3906 val_mean_squared_error: 20344.3906 val_mean_absolute_error: 108.9646\n","Model: \"sequential_66\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_208 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_209 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_76 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_210 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 63272.4375 - mse: 63272.4375 - mae: 176.7053 - val_loss: 60175.9297 - val_mse: 60175.9297 - val_mae: 169.8264\n","163/163 [==============================] - 0s 971us/step\n","Epoch 1/1\n","12/12 loss: 63272.4375 mean_squared_error: 63272.4375 mean_absolute_error: 176.7053 val_loss: 60175.9297 val_mean_squared_error: 60175.9297 val_mean_absolute_error: 169.8264\n","Model: \"sequential_67\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_211 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_212 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_77 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_213 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 34443.2500 - mse: 34443.2500 - mae: 135.4186 - val_loss: 21522.6895 - val_mse: 21522.6895 - val_mae: 108.5387\n","163/163 [==============================] - 0s 959us/step\n","Epoch 1/1\n","12/12 loss: 34443.2500 mean_squared_error: 34443.2500 mean_absolute_error: 135.4186 val_loss: 21522.6895 val_mean_squared_error: 21522.6895 val_mean_absolute_error: 108.5387\n","Model: \"sequential_68\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_214 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_215 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_78 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_216 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 34148.3477 - mse: 34148.3477 - mae: 135.9312 - val_loss: 22455.4473 - val_mse: 22455.4473 - val_mae: 114.5184\n","163/163 [==============================] - 0s 978us/step\n","Epoch 1/1\n","12/12 loss: 34148.3477 mean_squared_error: 34148.3477 mean_absolute_error: 135.9312 val_loss: 22455.4473 val_mean_squared_error: 22455.4473 val_mean_absolute_error: 114.5184\n","Model: \"sequential_69\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_217 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_218 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_79 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_219 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 31927.7051 - mse: 31927.7051 - mae: 131.5495 - val_loss: 20389.2617 - val_mse: 20389.2617 - val_mae: 108.8688\n","163/163 [==============================] - 0s 879us/step\n","Epoch 1/1\n","12/12 loss: 31927.7051 mean_squared_error: 31927.7051 mean_absolute_error: 131.5495 val_loss: 20389.2617 val_mean_squared_error: 20389.2617 val_mean_absolute_error: 108.8688\n","Model: \"sequential_70\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_220 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_221 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_80 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_222 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_81 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_223 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 26481.4785 - mse: 26481.4785 - mae: 115.1959 - val_loss: 14226.5391 - val_mse: 14226.5391 - val_mae: 84.0727\n","163/163 [==============================] - 0s 942us/step\n","Epoch 1/1\n","12/12 loss: 26481.4785 mean_squared_error: 26481.4785 mean_absolute_error: 115.1959 val_loss: 14226.5391 val_mean_squared_error: 14226.5391 val_mean_absolute_error: 84.0727\n","Model: \"sequential_71\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_224 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_225 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_82 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_226 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_83 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_227 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 63635.5039 - mse: 63635.5117 - mae: 177.2222 - val_loss: 60668.4688 - val_mse: 60668.4688 - val_mae: 170.7067\n","163/163 [==============================] - 0s 956us/step\n","Epoch 1/1\n","12/12 loss: 63635.5039 mean_squared_error: 63635.5117 mean_absolute_error: 177.2222 val_loss: 60668.4688 val_mean_squared_error: 60668.4688 val_mean_absolute_error: 170.7067\n","Model: \"sequential_72\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_228 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_229 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_84 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_230 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_85 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_231 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 23732.3848 - mse: 23732.3848 - mae: 109.1695 - val_loss: 14672.6162 - val_mse: 14672.6162 - val_mae: 79.3212\n","163/163 [==============================] - 1s 2ms/step\n","Epoch 1/1\n","12/12 loss: 23732.3848 mean_squared_error: 23732.3848 mean_absolute_error: 109.1695 val_loss: 14672.6162 val_mean_squared_error: 14672.6162 val_mean_absolute_error: 79.3212\n","Model: \"sequential_73\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_232 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_233 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_86 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_234 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_87 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_235 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 5s 3ms/step - loss: 27125.3691 - mse: 27125.3691 - mae: 118.6357 - val_loss: 14819.2881 - val_mse: 14819.2881 - val_mae: 84.2399\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","12/12 loss: 27125.3691 mean_squared_error: 27125.3691 mean_absolute_error: 118.6357 val_loss: 14819.2881 val_mean_squared_error: 14819.2881 val_mean_absolute_error: 84.2399\n","Model: \"sequential_74\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_236 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_237 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_88 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_238 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_89 (Dropout)        (None, 32)                0         \n","                                                                 \n"," dense_239 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 5s 3ms/step - loss: 22554.3066 - mse: 22554.3066 - mae: 106.9504 - val_loss: 15914.6650 - val_mse: 15914.6650 - val_mae: 100.4099\n","163/163 [==============================] - 1s 2ms/step\n","Epoch 1/1\n","12/12 loss: 22554.3066 mean_squared_error: 22554.3066 mean_absolute_error: 106.9504 val_loss: 15914.6650 val_mean_squared_error: 15914.6650 val_mean_absolute_error: 100.4099\n","Model: \"sequential_75\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_240 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_241 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 49631.5156 - mse: 49631.5117 - mae: 155.1863 - val_loss: 30757.3672 - val_mse: 30757.3672 - val_mae: 128.2141\n","Epoch 2/10\n","710/710 [==============================] - -1s -802us/step - loss: 27581.0527 - mse: 27581.0527 - mae: 126.7377 - val_loss: 25672.5098 - val_mse: 25672.5098 - val_mae: 122.5194\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23353.8379 - mse: 23353.8379 - mae: 116.2366 - val_loss: 21597.4043 - val_mse: 21597.4043 - val_mae: 112.0180\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 19883.9941 - mse: 19883.9941 - mae: 105.1252 - val_loss: 18723.3320 - val_mse: 18723.3320 - val_mae: 102.6608\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17588.1367 - mse: 17588.1367 - mae: 97.1138 - val_loss: 16937.3301 - val_mse: 16937.3301 - val_mae: 96.1554\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16199.2910 - mse: 16199.2910 - mae: 91.9967 - val_loss: 15855.7168 - val_mse: 15855.7168 - val_mae: 90.8616\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15321.8389 - mse: 15321.8389 - mae: 88.4483 - val_loss: 15092.1309 - val_mse: 15092.1309 - val_mae: 88.7738\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14692.8916 - mse: 14692.8916 - mae: 85.9267 - val_loss: 14583.9893 - val_mse: 14583.9893 - val_mae: 85.4978\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14240.4180 - mse: 14240.4180 - mae: 84.1159 - val_loss: 14152.8711 - val_mse: 14152.8711 - val_mae: 84.2868\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13905.7900 - mse: 13905.7900 - mae: 82.7915 - val_loss: 13840.7520 - val_mse: 13840.7520 - val_mae: 82.8662\n","163/163 [==============================] - 0s 986us/step\n","Epoch 10/10\n","12/12 loss: 13905.7900 mean_squared_error: 13905.7900 mean_absolute_error: 82.7915 val_loss: 13840.7520 val_mean_squared_error: 13840.7520 val_mean_absolute_error: 82.8662\n","Model: \"sequential_76\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_242 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_243 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 59286.0664 - mse: 59286.0664 - mae: 169.7386 - val_loss: 51760.9023 - val_mse: 51760.9023 - val_mae: 155.9714\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 46184.0508 - mse: 46184.0508 - mae: 148.5473 - val_loss: 42856.1445 - val_mse: 42856.1445 - val_mae: 143.8410\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 39484.4336 - mse: 39484.4336 - mae: 140.6078 - val_loss: 37770.9648 - val_mse: 37770.9648 - val_mae: 138.4220\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 35015.4023 - mse: 35015.4023 - mae: 133.2531 - val_loss: 33146.3203 - val_mse: 33146.3203 - val_mae: 125.8111\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 30154.7578 - mse: 30154.7578 - mae: 118.5267 - val_loss: 28547.0312 - val_mse: 28547.0312 - val_mae: 112.6195\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 26150.0781 - mse: 26150.0781 - mae: 107.8059 - val_loss: 25115.0684 - val_mse: 25115.0684 - val_mae: 105.9014\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23146.9980 - mse: 23146.9980 - mae: 101.0006 - val_loss: 22451.0137 - val_mse: 22451.0137 - val_mae: 99.2161\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20720.8848 - mse: 20720.8848 - mae: 95.4315 - val_loss: 20239.9414 - val_mse: 20239.9414 - val_mae: 93.6456\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18673.7246 - mse: 18673.7246 - mae: 90.4608 - val_loss: 18299.4199 - val_mse: 18299.4199 - val_mae: 89.4503\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16949.6504 - mse: 16949.6504 - mae: 86.1841 - val_loss: 16685.5000 - val_mse: 16685.5000 - val_mae: 85.5264\n","163/163 [==============================] - 0s 925us/step\n","Epoch 10/10\n","12/12 loss: 16949.6504 mean_squared_error: 16949.6504 mean_absolute_error: 86.1841 val_loss: 16685.5000 val_mean_squared_error: 16685.5000 val_mean_absolute_error: 85.5264\n","Model: \"sequential_77\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_244 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_245 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 48874.3945 - mse: 48874.3945 - mae: 153.5627 - val_loss: 31936.9688 - val_mse: 31936.9707 - val_mae: 130.1520\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 28838.1504 - mse: 28838.1504 - mae: 130.0151 - val_loss: 27294.5488 - val_mse: 27294.5488 - val_mae: 127.1339\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 24174.5273 - mse: 24174.5273 - mae: 117.7385 - val_loss: 21779.9648 - val_mse: 21779.9648 - val_mae: 109.8609\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19732.5918 - mse: 19732.5918 - mae: 104.3192 - val_loss: 18330.6738 - val_mse: 18330.6738 - val_mae: 99.4728\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17054.6387 - mse: 17054.6387 - mae: 94.7514 - val_loss: 16278.7549 - val_mse: 16278.7549 - val_mae: 93.3040\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15508.6309 - mse: 15508.6309 - mae: 89.0229 - val_loss: 15101.0889 - val_mse: 15101.0889 - val_mae: 88.4918\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14601.3398 - mse: 14601.3398 - mae: 85.4612 - val_loss: 14393.6748 - val_mse: 14393.6748 - val_mae: 84.8189\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14027.4492 - mse: 14027.4502 - mae: 83.1490 - val_loss: 13875.6035 - val_mse: 13875.6035 - val_mae: 83.9747\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13626.1250 - mse: 13626.1250 - mae: 81.7569 - val_loss: 13527.0996 - val_mse: 13527.0996 - val_mae: 82.2527\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13352.2646 - mse: 13352.2646 - mae: 80.6059 - val_loss: 13284.4600 - val_mse: 13284.4609 - val_mae: 82.5539\n","163/163 [==============================] - 0s 862us/step\n","Epoch 10/10\n","12/12 loss: 13352.2646 mean_squared_error: 13352.2646 mean_absolute_error: 80.6059 val_loss: 13284.4600 val_mean_squared_error: 13284.4609 val_mean_absolute_error: 82.5539\n","Model: \"sequential_78\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_246 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_247 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 50728.2383 - mse: 50728.2383 - mae: 157.0090 - val_loss: 31304.0137 - val_mse: 31304.0137 - val_mae: 128.1376\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27462.1816 - mse: 27462.1816 - mae: 125.9233 - val_loss: 25220.0645 - val_mse: 25220.0645 - val_mae: 121.5057\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 22833.4824 - mse: 22833.4824 - mae: 114.6635 - val_loss: 21103.9277 - val_mse: 21103.9277 - val_mae: 107.5839\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19382.3340 - mse: 19382.3340 - mae: 103.2927 - val_loss: 18358.3711 - val_mse: 18358.3711 - val_mae: 99.0890\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17267.8457 - mse: 17267.8457 - mae: 95.9370 - val_loss: 16766.6758 - val_mse: 16766.6758 - val_mae: 93.1522\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16003.9512 - mse: 16003.9512 - mae: 91.0734 - val_loss: 15702.6064 - val_mse: 15702.6064 - val_mae: 89.9458\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15159.7754 - mse: 15159.7754 - mae: 87.8708 - val_loss: 14974.3516 - val_mse: 14974.3516 - val_mae: 86.9974\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14562.3643 - mse: 14562.3643 - mae: 85.2695 - val_loss: 14401.2949 - val_mse: 14401.2949 - val_mae: 85.8063\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14105.7285 - mse: 14105.7285 - mae: 83.6006 - val_loss: 13992.3828 - val_mse: 13992.3828 - val_mae: 84.0438\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13767.8594 - mse: 13767.8594 - mae: 82.3237 - val_loss: 13672.3887 - val_mse: 13672.3887 - val_mae: 82.8113\n","163/163 [==============================] - 0s 860us/step\n","Epoch 10/10\n","12/12 loss: 13767.8594 mean_squared_error: 13767.8594 mean_absolute_error: 82.3237 val_loss: 13672.3887 val_mean_squared_error: 13672.3887 val_mean_absolute_error: 82.8113\n","Model: \"sequential_79\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_248 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_249 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 44921.9102 - mse: 44921.9062 - mae: 147.6908 - val_loss: 28634.6484 - val_mse: 28634.6426 - val_mae: 129.4765\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 26840.2070 - mse: 26840.2070 - mae: 127.0513 - val_loss: 25600.7539 - val_mse: 25600.7539 - val_mae: 125.0983\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23978.1465 - mse: 23978.1484 - mae: 119.8500 - val_loss: 22767.1680 - val_mse: 22767.1680 - val_mae: 117.1844\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 21294.5547 - mse: 21294.5547 - mae: 111.8521 - val_loss: 20211.5898 - val_mse: 20211.5898 - val_mae: 108.1258\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19003.3105 - mse: 19003.3105 - mae: 103.3189 - val_loss: 18206.9082 - val_mse: 18206.9082 - val_mae: 101.3871\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17340.3066 - mse: 17340.3066 - mae: 96.7951 - val_loss: 16844.1836 - val_mse: 16844.1836 - val_mae: 96.9172\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16211.0908 - mse: 16211.0908 - mae: 92.5785 - val_loss: 15962.3701 - val_mse: 15962.3711 - val_mae: 90.8242\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15430.0596 - mse: 15430.0596 - mae: 88.8290 - val_loss: 15235.8477 - val_mse: 15235.8477 - val_mae: 88.6736\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14863.6094 - mse: 14863.6094 - mae: 86.4914 - val_loss: 14714.4512 - val_mse: 14714.4512 - val_mae: 86.6909\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14419.8672 - mse: 14419.8672 - mae: 84.6503 - val_loss: 14323.4512 - val_mse: 14323.4512 - val_mae: 85.0582\n","163/163 [==============================] - 0s 906us/step\n","Epoch 10/10\n","12/12 loss: 14419.8672 mean_squared_error: 14419.8672 mean_absolute_error: 84.6503 val_loss: 14323.4512 val_mean_squared_error: 14323.4512 val_mean_absolute_error: 85.0582\n","Model: \"sequential_80\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_250 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_251 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_90 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_252 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 3ms/step - loss: 29792.0801 - mse: 29792.0801 - mae: 125.8909 - val_loss: 17511.9570 - val_mse: 17511.9570 - val_mae: 98.9315\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15779.5664 - mse: 15779.5664 - mae: 88.4565 - val_loss: 13983.9678 - val_mse: 13983.9678 - val_mae: 82.5966\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13990.3564 - mse: 13990.3564 - mae: 81.8084 - val_loss: 13538.5674 - val_mse: 13538.5684 - val_mae: 86.3330\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13663.7705 - mse: 13663.7705 - mae: 80.4096 - val_loss: 12834.4062 - val_mse: 12834.4062 - val_mae: 79.8894\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13360.3232 - mse: 13360.3232 - mae: 79.3446 - val_loss: 12621.6211 - val_mse: 12621.6211 - val_mae: 76.5208\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13019.7207 - mse: 13019.7207 - mae: 78.1115 - val_loss: 12304.3135 - val_mse: 12304.3135 - val_mae: 75.6601\n","Epoch 7/10\n","710/710 [==============================] - 2s 3ms/step - loss: 12768.4316 - mse: 12768.4316 - mae: 76.8170 - val_loss: 12053.9971 - val_mse: 12053.9971 - val_mae: 74.8117\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12470.2598 - mse: 12470.2598 - mae: 75.7862 - val_loss: 11888.1738 - val_mse: 11888.1738 - val_mae: 72.4295\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12318.7305 - mse: 12318.7305 - mae: 74.5551 - val_loss: 11583.4727 - val_mse: 11583.4727 - val_mae: 72.3185\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12056.3516 - mse: 12056.3516 - mae: 73.4466 - val_loss: 11348.2129 - val_mse: 11348.2129 - val_mae: 71.4292\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","12/12 loss: 12056.3516 mean_squared_error: 12056.3516 mean_absolute_error: 73.4466 val_loss: 11348.2129 val_mean_squared_error: 11348.2129 val_mean_absolute_error: 71.4292\n","Model: \"sequential_81\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_253 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_254 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_91 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_255 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 59258.8477 - mse: 59258.8398 - mae: 169.1562 - val_loss: 53541.0898 - val_mse: 53541.0898 - val_mae: 158.8835\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 48128.3594 - mse: 48128.3594 - mae: 151.3213 - val_loss: 44754.0547 - val_mse: 44754.0547 - val_mae: 146.4563\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 40053.2656 - mse: 40053.2656 - mae: 134.2609 - val_loss: 36576.0156 - val_mse: 36576.0234 - val_mae: 122.7411\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 32842.0859 - mse: 32842.0859 - mae: 114.1209 - val_loss: 30334.3789 - val_mse: 30334.3750 - val_mae: 107.2013\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27141.5078 - mse: 27141.5078 - mae: 99.1683 - val_loss: 25390.0996 - val_mse: 25390.0996 - val_mae: 96.3164\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 22897.6602 - mse: 22897.6602 - mae: 89.6265 - val_loss: 21562.1211 - val_mse: 21562.1211 - val_mae: 85.9523\n","Epoch 7/10\n","710/710 [==============================] - 2s 3ms/step - loss: 19623.4609 - mse: 19623.4609 - mae: 82.9594 - val_loss: 18687.8730 - val_mse: 18687.8730 - val_mae: 80.1394\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17369.6309 - mse: 17369.6309 - mae: 78.9052 - val_loss: 16687.0781 - val_mse: 16687.0781 - val_mae: 77.5238\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15579.8711 - mse: 15579.8711 - mae: 75.4856 - val_loss: 14920.7256 - val_mse: 14920.7256 - val_mae: 72.6439\n","Epoch 10/10\n","710/710 [==============================] - 2s 3ms/step - loss: 14327.0986 - mse: 14327.0986 - mae: 73.3303 - val_loss: 13779.9316 - val_mse: 13779.9316 - val_mae: 72.0858\n","163/163 [==============================] - 0s 981us/step\n","Epoch 10/10\n","12/12 loss: 14327.0986 mean_squared_error: 14327.0986 mean_absolute_error: 73.3303 val_loss: 13779.9316 val_mean_squared_error: 13779.9316 val_mean_absolute_error: 72.0858\n","Model: \"sequential_82\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_256 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_257 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_92 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_258 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 29246.5840 - mse: 29246.5840 - mae: 124.7753 - val_loss: 16714.5781 - val_mse: 16714.5781 - val_mae: 97.2439\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15068.0234 - mse: 15068.0234 - mae: 86.4319 - val_loss: 13487.3369 - val_mse: 13487.3369 - val_mae: 79.2568\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13517.7822 - mse: 13517.7822 - mae: 80.8297 - val_loss: 12594.4238 - val_mse: 12594.4238 - val_mae: 78.9290\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12897.6719 - mse: 12897.6719 - mae: 78.7025 - val_loss: 12236.8330 - val_mse: 12236.8330 - val_mae: 75.5946\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12378.6299 - mse: 12378.6299 - mae: 76.6437 - val_loss: 11741.6064 - val_mse: 11741.6064 - val_mae: 74.7076\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 12081.9072 - mse: 12081.9072 - mae: 74.4042 - val_loss: 11446.1182 - val_mse: 11446.1182 - val_mae: 69.5330\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11434.8525 - mse: 11434.8525 - mae: 71.8077 - val_loss: 10871.4893 - val_mse: 10871.4893 - val_mae: 70.5702\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11196.8564 - mse: 11196.8564 - mae: 70.7662 - val_loss: 10842.9385 - val_mse: 10842.9385 - val_mae: 67.6032\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 10991.8975 - mse: 10991.8975 - mae: 70.0015 - val_loss: 10509.5996 - val_mse: 10509.5996 - val_mae: 68.3030\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10828.4209 - mse: 10828.4209 - mae: 69.2834 - val_loss: 10408.7412 - val_mse: 10408.7412 - val_mae: 70.0499\n","163/163 [==============================] - 0s 971us/step\n","Epoch 10/10\n","12/12 loss: 10828.4209 mean_squared_error: 10828.4209 mean_absolute_error: 69.2834 val_loss: 10408.7412 val_mean_squared_error: 10408.7412 val_mean_absolute_error: 70.0499\n","Model: \"sequential_83\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_259 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_260 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_93 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_261 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 3ms/step - loss: 29273.0781 - mse: 29273.0762 - mae: 124.9357 - val_loss: 17245.7793 - val_mse: 17245.7793 - val_mae: 96.2627\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 15616.4277 - mse: 15616.4277 - mae: 87.7990 - val_loss: 14333.8984 - val_mse: 14333.8984 - val_mae: 79.9346\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14029.4219 - mse: 14029.4219 - mae: 81.8060 - val_loss: 13182.4131 - val_mse: 13182.4131 - val_mae: 79.2190\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13697.1875 - mse: 13697.1875 - mae: 80.4439 - val_loss: 12914.1504 - val_mse: 12914.1504 - val_mae: 77.4698\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13334.4756 - mse: 13334.4756 - mae: 79.2915 - val_loss: 12763.1719 - val_mse: 12763.1719 - val_mae: 75.9924\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13175.3906 - mse: 13175.3906 - mae: 78.7518 - val_loss: 12395.9648 - val_mse: 12395.9648 - val_mae: 77.1222\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12825.4258 - mse: 12825.4258 - mae: 77.4333 - val_loss: 12221.8203 - val_mse: 12221.8203 - val_mae: 76.1061\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 12711.9238 - mse: 12711.9238 - mae: 76.9127 - val_loss: 12043.8096 - val_mse: 12043.8096 - val_mae: 73.9587\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12385.3135 - mse: 12385.3135 - mae: 75.4078 - val_loss: 11819.5615 - val_mse: 11819.5615 - val_mae: 74.6303\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12177.2256 - mse: 12177.2256 - mae: 74.7733 - val_loss: 11711.6846 - val_mse: 11711.6846 - val_mae: 72.4366\n","163/163 [==============================] - 0s 919us/step\n","Epoch 10/10\n","12/12 loss: 12177.2256 mean_squared_error: 12177.2256 mean_absolute_error: 74.7733 val_loss: 11711.6846 val_mean_squared_error: 11711.6846 val_mean_absolute_error: 72.4366\n","Model: \"sequential_84\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_262 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_263 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_94 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_264 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 3ms/step - loss: 27935.1738 - mse: 27935.1738 - mae: 123.2869 - val_loss: 17256.1133 - val_mse: 17256.1133 - val_mae: 97.9343\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15250.8965 - mse: 15250.8965 - mae: 88.1426 - val_loss: 13953.5898 - val_mse: 13953.5898 - val_mae: 82.4057\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13636.9004 - mse: 13636.9004 - mae: 81.7081 - val_loss: 13308.1631 - val_mse: 13308.1631 - val_mae: 79.3042\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13476.7744 - mse: 13476.7744 - mae: 80.9565 - val_loss: 13035.1396 - val_mse: 13035.1396 - val_mae: 79.8948\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13314.4297 - mse: 13314.4287 - mae: 80.4002 - val_loss: 13804.5186 - val_mse: 13804.5186 - val_mae: 90.5803\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13387.0352 - mse: 13387.0352 - mae: 80.6564 - val_loss: 12986.6006 - val_mse: 12986.6006 - val_mae: 82.5908\n","Epoch 7/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13370.8291 - mse: 13370.8291 - mae: 80.3836 - val_loss: 13683.5625 - val_mse: 13683.5625 - val_mae: 89.6833\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13355.7705 - mse: 13355.7705 - mae: 80.3902 - val_loss: 13077.7930 - val_mse: 13077.7930 - val_mae: 78.0614\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13364.4766 - mse: 13364.4766 - mae: 80.4871 - val_loss: 13064.2715 - val_mse: 13064.2715 - val_mae: 77.7369\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13450.7715 - mse: 13450.7715 - mae: 80.8909 - val_loss: 12932.1230 - val_mse: 12932.1230 - val_mae: 79.2670\n","163/163 [==============================] - 0s 969us/step\n","Epoch 10/10\n","12/12 loss: 13450.7715 mean_squared_error: 13450.7715 mean_absolute_error: 80.8909 val_loss: 12932.1230 val_mean_squared_error: 12932.1230 val_mean_absolute_error: 79.2670\n","Model: \"sequential_85\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_265 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_266 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_95 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_267 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_96 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_268 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 21757.2559 - mse: 21757.2559 - mae: 103.9859 - val_loss: 13305.8770 - val_mse: 13305.8770 - val_mae: 80.0454\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13698.5400 - mse: 13698.5400 - mae: 80.4044 - val_loss: 12542.4824 - val_mse: 12542.4824 - val_mae: 77.1729\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13113.8584 - mse: 13113.8574 - mae: 77.9883 - val_loss: 11708.0879 - val_mse: 11708.0879 - val_mae: 72.0665\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12220.3711 - mse: 12220.3711 - mae: 74.3362 - val_loss: 12712.1250 - val_mse: 12712.1250 - val_mae: 67.6281\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11381.3916 - mse: 11381.3916 - mae: 70.9628 - val_loss: 10326.9121 - val_mse: 10326.9121 - val_mae: 66.2416\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11094.1592 - mse: 11094.1592 - mae: 69.3152 - val_loss: 9956.6025 - val_mse: 9956.6025 - val_mae: 69.2209\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10655.6250 - mse: 10655.6250 - mae: 68.0144 - val_loss: 9689.4580 - val_mse: 9689.4580 - val_mae: 66.8716\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10498.6133 - mse: 10498.6133 - mae: 67.3039 - val_loss: 9356.7744 - val_mse: 9356.7744 - val_mae: 66.2503\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10229.6162 - mse: 10229.6162 - mae: 66.3316 - val_loss: 9986.0537 - val_mse: 9986.0537 - val_mae: 62.6991\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10167.6953 - mse: 10167.6953 - mae: 65.4382 - val_loss: 8947.9043 - val_mse: 8947.9043 - val_mae: 62.0380\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 10167.6953 mean_squared_error: 10167.6953 mean_absolute_error: 65.4382 val_loss: 8947.9043 val_mean_squared_error: 8947.9043 val_mean_absolute_error: 62.0380\n","Model: \"sequential_86\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_269 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_270 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_97 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_271 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_98 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_272 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 59122.2305 - mse: 59122.2305 - mae: 169.0994 - val_loss: 53602.4453 - val_mse: 53602.4453 - val_mae: 158.9863\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 48207.3164 - mse: 48207.3164 - mae: 151.5400 - val_loss: 44851.5273 - val_mse: 44851.5273 - val_mae: 146.5981\n","Epoch 3/10\n","710/710 [==============================] - 2s 2ms/step - loss: 41284.6328 - mse: 41284.6328 - mae: 142.7866 - val_loss: 39384.8711 - val_mse: 39384.8711 - val_mae: 140.7837\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 33998.8281 - mse: 33998.8281 - mae: 118.3420 - val_loss: 30746.4707 - val_mse: 30746.4688 - val_mae: 106.4723\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27732.2012 - mse: 27732.2031 - mae: 100.6442 - val_loss: 25782.5645 - val_mse: 25782.5645 - val_mae: 96.2647\n","Epoch 6/10\n","710/710 [==============================] - 2s 2ms/step - loss: 23086.4180 - mse: 23086.4180 - mae: 89.6263 - val_loss: 21765.0625 - val_mse: 21765.0645 - val_mae: 86.9500\n","Epoch 7/10\n","710/710 [==============================] - 2s 2ms/step - loss: 19988.6914 - mse: 19988.6914 - mae: 83.8690 - val_loss: 18639.2949 - val_mse: 18639.2949 - val_mae: 78.3074\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 17308.5820 - mse: 17308.5820 - mae: 77.7388 - val_loss: 16160.1680 - val_mse: 16160.1680 - val_mae: 71.2872\n","Epoch 9/10\n","710/710 [==============================] - 2s 2ms/step - loss: 15075.0098 - mse: 15075.0098 - mae: 72.0245 - val_loss: 13664.6221 - val_mse: 13664.6221 - val_mae: 64.5471\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12938.6553 - mse: 12938.6572 - mae: 66.2414 - val_loss: 11513.1914 - val_mse: 11513.1914 - val_mae: 58.3281\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 12938.6553 mean_squared_error: 12938.6572 mean_absolute_error: 66.2414 val_loss: 11513.1914 val_mean_squared_error: 11513.1914 val_mean_absolute_error: 58.3281\n","Model: \"sequential_87\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_273 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_274 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_99 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_275 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_100 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_276 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 19394.5840 - mse: 19394.5840 - mae: 98.3663 - val_loss: 12986.0625 - val_mse: 12986.0625 - val_mae: 82.4382\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13118.3789 - mse: 13118.3789 - mae: 78.8724 - val_loss: 12204.7021 - val_mse: 12204.7021 - val_mae: 81.6235\n","Epoch 3/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12060.8213 - mse: 12060.8213 - mae: 74.4212 - val_loss: 10682.6855 - val_mse: 10682.6855 - val_mae: 69.9240\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11087.7842 - mse: 11087.7842 - mae: 70.7373 - val_loss: 10084.0645 - val_mse: 10084.0645 - val_mae: 68.0114\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10795.5537 - mse: 10795.5537 - mae: 69.8815 - val_loss: 10564.4932 - val_mse: 10564.4932 - val_mae: 72.3280\n","Epoch 6/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10627.8223 - mse: 10627.8223 - mae: 69.3893 - val_loss: 9904.2930 - val_mse: 9904.2930 - val_mae: 68.4703\n","Epoch 7/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10247.7314 - mse: 10247.7314 - mae: 67.8833 - val_loss: 9888.4219 - val_mse: 9888.4219 - val_mae: 65.7783\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10510.6758 - mse: 10510.6758 - mae: 68.6864 - val_loss: 9654.1152 - val_mse: 9654.1152 - val_mae: 65.6310\n","Epoch 9/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10365.5654 - mse: 10365.5654 - mae: 67.9165 - val_loss: 9560.7139 - val_mse: 9560.7139 - val_mae: 63.7937\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 10203.4736 - mse: 10203.4736 - mae: 67.1240 - val_loss: 9754.3027 - val_mse: 9754.3027 - val_mae: 70.3346\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 10203.4736 mean_squared_error: 10203.4736 mean_absolute_error: 67.1240 val_loss: 9754.3027 val_mean_squared_error: 9754.3027 val_mean_absolute_error: 70.3346\n","Model: \"sequential_88\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_277 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_278 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_101 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_279 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_102 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_280 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 21228.0840 - mse: 21228.0840 - mae: 101.7804 - val_loss: 13491.7920 - val_mse: 13491.7920 - val_mae: 86.1626\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13480.9062 - mse: 13480.9062 - mae: 79.0584 - val_loss: 13649.6406 - val_mse: 13649.6406 - val_mae: 91.9846\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12293.1064 - mse: 12293.1074 - mae: 74.5692 - val_loss: 10980.9326 - val_mse: 10980.9326 - val_mae: 74.2573\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11456.9473 - mse: 11456.9473 - mae: 71.2182 - val_loss: 10142.8574 - val_mse: 10142.8574 - val_mae: 69.1416\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10868.4902 - mse: 10868.4902 - mae: 69.1218 - val_loss: 9718.1260 - val_mse: 9718.1260 - val_mae: 64.4191\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10575.7646 - mse: 10575.7637 - mae: 67.9209 - val_loss: 10433.1562 - val_mse: 10433.1562 - val_mae: 62.3362\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10243.4785 - mse: 10243.4785 - mae: 66.2627 - val_loss: 9240.4717 - val_mse: 9240.4717 - val_mae: 61.0890\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10152.3516 - mse: 10152.3516 - mae: 65.7149 - val_loss: 9402.9453 - val_mse: 9402.9453 - val_mae: 68.0084\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 9813.6494 - mse: 9813.6494 - mae: 64.4300 - val_loss: 8779.0127 - val_mse: 8779.0127 - val_mae: 62.2440\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 9657.9502 - mse: 9657.9502 - mae: 63.7288 - val_loss: 8854.1436 - val_mse: 8854.1436 - val_mae: 58.5349\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 9657.9502 mean_squared_error: 9657.9502 mean_absolute_error: 63.7288 val_loss: 8854.1436 val_mean_squared_error: 8854.1436 val_mean_absolute_error: 58.5349\n","Model: \"sequential_89\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_281 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_282 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_103 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_283 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_104 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_284 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 19541.9805 - mse: 19541.9805 - mae: 98.2253 - val_loss: 13172.7734 - val_mse: 13172.7764 - val_mae: 81.8788\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13887.3574 - mse: 13887.3574 - mae: 81.9052 - val_loss: 13001.9463 - val_mse: 13001.9463 - val_mae: 78.7027\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13778.2666 - mse: 13778.2666 - mae: 81.6791 - val_loss: 12962.4053 - val_mse: 12962.4053 - val_mae: 79.7872\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13840.9189 - mse: 13840.9189 - mae: 81.7202 - val_loss: 13507.2354 - val_mse: 13507.2354 - val_mae: 78.0434\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13684.3818 - mse: 13684.3818 - mae: 82.0191 - val_loss: 12967.6611 - val_mse: 12967.6611 - val_mae: 82.8141\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13770.4795 - mse: 13770.4795 - mae: 81.5521 - val_loss: 12938.7148 - val_mse: 12938.7158 - val_mae: 80.5059\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13821.4502 - mse: 13821.4502 - mae: 82.0253 - val_loss: 13502.1191 - val_mse: 13502.1191 - val_mae: 77.0329\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13604.7588 - mse: 13604.7588 - mae: 81.0779 - val_loss: 13158.2705 - val_mse: 13158.2705 - val_mae: 77.7915\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13768.5215 - mse: 13768.5225 - mae: 81.4347 - val_loss: 13502.6152 - val_mse: 13502.6172 - val_mae: 78.9457\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13665.3555 - mse: 13665.3555 - mae: 81.1082 - val_loss: 12929.6689 - val_mse: 12929.6689 - val_mae: 79.3756\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 13665.3555 mean_squared_error: 13665.3555 mean_absolute_error: 81.1082 val_loss: 12929.6689 val_mean_squared_error: 12929.6689 val_mean_absolute_error: 79.3756\n","Model: \"sequential_90\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_285 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_286 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_105 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_287 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 36077.0273 - mse: 36077.0273 - mae: 138.3624 - val_loss: 22514.5312 - val_mse: 22514.5312 - val_mae: 115.0303\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 19335.8555 - mse: 19335.8555 - mae: 102.1269 - val_loss: 16174.2158 - val_mse: 16174.2158 - val_mae: 88.3795\n","Epoch 3/10\n","710/710 [==============================] - 2s 2ms/step - loss: 15821.7168 - mse: 15821.7168 - mae: 87.8202 - val_loss: 14141.4131 - val_mse: 14141.4131 - val_mae: 85.1814\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14870.7588 - mse: 14870.7588 - mae: 84.0476 - val_loss: 13443.9287 - val_mse: 13443.9287 - val_mae: 80.3755\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14390.5508 - mse: 14390.5508 - mae: 82.0849 - val_loss: 13075.0059 - val_mse: 13075.0059 - val_mae: 79.3673\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 14197.6553 - mse: 14197.6553 - mae: 81.4549 - val_loss: 12879.7188 - val_mse: 12879.7188 - val_mae: 77.9090\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14020.4150 - mse: 14020.4150 - mae: 81.0432 - val_loss: 12719.7969 - val_mse: 12719.7969 - val_mae: 77.3623\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13798.9502 - mse: 13798.9502 - mae: 80.2566 - val_loss: 12532.6973 - val_mse: 12532.6973 - val_mae: 76.0664\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13651.3750 - mse: 13651.3750 - mae: 79.7027 - val_loss: 12388.6328 - val_mse: 12388.6328 - val_mae: 75.1877\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13573.9072 - mse: 13573.9072 - mae: 79.1613 - val_loss: 12460.7559 - val_mse: 12460.7559 - val_mae: 73.0901\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 13573.9072 mean_squared_error: 13573.9072 mean_absolute_error: 79.1613 val_loss: 12460.7559 val_mean_squared_error: 12460.7559 val_mean_absolute_error: 73.0901\n","Model: \"sequential_91\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_288 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_289 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_106 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_290 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 63392.7031 - mse: 63392.7031 - mae: 176.8653 - val_loss: 60281.6836 - val_mse: 60281.6836 - val_mae: 170.0140\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 56290.4961 - mse: 56290.4961 - mae: 163.8322 - val_loss: 54051.1250 - val_mse: 54051.1250 - val_mae: 159.6834\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 50715.8789 - mse: 50715.8789 - mae: 155.0200 - val_loss: 48987.8945 - val_mse: 48987.8945 - val_mae: 152.1254\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 46234.8867 - mse: 46234.8867 - mae: 148.8170 - val_loss: 44883.0156 - val_mse: 44883.0156 - val_mae: 146.6138\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 41654.8516 - mse: 41654.8516 - mae: 136.0323 - val_loss: 39803.5977 - val_mse: 39803.5977 - val_mae: 127.9641\n","Epoch 6/10\n","710/710 [==============================] - 2s 2ms/step - loss: 37201.4023 - mse: 37201.4023 - mae: 123.2574 - val_loss: 35877.7656 - val_mse: 35877.7656 - val_mae: 119.0785\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 33562.5664 - mse: 33562.5664 - mae: 114.6182 - val_loss: 32237.2500 - val_mse: 32237.2500 - val_mae: 109.5157\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 30131.3477 - mse: 30131.3477 - mae: 105.2802 - val_loss: 29059.1621 - val_mse: 29059.1621 - val_mae: 101.0099\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 27201.5938 - mse: 27201.5938 - mae: 98.4630 - val_loss: 26306.7285 - val_mse: 26306.7246 - val_mae: 95.1851\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 24821.5859 - mse: 24821.5859 - mae: 93.2898 - val_loss: 23946.4102 - val_mse: 23946.4102 - val_mae: 89.8966\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 24821.5859 mean_squared_error: 24821.5859 mean_absolute_error: 93.2898 val_loss: 23946.4102 val_mean_squared_error: 23946.4102 val_mean_absolute_error: 89.8966\n","Model: \"sequential_92\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_291 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_292 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_107 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_293 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 3ms/step - loss: 32995.1680 - mse: 32995.1680 - mae: 133.1929 - val_loss: 20570.9590 - val_mse: 20570.9590 - val_mae: 104.3281\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 16963.7520 - mse: 16963.7520 - mae: 93.7298 - val_loss: 14420.8916 - val_mse: 14420.8916 - val_mae: 86.0561\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14342.8096 - mse: 14342.8096 - mae: 83.9778 - val_loss: 13321.2861 - val_mse: 13321.2861 - val_mae: 83.0137\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13927.1748 - mse: 13927.1748 - mae: 82.0457 - val_loss: 12930.2627 - val_mse: 12930.2627 - val_mae: 77.7030\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13363.4443 - mse: 13363.4443 - mae: 80.2356 - val_loss: 12533.9111 - val_mse: 12533.9111 - val_mae: 78.1761\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13095.9492 - mse: 13095.9492 - mae: 79.2633 - val_loss: 12375.4082 - val_mse: 12375.4082 - val_mae: 78.4005\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12885.9863 - mse: 12885.9863 - mae: 78.2707 - val_loss: 12093.8535 - val_mse: 12093.8535 - val_mae: 76.4737\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12527.1738 - mse: 12527.1738 - mae: 77.3352 - val_loss: 11837.8721 - val_mse: 11837.8721 - val_mae: 77.0001\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 12389.8838 - mse: 12389.8857 - mae: 76.0355 - val_loss: 11555.3730 - val_mse: 11555.3730 - val_mae: 75.3940\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12161.8828 - mse: 12161.8848 - mae: 74.4363 - val_loss: 11290.0166 - val_mse: 11290.0166 - val_mae: 70.7506\n","163/163 [==============================] - 0s 942us/step\n","Epoch 10/10\n","12/12 loss: 12161.8828 mean_squared_error: 12161.8848 mean_absolute_error: 74.4363 val_loss: 11290.0166 val_mean_squared_error: 11290.0166 val_mean_absolute_error: 70.7506\n","Model: \"sequential_93\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_294 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_295 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_108 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_296 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 3ms/step - loss: 34037.5977 - mse: 34037.5977 - mae: 135.0058 - val_loss: 22068.6133 - val_mse: 22068.6133 - val_mae: 110.4012\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18579.3301 - mse: 18579.3301 - mae: 99.3551 - val_loss: 15290.7920 - val_mse: 15290.7920 - val_mae: 88.5116\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15345.6006 - mse: 15345.6006 - mae: 86.4166 - val_loss: 13817.4912 - val_mse: 13817.4912 - val_mae: 81.5007\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 14336.9893 - mse: 14336.9893 - mae: 83.1869 - val_loss: 13167.2686 - val_mse: 13167.2686 - val_mae: 81.8615\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13850.4209 - mse: 13850.4209 - mae: 80.9135 - val_loss: 12801.7666 - val_mse: 12801.7666 - val_mae: 78.9371\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13605.9775 - mse: 13605.9775 - mae: 80.5707 - val_loss: 12592.5312 - val_mse: 12592.5312 - val_mae: 78.0473\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13304.8838 - mse: 13304.8838 - mae: 79.0437 - val_loss: 12373.5137 - val_mse: 12373.5137 - val_mae: 77.2030\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13245.3164 - mse: 13245.3164 - mae: 78.4156 - val_loss: 12333.5498 - val_mse: 12333.5498 - val_mae: 73.5443\n","Epoch 9/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12952.3936 - mse: 12952.3936 - mae: 77.3755 - val_loss: 11968.4863 - val_mse: 11968.4863 - val_mae: 73.7231\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12705.1289 - mse: 12705.1289 - mae: 76.4719 - val_loss: 11790.1758 - val_mse: 11790.1758 - val_mae: 72.9606\n","163/163 [==============================] - 0s 912us/step\n","Epoch 10/10\n","12/12 loss: 12705.1289 mean_squared_error: 12705.1289 mean_absolute_error: 76.4719 val_loss: 11790.1758 val_mean_squared_error: 11790.1758 val_mean_absolute_error: 72.9606\n","Model: \"sequential_94\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_297 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_298 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_109 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_299 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 4ms/step - loss: 32465.1602 - mse: 32465.1602 - mae: 132.3491 - val_loss: 21157.1328 - val_mse: 21157.1328 - val_mae: 113.6098\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17876.4824 - mse: 17876.4824 - mae: 97.8963 - val_loss: 15454.2812 - val_mse: 15454.2812 - val_mae: 90.0094\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14954.5439 - mse: 14954.5439 - mae: 86.6549 - val_loss: 13930.8291 - val_mse: 13930.8291 - val_mae: 83.4372\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 14018.6826 - mse: 14018.6826 - mae: 83.1021 - val_loss: 13431.3428 - val_mse: 13431.3428 - val_mae: 80.4601\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13677.9951 - mse: 13677.9941 - mae: 81.6043 - val_loss: 13154.4854 - val_mse: 13154.4834 - val_mae: 81.8048\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13698.9229 - mse: 13698.9229 - mae: 81.3333 - val_loss: 13157.5674 - val_mse: 13157.5674 - val_mae: 78.4467\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13527.8525 - mse: 13527.8525 - mae: 81.0796 - val_loss: 12996.8066 - val_mse: 12996.8066 - val_mae: 81.5069\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13514.9531 - mse: 13514.9531 - mae: 80.9913 - val_loss: 13113.2725 - val_mse: 13113.2725 - val_mae: 77.7964\n","Epoch 9/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13504.0488 - mse: 13504.0488 - mae: 80.7441 - val_loss: 13012.5352 - val_mse: 13012.5352 - val_mae: 83.1251\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13606.7246 - mse: 13606.7246 - mae: 81.2700 - val_loss: 13089.9443 - val_mse: 13089.9443 - val_mae: 77.5316\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","12/12 loss: 13606.7246 mean_squared_error: 13606.7246 mean_absolute_error: 81.2700 val_loss: 13089.9443 val_mean_squared_error: 13089.9443 val_mean_absolute_error: 77.5316\n","Model: \"sequential_95\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_300 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_301 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_110 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_302 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_111 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_303 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 24943.7773 - mse: 24943.7754 - mae: 112.0932 - val_loss: 14272.8311 - val_mse: 14272.8311 - val_mae: 83.7126\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14805.0771 - mse: 14805.0771 - mae: 83.3842 - val_loss: 12942.4375 - val_mse: 12942.4375 - val_mae: 80.4156\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13895.9648 - mse: 13895.9648 - mae: 80.7572 - val_loss: 12478.9482 - val_mse: 12478.9482 - val_mae: 77.3796\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13658.1084 - mse: 13658.1084 - mae: 79.5776 - val_loss: 12376.9932 - val_mse: 12376.9932 - val_mae: 72.0296\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13269.0215 - mse: 13269.0225 - mae: 77.8115 - val_loss: 11710.5439 - val_mse: 11710.5439 - val_mae: 73.1753\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12684.3145 - mse: 12684.3145 - mae: 75.8934 - val_loss: 12362.8730 - val_mse: 12362.8730 - val_mae: 67.3630\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12546.3008 - mse: 12546.3008 - mae: 74.2860 - val_loss: 10958.4971 - val_mse: 10958.4990 - val_mae: 70.2894\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12054.8047 - mse: 12054.8047 - mae: 72.7122 - val_loss: 10707.6553 - val_mse: 10707.6553 - val_mae: 71.4101\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11760.5381 - mse: 11760.5371 - mae: 72.0332 - val_loss: 10493.5156 - val_mse: 10493.5156 - val_mae: 67.7916\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11725.5293 - mse: 11725.5293 - mae: 71.4056 - val_loss: 10429.7568 - val_mse: 10429.7559 - val_mae: 65.9387\n","163/163 [==============================] - 0s 943us/step\n","Epoch 10/10\n","12/12 loss: 11725.5293 mean_squared_error: 11725.5293 mean_absolute_error: 71.4056 val_loss: 10429.7568 val_mean_squared_error: 10429.7559 val_mean_absolute_error: 65.9387\n","Model: \"sequential_96\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_304 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_305 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_112 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_306 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_113 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_307 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 62861.1602 - mse: 62861.1602 - mae: 175.7304 - val_loss: 59888.7930 - val_mse: 59888.7930 - val_mae: 169.3202\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 55975.9805 - mse: 55975.9805 - mae: 163.3740 - val_loss: 53757.4805 - val_mse: 53757.4805 - val_mae: 159.2283\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 50472.7578 - mse: 50472.7578 - mae: 154.7345 - val_loss: 48731.8828 - val_mse: 48731.8828 - val_mae: 151.7680\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 45923.0234 - mse: 45923.0234 - mae: 148.4196 - val_loss: 44677.4102 - val_mse: 44677.4102 - val_mae: 146.3803\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 42425.1602 - mse: 42425.1602 - mae: 144.0994 - val_loss: 41458.2852 - val_mse: 41458.2852 - val_mae: 142.7326\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 39565.4141 - mse: 39565.4141 - mae: 141.2338 - val_loss: 38990.6055 - val_mse: 38990.6055 - val_mae: 140.4755\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 35758.8477 - mse: 35758.8477 - mae: 127.4297 - val_loss: 33447.0664 - val_mse: 33447.0664 - val_mae: 115.3745\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 31134.9629 - mse: 31134.9629 - mae: 109.9391 - val_loss: 29976.9531 - val_mse: 29976.9531 - val_mae: 105.3466\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27971.4512 - mse: 27971.4531 - mae: 100.9946 - val_loss: 26787.3945 - val_mse: 26787.3945 - val_mae: 96.4663\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 25163.2793 - mse: 25163.2812 - mae: 94.2627 - val_loss: 24325.9766 - val_mse: 24325.9766 - val_mae: 89.8011\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 25163.2793 mean_squared_error: 25163.2812 mean_absolute_error: 94.2627 val_loss: 24325.9766 val_mean_squared_error: 24325.9766 val_mean_absolute_error: 89.8011\n","Model: \"sequential_97\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_308 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_309 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_114 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_310 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_115 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_311 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 24653.6406 - mse: 24653.6387 - mae: 111.0748 - val_loss: 14002.2852 - val_mse: 14002.2852 - val_mae: 82.9991\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14534.3457 - mse: 14534.3457 - mae: 82.9332 - val_loss: 12592.4756 - val_mse: 12592.4756 - val_mae: 79.6141\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13495.1953 - mse: 13495.1953 - mae: 79.3201 - val_loss: 12008.6289 - val_mse: 12008.6299 - val_mae: 72.2965\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12787.1045 - mse: 12787.1045 - mae: 76.3706 - val_loss: 11426.8047 - val_mse: 11426.8047 - val_mae: 69.9827\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12285.3418 - mse: 12285.3418 - mae: 73.8906 - val_loss: 11199.2891 - val_mse: 11199.2891 - val_mae: 76.6231\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11807.0117 - mse: 11807.0117 - mae: 72.1155 - val_loss: 10492.6641 - val_mse: 10492.6641 - val_mae: 69.5141\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11521.9502 - mse: 11521.9502 - mae: 70.9947 - val_loss: 10488.3232 - val_mse: 10488.3232 - val_mae: 72.8197\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11136.3838 - mse: 11136.3838 - mae: 69.6710 - val_loss: 10142.1826 - val_mse: 10142.1826 - val_mae: 64.7359\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11088.6221 - mse: 11088.6221 - mae: 69.1607 - val_loss: 9768.9580 - val_mse: 9768.9580 - val_mae: 65.0016\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10808.4473 - mse: 10808.4482 - mae: 68.4468 - val_loss: 10117.8926 - val_mse: 10117.8926 - val_mae: 70.8152\n","163/163 [==============================] - 0s 959us/step\n","Epoch 10/10\n","12/12 loss: 10808.4473 mean_squared_error: 10808.4482 mean_absolute_error: 68.4468 val_loss: 10117.8926 val_mean_squared_error: 10117.8926 val_mean_absolute_error: 70.8152\n","Model: \"sequential_98\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_312 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_313 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_116 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_314 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_117 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_315 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 24734.4492 - mse: 24734.4492 - mae: 111.2409 - val_loss: 13895.7373 - val_mse: 13895.7373 - val_mae: 81.4292\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14652.7568 - mse: 14652.7568 - mae: 82.6120 - val_loss: 12808.1699 - val_mse: 12808.1689 - val_mae: 77.7039\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13720.1738 - mse: 13720.1738 - mae: 79.6760 - val_loss: 12162.9863 - val_mse: 12162.9863 - val_mae: 79.0890\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13196.6172 - mse: 13196.6172 - mae: 77.4725 - val_loss: 11375.0156 - val_mse: 11375.0156 - val_mae: 72.0652\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12487.7402 - mse: 12487.7402 - mae: 74.5601 - val_loss: 10963.2051 - val_mse: 10963.2051 - val_mae: 68.6179\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11891.8545 - mse: 11891.8545 - mae: 71.9786 - val_loss: 10458.6641 - val_mse: 10458.6641 - val_mae: 73.1805\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11479.1191 - mse: 11479.1191 - mae: 70.7166 - val_loss: 9779.4971 - val_mse: 9779.4971 - val_mae: 64.8630\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11035.4258 - mse: 11035.4258 - mae: 69.3164 - val_loss: 9648.3447 - val_mse: 9648.3447 - val_mae: 63.0111\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10681.2061 - mse: 10681.2061 - mae: 67.6944 - val_loss: 9415.3564 - val_mse: 9415.3564 - val_mae: 66.7341\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10720.5508 - mse: 10720.5508 - mae: 67.2050 - val_loss: 9164.2012 - val_mse: 9164.2012 - val_mae: 63.2027\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 10720.5508 mean_squared_error: 10720.5508 mean_absolute_error: 67.2050 val_loss: 9164.2012 val_mean_squared_error: 9164.2012 val_mean_absolute_error: 63.2027\n","Model: \"sequential_99\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_316 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_317 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_118 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_318 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_119 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_319 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 22366.0449 - mse: 22366.0449 - mae: 106.7768 - val_loss: 14312.5791 - val_mse: 14312.5791 - val_mae: 82.1898\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14429.9111 - mse: 14429.9111 - mae: 83.7823 - val_loss: 13292.1621 - val_mse: 13292.1621 - val_mae: 84.3655\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14061.4932 - mse: 14061.4932 - mae: 82.5287 - val_loss: 13222.9121 - val_mse: 13222.9121 - val_mae: 77.9720\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13979.5713 - mse: 13979.5713 - mae: 81.9475 - val_loss: 13117.8535 - val_mse: 13117.8535 - val_mae: 78.0921\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14006.4551 - mse: 14006.4551 - mae: 82.5813 - val_loss: 13159.0527 - val_mse: 13159.0527 - val_mae: 76.9298\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14057.6035 - mse: 14057.6035 - mae: 82.2252 - val_loss: 13001.2441 - val_mse: 13001.2441 - val_mae: 82.8703\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13909.7803 - mse: 13909.7803 - mae: 82.0348 - val_loss: 13214.2344 - val_mse: 13214.2344 - val_mae: 77.0515\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13963.0078 - mse: 13963.0078 - mae: 82.0523 - val_loss: 13009.6553 - val_mse: 13009.6553 - val_mae: 77.9282\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13793.1172 - mse: 13793.1172 - mae: 81.5392 - val_loss: 12941.8018 - val_mse: 12941.8018 - val_mae: 79.0376\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14158.2266 - mse: 14158.2266 - mae: 82.5454 - val_loss: 13832.1680 - val_mse: 13832.1680 - val_mae: 76.0224\n","163/163 [==============================] - 0s 916us/step\n","Epoch 10/10\n","12/12 loss: 14158.2266 mean_squared_error: 14158.2266 mean_absolute_error: 82.5454 val_loss: 13832.1680 val_mean_squared_error: 13832.1680 val_mean_absolute_error: 76.0224\n","Model: \"sequential_100\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_320 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_321 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 55492.9883 - mse: 55492.9883 - mae: 163.9408 - val_loss: 37140.9180 - val_mse: 37140.9180 - val_mae: 133.5840\n","163/163 [==============================] - 0s 921us/step\n","Epoch 1/1\n","16/16 loss: 55492.9883 mean_squared_error: 55492.9883 mean_absolute_error: 163.9408 val_loss: 37140.9180 val_mean_squared_error: 37140.9180 val_mean_absolute_error: 133.5840\n","Model: \"sequential_101\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_322 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_323 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 61598.8359 - mse: 61598.8359 - mae: 173.7590 - val_loss: 55248.4609 - val_mse: 55248.4609 - val_mae: 161.4768\n","163/163 [==============================] - 0s 943us/step\n","Epoch 1/1\n","16/16 loss: 61598.8359 mean_squared_error: 61598.8359 mean_absolute_error: 173.7590 val_loss: 55248.4609 val_mean_squared_error: 55248.4609 val_mean_absolute_error: 161.4768\n","Model: \"sequential_102\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_324 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_325 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 52962.4492 - mse: 52962.4492 - mae: 160.1501 - val_loss: 35292.3125 - val_mse: 35292.3125 - val_mae: 131.9405\n","163/163 [==============================] - 0s 929us/step\n","Epoch 1/1\n","16/16 loss: 52962.4492 mean_squared_error: 52962.4492 mean_absolute_error: 160.1501 val_loss: 35292.3125 val_mean_squared_error: 35292.3125 val_mean_absolute_error: 131.9405\n","Model: \"sequential_103\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_326 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_327 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 55471.7891 - mse: 55471.7891 - mae: 163.8022 - val_loss: 37098.7188 - val_mse: 37098.7188 - val_mae: 133.5850\n","163/163 [==============================] - 0s 923us/step\n","Epoch 1/1\n","16/16 loss: 55471.7891 mean_squared_error: 55471.7891 mean_absolute_error: 163.8022 val_loss: 37098.7188 val_mean_squared_error: 37098.7188 val_mean_absolute_error: 133.5850\n","Model: \"sequential_104\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_328 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_329 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 50633.5664 - mse: 50633.5664 - mae: 156.8820 - val_loss: 31213.9355 - val_mse: 31213.9355 - val_mae: 128.2584\n","163/163 [==============================] - 0s 914us/step\n","Epoch 1/1\n","16/16 loss: 50633.5664 mean_squared_error: 50633.5664 mean_absolute_error: 156.8820 val_loss: 31213.9355 val_mean_squared_error: 31213.9355 val_mean_absolute_error: 128.2584\n","Model: \"sequential_105\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_330 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_331 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_120 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_332 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 33430.6562 - mse: 33430.6562 - mae: 134.1921 - val_loss: 20672.6270 - val_mse: 20672.6270 - val_mae: 104.2824\n","163/163 [==============================] - 0s 938us/step\n","Epoch 1/1\n","16/16 loss: 33430.6562 mean_squared_error: 33430.6562 mean_absolute_error: 134.1921 val_loss: 20672.6270 val_mean_squared_error: 20672.6270 val_mean_absolute_error: 104.2824\n","Model: \"sequential_106\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_333 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_334 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_121 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_335 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 60675.5273 - mse: 60675.5273 - mae: 171.7560 - val_loss: 56071.0781 - val_mse: 56071.0781 - val_mae: 162.9011\n","163/163 [==============================] - 0s 978us/step\n","Epoch 1/1\n","16/16 loss: 60675.5273 mean_squared_error: 60675.5273 mean_absolute_error: 171.7560 val_loss: 56071.0781 val_mean_squared_error: 56071.0781 val_mean_absolute_error: 162.9011\n","Model: \"sequential_107\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_336 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_337 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_122 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_338 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 31524.1406 - mse: 31524.1406 - mae: 130.6040 - val_loss: 18815.5918 - val_mse: 18815.5918 - val_mae: 99.3483\n","163/163 [==============================] - 0s 991us/step\n","Epoch 1/1\n","16/16 loss: 31524.1406 mean_squared_error: 31524.1406 mean_absolute_error: 130.6040 val_loss: 18815.5918 val_mean_squared_error: 18815.5918 val_mean_absolute_error: 99.3483\n","Model: \"sequential_108\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_339 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_340 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_123 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_341 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 32184.6641 - mse: 32184.6641 - mae: 131.4449 - val_loss: 19805.4590 - val_mse: 19805.4590 - val_mae: 107.1988\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","16/16 loss: 32184.6641 mean_squared_error: 32184.6641 mean_absolute_error: 131.4449 val_loss: 19805.4590 val_mean_squared_error: 19805.4590 val_mean_absolute_error: 107.1988\n","Model: \"sequential_109\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_342 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_343 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_124 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_344 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 2ms/step - loss: 29382.0273 - mse: 29382.0273 - mae: 126.4478 - val_loss: 18342.7402 - val_mse: 18342.7402 - val_mae: 99.3577\n","163/163 [==============================] - 0s 990us/step\n","Epoch 1/1\n","16/16 loss: 29382.0273 mean_squared_error: 29382.0273 mean_absolute_error: 126.4478 val_loss: 18342.7402 val_mean_squared_error: 18342.7402 val_mean_absolute_error: 99.3577\n","Model: \"sequential_110\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_345 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_346 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_125 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_347 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_126 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_348 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 22501.7051 - mse: 22501.7051 - mae: 106.1501 - val_loss: 13585.6328 - val_mse: 13585.6328 - val_mae: 82.3015\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","16/16 loss: 22501.7051 mean_squared_error: 22501.7051 mean_absolute_error: 106.1501 val_loss: 13585.6328 val_mean_squared_error: 13585.6328 val_mean_absolute_error: 82.3015\n","Model: \"sequential_111\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_349 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_350 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_127 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_351 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_128 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_352 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 60625.2852 - mse: 60625.2852 - mae: 171.5748 - val_loss: 56303.8945 - val_mse: 56303.8945 - val_mae: 163.2865\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 60625.2852 mean_squared_error: 60625.2852 mean_absolute_error: 171.5748 val_loss: 56303.8945 val_mean_squared_error: 56303.8945 val_mean_absolute_error: 163.2865\n","Model: \"sequential_112\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_353 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_354 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_129 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_355 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_130 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_356 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 4s 4ms/step - loss: 23210.9434 - mse: 23210.9434 - mae: 107.1664 - val_loss: 14136.8545 - val_mse: 14136.8545 - val_mae: 77.1738\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 23210.9434 mean_squared_error: 23210.9434 mean_absolute_error: 107.1664 val_loss: 14136.8545 val_mean_squared_error: 14136.8545 val_mean_absolute_error: 77.1738\n","Model: \"sequential_113\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_357 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_358 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_131 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_359 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_132 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_360 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 22832.4238 - mse: 22832.4238 - mae: 106.6744 - val_loss: 13499.4199 - val_mse: 13499.4199 - val_mae: 80.4107\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","16/16 loss: 22832.4238 mean_squared_error: 22832.4238 mean_absolute_error: 106.6744 val_loss: 13499.4199 val_mean_squared_error: 13499.4199 val_mean_absolute_error: 80.4107\n","Model: \"sequential_114\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_361 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_362 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_133 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_363 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_134 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_364 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 20434.2910 - mse: 20434.2910 - mae: 102.5516 - val_loss: 13652.3594 - val_mse: 13652.3594 - val_mae: 79.2942\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 20434.2910 mean_squared_error: 20434.2910 mean_absolute_error: 102.5516 val_loss: 13652.3594 val_mean_squared_error: 13652.3594 val_mean_absolute_error: 79.2942\n","Model: \"sequential_115\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_365 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_366 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_135 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_367 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 4ms/step - loss: 40223.4570 - mse: 40223.4570 - mae: 145.5478 - val_loss: 25206.1172 - val_mse: 25206.1172 - val_mae: 122.8375\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 40223.4570 mean_squared_error: 40223.4570 mean_absolute_error: 145.5478 val_loss: 25206.1172 val_mean_squared_error: 25206.1172 val_mean_absolute_error: 122.8375\n","Model: \"sequential_116\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_368 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_369 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_136 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_370 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 64269.5430 - mse: 64269.5430 - mae: 178.5366 - val_loss: 61922.2891 - val_mse: 61922.2891 - val_mae: 173.0103\n","163/163 [==============================] - 0s 938us/step\n","Epoch 1/1\n","16/16 loss: 64269.5430 mean_squared_error: 64269.5430 mean_absolute_error: 178.5366 val_loss: 61922.2891 val_mean_squared_error: 61922.2891 val_mean_absolute_error: 173.0103\n","Model: \"sequential_117\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_371 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_372 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_137 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_373 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 37326.4961 - mse: 37326.4961 - mae: 140.7360 - val_loss: 25127.4785 - val_mse: 25127.4785 - val_mae: 120.5410\n","163/163 [==============================] - 0s 980us/step\n","Epoch 1/1\n","16/16 loss: 37326.4961 mean_squared_error: 37326.4961 mean_absolute_error: 140.7360 val_loss: 25127.4785 val_mean_squared_error: 25127.4785 val_mean_absolute_error: 120.5410\n","Model: \"sequential_118\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_374 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_375 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_138 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_376 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 40675.0156 - mse: 40675.0156 - mae: 145.7926 - val_loss: 25322.0801 - val_mse: 25322.0801 - val_mae: 120.2808\n","163/163 [==============================] - 0s 992us/step\n","Epoch 1/1\n","16/16 loss: 40675.0156 mean_squared_error: 40675.0156 mean_absolute_error: 145.7926 val_loss: 25322.0801 val_mean_squared_error: 25322.0801 val_mean_absolute_error: 120.2808\n","Model: \"sequential_119\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_377 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_378 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_139 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_379 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 34239.9531 - mse: 34239.9531 - mae: 135.8211 - val_loss: 22804.3594 - val_mse: 22804.3594 - val_mae: 114.8890\n","163/163 [==============================] - 0s 981us/step\n","Epoch 1/1\n","16/16 loss: 34239.9531 mean_squared_error: 34239.9531 mean_absolute_error: 135.8211 val_loss: 22804.3594 val_mean_squared_error: 22804.3594 val_mean_absolute_error: 114.8890\n","Model: \"sequential_120\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_380 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_381 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_140 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_382 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_141 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_383 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 29806.0176 - mse: 29806.0176 - mae: 125.0203 - val_loss: 15621.6406 - val_mse: 15621.6406 - val_mae: 88.4677\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","16/16 loss: 29806.0176 mean_squared_error: 29806.0176 mean_absolute_error: 125.0203 val_loss: 15621.6406 val_mean_squared_error: 15621.6406 val_mean_absolute_error: 88.4677\n","Model: \"sequential_121\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_384 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_385 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_142 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_386 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_143 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_387 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 2ms/step - loss: 63947.1836 - mse: 63947.1836 - mae: 177.8440 - val_loss: 61713.5625 - val_mse: 61713.5625 - val_mae: 172.6233\n","163/163 [==============================] - 0s 967us/step\n","Epoch 1/1\n","16/16 loss: 63947.1836 mean_squared_error: 63947.1836 mean_absolute_error: 177.8440 val_loss: 61713.5625 val_mean_squared_error: 61713.5625 val_mean_absolute_error: 172.6233\n","Model: \"sequential_122\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_388 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_389 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_144 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_390 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_145 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_391 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 4ms/step - loss: 25990.0527 - mse: 25990.0527 - mae: 115.3028 - val_loss: 15107.6709 - val_mse: 15107.6709 - val_mae: 92.5267\n","163/163 [==============================] - 0s 991us/step\n","Epoch 1/1\n","16/16 loss: 25990.0527 mean_squared_error: 25990.0527 mean_absolute_error: 115.3028 val_loss: 15107.6709 val_mean_squared_error: 15107.6709 val_mean_absolute_error: 92.5267\n","Model: \"sequential_123\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_392 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_393 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_146 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_394 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_147 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_395 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 27185.0566 - mse: 27185.0566 - mae: 117.5299 - val_loss: 15790.4990 - val_mse: 15790.4990 - val_mae: 81.5761\n","163/163 [==============================] - 0s 967us/step\n","Epoch 1/1\n","16/16 loss: 27185.0566 mean_squared_error: 27185.0566 mean_absolute_error: 117.5299 val_loss: 15790.4990 val_mean_squared_error: 15790.4990 val_mean_absolute_error: 81.5761\n","Model: \"sequential_124\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_396 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_397 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_148 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_398 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_149 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_399 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 24797.8340 - mse: 24797.8340 - mae: 112.6286 - val_loss: 14592.1885 - val_mse: 14592.1885 - val_mae: 87.6684\n","163/163 [==============================] - 0s 935us/step\n","Epoch 1/1\n","16/16 loss: 24797.8340 mean_squared_error: 24797.8340 mean_absolute_error: 112.6286 val_loss: 14592.1885 val_mean_squared_error: 14592.1885 val_mean_absolute_error: 87.6684\n","Model: \"sequential_125\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_400 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_401 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 56278.8945 - mse: 56278.8945 - mae: 165.5011 - val_loss: 37173.7773 - val_mse: 37173.7773 - val_mae: 133.5965\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29968.0254 - mse: 29968.0254 - mae: 128.3985 - val_loss: 27406.5469 - val_mse: 27406.5469 - val_mae: 127.0711\n","Epoch 3/10\n","533/533 [==============================] - 2s 3ms/step - loss: 25421.7949 - mse: 25421.7949 - mae: 122.3041 - val_loss: 23783.0859 - val_mse: 23783.0859 - val_mae: 117.7296\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21903.4199 - mse: 21903.4199 - mae: 111.7976 - val_loss: 20601.7793 - val_mse: 20601.7793 - val_mae: 105.9995\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19155.1211 - mse: 19155.1211 - mae: 102.3093 - val_loss: 18332.3379 - val_mse: 18332.3379 - val_mae: 101.9621\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17392.0684 - mse: 17392.0684 - mae: 96.4944 - val_loss: 16917.6523 - val_mse: 16917.6523 - val_mae: 96.2898\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16274.7510 - mse: 16274.7510 - mae: 92.2793 - val_loss: 15988.2510 - val_mse: 15988.2510 - val_mae: 92.2707\n","Epoch 8/10\n","533/533 [==============================] - 2s 3ms/step - loss: 15495.5137 - mse: 15495.5137 - mae: 89.3310 - val_loss: 15318.4561 - val_mse: 15318.4561 - val_mae: 89.3806\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14929.7617 - mse: 14929.7617 - mae: 86.8773 - val_loss: 14805.9248 - val_mse: 14805.9248 - val_mae: 88.6952\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14484.7256 - mse: 14484.7256 - mae: 85.2712 - val_loss: 14391.7051 - val_mse: 14391.7051 - val_mae: 85.6634\n","163/163 [==============================] - 0s 929us/step\n","Epoch 10/10\n","16/16 loss: 14484.7256 mean_squared_error: 14484.7256 mean_absolute_error: 85.2712 val_loss: 14391.7051 val_mean_squared_error: 14391.7051 val_mean_absolute_error: 85.6634\n","Model: \"sequential_126\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_402 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_403 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 61477.3242 - mse: 61477.3242 - mae: 173.9027 - val_loss: 55108.3984 - val_mse: 55108.3984 - val_mae: 161.2763\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 49886.1406 - mse: 49886.1406 - mae: 153.7547 - val_loss: 46748.4492 - val_mse: 46748.4492 - val_mae: 148.7988\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 43172.2227 - mse: 43172.2227 - mae: 144.6334 - val_loss: 41294.8047 - val_mse: 41294.8047 - val_mae: 142.1500\n","Epoch 4/10\n","533/533 [==============================] - 2s 3ms/step - loss: 38799.4258 - mse: 38799.4258 - mae: 139.9299 - val_loss: 37720.6367 - val_mse: 37720.6367 - val_mae: 138.5288\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 35456.8711 - mse: 35456.8711 - mae: 134.4212 - val_loss: 34155.9961 - val_mse: 34155.9961 - val_mae: 129.2710\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 31633.2871 - mse: 31633.2871 - mae: 122.7103 - val_loss: 30365.0156 - val_mse: 30365.0156 - val_mae: 117.7214\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 28150.8887 - mse: 28150.8887 - mae: 113.0044 - val_loss: 27243.0859 - val_mse: 27243.0859 - val_mae: 109.7605\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25352.5742 - mse: 25352.5742 - mae: 105.8490 - val_loss: 24740.0215 - val_mse: 24740.0215 - val_mae: 104.6042\n","Epoch 9/10\n","533/533 [==============================] - 2s 4ms/step - loss: 23083.4434 - mse: 23083.4434 - mae: 100.7086 - val_loss: 22655.1445 - val_mse: 22655.1445 - val_mae: 99.9852\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21155.5938 - mse: 21155.5938 - mae: 96.2311 - val_loss: 20831.5039 - val_mse: 20831.5039 - val_mae: 95.7612\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 21155.5938 mean_squared_error: 21155.5938 mean_absolute_error: 96.2311 val_loss: 20831.5039 val_mean_squared_error: 20831.5039 val_mean_absolute_error: 95.7612\n","Model: \"sequential_127\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_404 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_405 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 53081.5234 - mse: 53081.5234 - mae: 160.1307 - val_loss: 35276.1719 - val_mse: 35276.1719 - val_mae: 131.9864\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29903.2500 - mse: 29903.2500 - mae: 129.6318 - val_loss: 28299.3398 - val_mse: 28299.3398 - val_mae: 130.5729\n","Epoch 3/10\n","533/533 [==============================] - 2s 3ms/step - loss: 26663.4727 - mse: 26663.4727 - mae: 126.2420 - val_loss: 25065.2695 - val_mse: 25065.2695 - val_mae: 121.2686\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22814.7363 - mse: 22814.7363 - mae: 114.6231 - val_loss: 21282.3438 - val_mse: 21282.3438 - val_mae: 110.4074\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19761.5469 - mse: 19761.5469 - mae: 105.1850 - val_loss: 18755.1172 - val_mse: 18755.1172 - val_mae: 101.4764\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17639.2871 - mse: 17639.2871 - mae: 97.2933 - val_loss: 17012.7812 - val_mse: 17012.7812 - val_mae: 94.9153\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16218.1035 - mse: 16218.1035 - mae: 91.9743 - val_loss: 15840.3848 - val_mse: 15840.3848 - val_mae: 91.9045\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15294.1104 - mse: 15294.1104 - mae: 88.5635 - val_loss: 15161.0801 - val_mse: 15161.0801 - val_mae: 86.9013\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14693.7529 - mse: 14693.7529 - mae: 85.7495 - val_loss: 14564.0127 - val_mse: 14564.0127 - val_mae: 85.3943\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14238.7402 - mse: 14238.7402 - mae: 84.0491 - val_loss: 14134.4219 - val_mse: 14134.4219 - val_mae: 84.2061\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 14238.7402 mean_squared_error: 14238.7402 mean_absolute_error: 84.0491 val_loss: 14134.4219 val_mean_squared_error: 14134.4219 val_mean_absolute_error: 84.2061\n","Model: \"sequential_128\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_406 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_407 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 54047.8516 - mse: 54047.8516 - mae: 161.7854 - val_loss: 35207.0586 - val_mse: 35207.0586 - val_mae: 131.3712\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29259.0254 - mse: 29259.0254 - mae: 127.8651 - val_loss: 27087.8496 - val_mse: 27087.8496 - val_mae: 127.9706\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25105.5664 - mse: 25105.5664 - mae: 121.7566 - val_loss: 23536.2832 - val_mse: 23536.2832 - val_mae: 117.0898\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21798.0371 - mse: 21798.0371 - mae: 111.7203 - val_loss: 20558.4082 - val_mse: 20558.4082 - val_mae: 107.2784\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19279.8477 - mse: 19279.8477 - mae: 102.9383 - val_loss: 18510.5840 - val_mse: 18510.5840 - val_mae: 103.4357\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17618.2910 - mse: 17618.2910 - mae: 97.6298 - val_loss: 17149.2793 - val_mse: 17149.2793 - val_mae: 95.7126\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16491.6523 - mse: 16491.6523 - mae: 92.9490 - val_loss: 16197.4902 - val_mse: 16197.4902 - val_mae: 93.0803\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15706.0283 - mse: 15706.0283 - mae: 90.0583 - val_loss: 15512.9268 - val_mse: 15512.9268 - val_mae: 90.1087\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15124.0420 - mse: 15124.0420 - mae: 87.6157 - val_loss: 14980.7676 - val_mse: 14980.7676 - val_mae: 88.5874\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14660.7188 - mse: 14660.7188 - mae: 85.7449 - val_loss: 14579.1777 - val_mse: 14579.1777 - val_mae: 85.6285\n","163/163 [==============================] - 0s 879us/step\n","Epoch 10/10\n","16/16 loss: 14660.7188 mean_squared_error: 14660.7188 mean_absolute_error: 85.7449 val_loss: 14579.1777 val_mean_squared_error: 14579.1777 val_mean_absolute_error: 85.6285\n","Model: \"sequential_129\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_408 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_409 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 50483.8242 - mse: 50483.8242 - mae: 156.2682 - val_loss: 30956.2500 - val_mse: 30956.2500 - val_mae: 128.0579\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 27955.1895 - mse: 27955.1895 - mae: 128.2514 - val_loss: 26883.5801 - val_mse: 26883.5801 - val_mae: 127.7813\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25541.2012 - mse: 25541.2012 - mae: 124.1615 - val_loss: 24592.6836 - val_mse: 24592.6836 - val_mae: 121.6360\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 23286.7559 - mse: 23286.7559 - mae: 118.0022 - val_loss: 22378.1035 - val_mse: 22378.1035 - val_mae: 114.5639\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21147.5391 - mse: 21147.5391 - mae: 110.9280 - val_loss: 20300.8184 - val_mse: 20300.8184 - val_mae: 109.5293\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19285.5293 - mse: 19285.5293 - mae: 104.6400 - val_loss: 18644.9277 - val_mse: 18644.9277 - val_mae: 102.3190\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17812.7188 - mse: 17812.7188 - mae: 98.6576 - val_loss: 17370.4609 - val_mse: 17370.4609 - val_mae: 98.7348\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16745.9961 - mse: 16745.9961 - mae: 94.6003 - val_loss: 16494.4238 - val_mse: 16494.4238 - val_mae: 93.3699\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15960.5273 - mse: 15960.5273 - mae: 90.9975 - val_loss: 15778.5410 - val_mse: 15778.5410 - val_mae: 92.2060\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15369.0645 - mse: 15369.0645 - mae: 88.8726 - val_loss: 15252.8262 - val_mse: 15252.8262 - val_mae: 88.6039\n","163/163 [==============================] - 0s 957us/step\n","Epoch 10/10\n","16/16 loss: 15369.0645 mean_squared_error: 15369.0645 mean_absolute_error: 88.8726 val_loss: 15252.8262 val_mean_squared_error: 15252.8262 val_mean_absolute_error: 88.6039\n","Model: \"sequential_130\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_410 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_411 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_150 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_412 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 33130.3867 - mse: 33130.3867 - mae: 132.9679 - val_loss: 19927.3926 - val_mse: 19927.3926 - val_mae: 110.0118\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16908.2969 - mse: 16908.2969 - mae: 93.6818 - val_loss: 14733.0342 - val_mse: 14733.0342 - val_mae: 85.0995\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14499.4893 - mse: 14499.4893 - mae: 83.7886 - val_loss: 13582.3965 - val_mse: 13582.3965 - val_mae: 79.7855\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13821.5967 - mse: 13821.5967 - mae: 81.1097 - val_loss: 13047.8760 - val_mse: 13047.8760 - val_mae: 80.2522\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13533.2705 - mse: 13533.2705 - mae: 80.1248 - val_loss: 12777.8291 - val_mse: 12777.8291 - val_mae: 78.7051\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13280.6523 - mse: 13280.6523 - mae: 79.3127 - val_loss: 12641.9893 - val_mse: 12641.9893 - val_mae: 80.8163\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13146.6006 - mse: 13146.6006 - mae: 78.8414 - val_loss: 12474.7861 - val_mse: 12474.7861 - val_mae: 74.5111\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12894.8389 - mse: 12894.8389 - mae: 77.2136 - val_loss: 12212.8965 - val_mse: 12212.8965 - val_mae: 74.7082\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12717.2598 - mse: 12717.2598 - mae: 76.7412 - val_loss: 11988.3477 - val_mse: 11988.3477 - val_mae: 74.9044\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12528.3145 - mse: 12528.3145 - mae: 75.8132 - val_loss: 11831.4893 - val_mse: 11831.4893 - val_mae: 73.9731\n","163/163 [==============================] - 0s 924us/step\n","Epoch 10/10\n","16/16 loss: 12528.3145 mean_squared_error: 12528.3145 mean_absolute_error: 75.8132 val_loss: 11831.4893 val_mean_squared_error: 11831.4893 val_mean_absolute_error: 73.9731\n","Model: \"sequential_131\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_413 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_414 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_151 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_415 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 59976.9141 - mse: 59976.9141 - mae: 170.6093 - val_loss: 55391.7891 - val_mse: 55391.7891 - val_mae: 161.7986\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 50590.2812 - mse: 50590.2812 - mae: 154.8611 - val_loss: 47724.3750 - val_mse: 47724.3750 - val_mae: 150.3643\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 44216.3633 - mse: 44216.3633 - mae: 145.7744 - val_loss: 41864.6836 - val_mse: 41864.6836 - val_mae: 136.3670\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 37743.7617 - mse: 37743.7617 - mae: 126.0381 - val_loss: 35526.2969 - val_mse: 35526.2969 - val_mae: 118.8066\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 32591.3184 - mse: 32591.3184 - mae: 113.7831 - val_loss: 30988.1914 - val_mse: 30988.1914 - val_mae: 110.3574\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 28225.7363 - mse: 28225.7363 - mae: 102.0519 - val_loss: 26671.4434 - val_mse: 26671.4434 - val_mae: 97.0458\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 24504.1738 - mse: 24504.1738 - mae: 93.0693 - val_loss: 23450.8516 - val_mse: 23450.8516 - val_mae: 90.0399\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21647.5645 - mse: 21647.5645 - mae: 87.0456 - val_loss: 20795.5215 - val_mse: 20795.5215 - val_mae: 84.1282\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19410.7051 - mse: 19410.7051 - mae: 82.3313 - val_loss: 18680.0039 - val_mse: 18680.0039 - val_mae: 80.3056\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17510.1875 - mse: 17510.1875 - mae: 79.1091 - val_loss: 17006.1152 - val_mse: 17006.1152 - val_mae: 77.9260\n","163/163 [==============================] - 0s 970us/step\n","Epoch 10/10\n","16/16 loss: 17510.1875 mean_squared_error: 17510.1875 mean_absolute_error: 79.1091 val_loss: 17006.1152 val_mean_squared_error: 17006.1152 val_mean_absolute_error: 77.9260\n","Model: \"sequential_132\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_416 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_417 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_152 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_418 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 31426.2793 - mse: 31426.2793 - mae: 129.8423 - val_loss: 19189.5195 - val_mse: 19189.5195 - val_mae: 98.2174\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16057.8779 - mse: 16057.8779 - mae: 90.6222 - val_loss: 14097.0264 - val_mse: 14097.0264 - val_mae: 83.6282\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14010.1787 - mse: 14010.1787 - mae: 82.4932 - val_loss: 13260.4463 - val_mse: 13260.4463 - val_mae: 84.9131\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13381.3838 - mse: 13381.3838 - mae: 80.2829 - val_loss: 12613.1133 - val_mse: 12613.1133 - val_mae: 79.9650\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12961.6162 - mse: 12961.6162 - mae: 78.8403 - val_loss: 12374.0068 - val_mse: 12374.0068 - val_mae: 75.6012\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12662.2197 - mse: 12662.2197 - mae: 77.3887 - val_loss: 11917.3662 - val_mse: 11917.3662 - val_mae: 76.9707\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11954.5723 - mse: 11954.5723 - mae: 74.4918 - val_loss: 11680.8447 - val_mse: 11680.8447 - val_mae: 79.3445\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11710.5020 - mse: 11710.5020 - mae: 72.9929 - val_loss: 11152.8184 - val_mse: 11152.8184 - val_mae: 69.6635\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11257.7061 - mse: 11257.7061 - mae: 70.8835 - val_loss: 10750.2988 - val_mse: 10750.2988 - val_mae: 71.5286\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11047.1865 - mse: 11047.1865 - mae: 70.0550 - val_loss: 10609.5664 - val_mse: 10609.5664 - val_mae: 69.4202\n","163/163 [==============================] - 0s 987us/step\n","Epoch 10/10\n","16/16 loss: 11047.1865 mean_squared_error: 11047.1865 mean_absolute_error: 70.0550 val_loss: 10609.5664 val_mean_squared_error: 10609.5664 val_mean_absolute_error: 69.4202\n","Model: \"sequential_133\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_419 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_420 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_153 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_421 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 31885.3496 - mse: 31885.3496 - mae: 130.5632 - val_loss: 18794.5977 - val_mse: 18794.5977 - val_mae: 103.8379\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16379.1611 - mse: 16379.1611 - mae: 91.2648 - val_loss: 14372.9932 - val_mse: 14372.9932 - val_mae: 84.3542\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14219.1523 - mse: 14219.1523 - mae: 82.3585 - val_loss: 13343.6221 - val_mse: 13343.6221 - val_mae: 81.3772\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13518.0361 - mse: 13518.0361 - mae: 80.1529 - val_loss: 12950.0176 - val_mse: 12950.0176 - val_mae: 79.3302\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13350.5059 - mse: 13350.5059 - mae: 79.3208 - val_loss: 12689.5166 - val_mse: 12689.5166 - val_mae: 79.6171\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13018.5898 - mse: 13018.5898 - mae: 78.3955 - val_loss: 12428.6436 - val_mse: 12428.6436 - val_mae: 77.6113\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12778.2119 - mse: 12778.2119 - mae: 77.4108 - val_loss: 12234.6182 - val_mse: 12234.6182 - val_mae: 78.1480\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12705.8535 - mse: 12705.8535 - mae: 76.8288 - val_loss: 12006.1592 - val_mse: 12006.1592 - val_mae: 75.6273\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12457.9883 - mse: 12457.9883 - mae: 75.4194 - val_loss: 11927.8203 - val_mse: 11927.8203 - val_mae: 72.5271\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12310.2305 - mse: 12310.2305 - mae: 74.9766 - val_loss: 11665.9521 - val_mse: 11665.9521 - val_mae: 73.2826\n","163/163 [==============================] - 0s 981us/step\n","Epoch 10/10\n","16/16 loss: 12310.2305 mean_squared_error: 12310.2305 mean_absolute_error: 74.9766 val_loss: 11665.9521 val_mean_squared_error: 11665.9521 val_mean_absolute_error: 73.2826\n","Model: \"sequential_134\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_422 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_423 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_154 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_424 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 29181.2891 - mse: 29181.2891 - mae: 126.6639 - val_loss: 18122.5762 - val_mse: 18122.5762 - val_mae: 100.4347\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15822.8711 - mse: 15822.8711 - mae: 89.9659 - val_loss: 14534.8682 - val_mse: 14534.8682 - val_mae: 90.2518\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14046.2783 - mse: 14046.2783 - mae: 83.2597 - val_loss: 13381.6973 - val_mse: 13381.6973 - val_mae: 82.6912\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13531.8018 - mse: 13531.8018 - mae: 81.1831 - val_loss: 13079.5713 - val_mse: 13079.5713 - val_mae: 80.7170\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13360.9658 - mse: 13360.9658 - mae: 80.5210 - val_loss: 13089.8018 - val_mse: 13089.8018 - val_mae: 78.4243\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13399.8672 - mse: 13399.8672 - mae: 80.7454 - val_loss: 13126.6963 - val_mse: 13126.6963 - val_mae: 77.5350\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13321.6885 - mse: 13321.6885 - mae: 80.6629 - val_loss: 13028.3486 - val_mse: 13028.3486 - val_mae: 78.1465\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13381.4189 - mse: 13381.4189 - mae: 80.5262 - val_loss: 12936.9248 - val_mse: 12936.9248 - val_mae: 81.7816\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13282.0430 - mse: 13282.0430 - mae: 80.3129 - val_loss: 12951.1416 - val_mse: 12951.1416 - val_mae: 79.1617\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13265.0928 - mse: 13265.0928 - mae: 80.3644 - val_loss: 12926.0342 - val_mse: 12926.0342 - val_mae: 79.4807\n","163/163 [==============================] - 0s 889us/step\n","Epoch 10/10\n","16/16 loss: 13265.0928 mean_squared_error: 13265.0928 mean_absolute_error: 80.3644 val_loss: 12926.0342 val_mean_squared_error: 12926.0342 val_mean_absolute_error: 79.4807\n","Model: \"sequential_135\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_425 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_426 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_155 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_427 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_156 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_428 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 2ms/step - loss: 22235.6445 - mse: 22235.6445 - mae: 105.7896 - val_loss: 13883.8408 - val_mse: 13883.8408 - val_mae: 88.0607\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13851.0752 - mse: 13851.0752 - mae: 80.8981 - val_loss: 12453.6924 - val_mse: 12453.6924 - val_mae: 75.5088\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12947.3320 - mse: 12947.3320 - mae: 77.7050 - val_loss: 11712.4863 - val_mse: 11712.4863 - val_mae: 72.4633\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12135.5420 - mse: 12135.5420 - mae: 73.7604 - val_loss: 11207.6094 - val_mse: 11207.6094 - val_mae: 74.0678\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11650.7510 - mse: 11650.7510 - mae: 72.1309 - val_loss: 10411.8545 - val_mse: 10411.8545 - val_mae: 70.4907\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11045.0508 - mse: 11045.0508 - mae: 70.2026 - val_loss: 10098.2041 - val_mse: 10098.2041 - val_mae: 68.2067\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10699.8408 - mse: 10699.8408 - mae: 68.8135 - val_loss: 9714.5205 - val_mse: 9714.5205 - val_mae: 67.5904\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10500.3203 - mse: 10500.3203 - mae: 68.0786 - val_loss: 9643.5898 - val_mse: 9643.5898 - val_mae: 63.5529\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10316.9795 - mse: 10316.9795 - mae: 67.4686 - val_loss: 9534.8086 - val_mse: 9534.8086 - val_mae: 61.2287\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10047.4902 - mse: 10047.4902 - mae: 65.9774 - val_loss: 9541.4082 - val_mse: 9541.4082 - val_mae: 61.6651\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 10047.4902 mean_squared_error: 10047.4902 mean_absolute_error: 65.9774 val_loss: 9541.4082 val_mean_squared_error: 9541.4082 val_mean_absolute_error: 61.6651\n","Model: \"sequential_136\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_429 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_430 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_157 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_431 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_158 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_432 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 4s 3ms/step - loss: 60600.3438 - mse: 60600.3438 - mae: 171.5309 - val_loss: 56157.4180 - val_mse: 56157.4180 - val_mae: 163.0489\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 51362.8203 - mse: 51362.8203 - mae: 156.0535 - val_loss: 48378.6445 - val_mse: 48378.6445 - val_mae: 151.2755\n","Epoch 3/10\n","533/533 [==============================] - 1s 3ms/step - loss: 44783.7148 - mse: 44783.7148 - mae: 147.0669 - val_loss: 42861.8242 - val_mse: 42861.8242 - val_mae: 144.2468\n","Epoch 4/10\n","533/533 [==============================] - 2s 4ms/step - loss: 40220.5312 - mse: 40220.5312 - mae: 141.3683 - val_loss: 38116.6211 - val_mse: 38116.6211 - val_mae: 130.9827\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 33769.1523 - mse: 33769.1523 - mae: 116.4856 - val_loss: 31510.2363 - val_mse: 31510.2363 - val_mae: 107.0512\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 28662.3262 - mse: 28662.3262 - mae: 102.1766 - val_loss: 27103.1973 - val_mse: 27103.1973 - val_mae: 97.0647\n","Epoch 7/10\n","533/533 [==============================] - 2s 3ms/step - loss: 25003.0039 - mse: 25003.0039 - mae: 93.8136 - val_loss: 23678.7969 - val_mse: 23678.7969 - val_mae: 89.7646\n","Epoch 8/10\n","533/533 [==============================] - 2s 4ms/step - loss: 21925.1797 - mse: 21925.1797 - mae: 86.9490 - val_loss: 20845.6445 - val_mse: 20845.6445 - val_mae: 82.3783\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19446.8164 - mse: 19446.8164 - mae: 81.5288 - val_loss: 18689.0000 - val_mse: 18689.0000 - val_mae: 79.5215\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17401.6777 - mse: 17401.6777 - mae: 77.3219 - val_loss: 16455.5742 - val_mse: 16455.5742 - val_mae: 70.9162\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 17401.6777 mean_squared_error: 17401.6777 mean_absolute_error: 77.3219 val_loss: 16455.5742 val_mean_squared_error: 16455.5742 val_mean_absolute_error: 70.9162\n","Model: \"sequential_137\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_433 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_434 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_159 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_435 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_160 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_436 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 4s 3ms/step - loss: 21813.8203 - mse: 21813.8203 - mae: 104.4517 - val_loss: 13383.4766 - val_mse: 13383.4766 - val_mae: 81.0645\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13696.5703 - mse: 13696.5703 - mae: 80.2914 - val_loss: 13240.1494 - val_mse: 13240.1494 - val_mae: 88.3975\n","Epoch 3/10\n","533/533 [==============================] - 1s 3ms/step - loss: 12530.1787 - mse: 12530.1787 - mae: 76.5915 - val_loss: 11796.6553 - val_mse: 11796.6553 - val_mae: 80.2737\n","Epoch 4/10\n","533/533 [==============================] - 2s 4ms/step - loss: 12036.3174 - mse: 12036.3174 - mae: 73.9123 - val_loss: 11000.5469 - val_mse: 11000.5469 - val_mae: 71.4465\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11193.9658 - mse: 11193.9658 - mae: 70.5721 - val_loss: 11081.2881 - val_mse: 11081.2881 - val_mae: 66.8375\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10712.6934 - mse: 10712.6934 - mae: 68.9603 - val_loss: 10020.7012 - val_mse: 10020.7012 - val_mae: 65.0869\n","Epoch 7/10\n","533/533 [==============================] - 2s 3ms/step - loss: 10470.6113 - mse: 10470.6113 - mae: 68.7463 - val_loss: 9762.7617 - val_mse: 9762.7617 - val_mae: 65.2207\n","Epoch 8/10\n","533/533 [==============================] - 2s 4ms/step - loss: 10489.1396 - mse: 10489.1396 - mae: 68.0398 - val_loss: 9647.2744 - val_mse: 9647.2744 - val_mae: 65.8375\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10360.4912 - mse: 10360.4912 - mae: 67.6923 - val_loss: 9750.5508 - val_mse: 9750.5508 - val_mae: 66.7449\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10244.1260 - mse: 10244.1260 - mae: 67.0471 - val_loss: 9388.0371 - val_mse: 9388.0371 - val_mae: 64.1738\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 10244.1260 mean_squared_error: 10244.1260 mean_absolute_error: 67.0471 val_loss: 9388.0371 val_mean_squared_error: 9388.0371 val_mean_absolute_error: 64.1738\n","Model: \"sequential_138\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_437 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_438 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_161 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_439 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_162 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_440 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 4s 3ms/step - loss: 23465.9238 - mse: 23465.9238 - mae: 107.8568 - val_loss: 13515.2090 - val_mse: 13515.2090 - val_mae: 82.2638\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13944.2793 - mse: 13944.2793 - mae: 81.2363 - val_loss: 12415.6826 - val_mse: 12415.6826 - val_mae: 76.0292\n","Epoch 3/10\n","533/533 [==============================] - 2s 3ms/step - loss: 12883.3916 - mse: 12883.3916 - mae: 76.9831 - val_loss: 12456.3516 - val_mse: 12456.3516 - val_mae: 70.7124\n","Epoch 4/10\n","533/533 [==============================] - 2s 4ms/step - loss: 12217.5703 - mse: 12217.5703 - mae: 74.5997 - val_loss: 11109.3477 - val_mse: 11109.3477 - val_mae: 67.5160\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11688.1396 - mse: 11688.1396 - mae: 72.2569 - val_loss: 10502.8174 - val_mse: 10502.8174 - val_mae: 72.7033\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11090.5879 - mse: 11090.5879 - mae: 70.0730 - val_loss: 9864.5938 - val_mse: 9864.5938 - val_mae: 67.9430\n","Epoch 7/10\n","533/533 [==============================] - 2s 4ms/step - loss: 10604.2988 - mse: 10604.2988 - mae: 68.1621 - val_loss: 10119.8477 - val_mse: 10119.8477 - val_mae: 63.1675\n","Epoch 8/10\n","533/533 [==============================] - 2s 3ms/step - loss: 10656.5312 - mse: 10656.5312 - mae: 68.2846 - val_loss: 9489.4287 - val_mse: 9489.4287 - val_mae: 66.8397\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10368.3203 - mse: 10368.3203 - mae: 66.5881 - val_loss: 9470.3652 - val_mse: 9470.3652 - val_mae: 67.3649\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 9970.6562 - mse: 9970.6562 - mae: 65.6001 - val_loss: 9008.1895 - val_mse: 9008.1895 - val_mae: 62.9350\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","16/16 loss: 9970.6562 mean_squared_error: 9970.6562 mean_absolute_error: 65.6001 val_loss: 9008.1895 val_mean_squared_error: 9008.1895 val_mean_absolute_error: 62.9350\n","Model: \"sequential_139\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_441 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_442 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_163 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_443 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_164 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_444 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 2ms/step - loss: 20045.9785 - mse: 20045.9785 - mae: 101.5872 - val_loss: 13449.6934 - val_mse: 13449.6934 - val_mae: 84.1009\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13884.5195 - mse: 13884.5195 - mae: 82.0140 - val_loss: 12963.5498 - val_mse: 12963.5498 - val_mae: 80.5069\n","Epoch 3/10\n","533/533 [==============================] - 2s 3ms/step - loss: 13715.3369 - mse: 13715.3369 - mae: 81.6826 - val_loss: 12954.9160 - val_mse: 12954.9160 - val_mae: 79.6236\n","Epoch 4/10\n","533/533 [==============================] - 2s 3ms/step - loss: 13663.2236 - mse: 13663.2236 - mae: 81.1468 - val_loss: 13903.5303 - val_mse: 13903.5303 - val_mae: 77.5280\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13737.1230 - mse: 13737.1230 - mae: 81.5848 - val_loss: 13364.6123 - val_mse: 13364.6123 - val_mae: 76.3639\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13681.1445 - mse: 13681.1445 - mae: 81.1641 - val_loss: 12946.6719 - val_mse: 12946.6719 - val_mae: 81.3550\n","Epoch 7/10\n","533/533 [==============================] - 2s 3ms/step - loss: 13629.3320 - mse: 13629.3320 - mae: 81.1971 - val_loss: 13118.6270 - val_mse: 13118.6270 - val_mae: 83.9476\n","Epoch 8/10\n","533/533 [==============================] - 2s 3ms/step - loss: 13661.0137 - mse: 13661.0137 - mae: 81.4393 - val_loss: 13078.6045 - val_mse: 13078.6045 - val_mae: 78.2770\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13501.2637 - mse: 13501.2637 - mae: 80.6414 - val_loss: 13195.8066 - val_mse: 13195.8066 - val_mae: 85.4554\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13788.5957 - mse: 13788.5957 - mae: 81.5604 - val_loss: 13211.7119 - val_mse: 13211.7119 - val_mae: 77.0716\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 13788.5957 mean_squared_error: 13788.5957 mean_absolute_error: 81.5604 val_loss: 13211.7119 val_mean_squared_error: 13211.7119 val_mean_absolute_error: 77.0716\n","Model: \"sequential_140\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_445 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_446 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_165 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_447 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 2ms/step - loss: 39567.2773 - mse: 39567.2773 - mae: 144.0772 - val_loss: 25111.6836 - val_mse: 25111.6836 - val_mae: 121.8751\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21931.3555 - mse: 21931.3555 - mae: 111.6590 - val_loss: 18167.7363 - val_mse: 18167.7363 - val_mae: 98.7096\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17533.7832 - mse: 17533.7832 - mae: 94.8609 - val_loss: 15480.5361 - val_mse: 15480.5361 - val_mae: 86.6668\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15835.4414 - mse: 15835.4414 - mae: 87.4139 - val_loss: 14212.4775 - val_mse: 14212.4775 - val_mae: 84.0252\n","Epoch 5/10\n","533/533 [==============================] - 2s 3ms/step - loss: 14933.7178 - mse: 14933.7178 - mae: 84.5316 - val_loss: 13582.7832 - val_mse: 13582.7832 - val_mae: 82.2746\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14599.2197 - mse: 14599.2197 - mae: 83.1357 - val_loss: 13864.1416 - val_mse: 13864.1416 - val_mae: 76.3357\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14538.0293 - mse: 14538.0293 - mae: 82.3453 - val_loss: 13074.8945 - val_mse: 13074.8945 - val_mae: 78.6554\n","Epoch 8/10\n","533/533 [==============================] - 1s 3ms/step - loss: 14262.8359 - mse: 14262.8359 - mae: 82.0744 - val_loss: 13071.8115 - val_mse: 13071.8115 - val_mae: 76.6894\n","Epoch 9/10\n","533/533 [==============================] - 2s 4ms/step - loss: 14303.8877 - mse: 14303.8877 - mae: 81.7878 - val_loss: 12817.8633 - val_mse: 12817.8633 - val_mae: 80.8352\n","Epoch 10/10\n","533/533 [==============================] - 2s 3ms/step - loss: 14016.6895 - mse: 14016.6895 - mae: 80.8048 - val_loss: 12644.5117 - val_mse: 12644.5117 - val_mae: 78.6480\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 14016.6895 mean_squared_error: 14016.6895 mean_absolute_error: 80.8048 val_loss: 12644.5117 val_mean_squared_error: 12644.5117 val_mean_absolute_error: 78.6480\n","Model: \"sequential_141\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_448 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_449 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_166 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_450 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 64179.0039 - mse: 64179.0039 - mae: 178.3467 - val_loss: 61770.6055 - val_mse: 61770.6055 - val_mae: 172.7278\n","Epoch 2/10\n","533/533 [==============================] - 2s 3ms/step - loss: 58339.0625 - mse: 58339.0625 - mae: 167.2626 - val_loss: 56663.7148 - val_mse: 56663.7148 - val_mae: 163.8683\n","Epoch 3/10\n","533/533 [==============================] - 1s 3ms/step - loss: 53714.3906 - mse: 53714.3906 - mae: 159.6423 - val_loss: 52322.2500 - val_mse: 52322.2500 - val_mae: 157.0127\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 49694.9023 - mse: 49694.9023 - mae: 153.6026 - val_loss: 48582.4297 - val_mse: 48582.4297 - val_mae: 151.5528\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 46291.8828 - mse: 46291.8828 - mae: 148.8143 - val_loss: 45421.6758 - val_mse: 45421.6758 - val_mae: 147.3079\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 42881.1992 - mse: 42881.1992 - mae: 139.7875 - val_loss: 41431.0430 - val_mse: 41431.0430 - val_mae: 131.9008\n","Epoch 7/10\n","533/533 [==============================] - 2s 3ms/step - loss: 39096.7461 - mse: 39096.7461 - mae: 127.4712 - val_loss: 38128.1797 - val_mse: 38128.1797 - val_mae: 123.7201\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 36085.9258 - mse: 36085.9258 - mae: 120.5361 - val_loss: 35249.6445 - val_mse: 35249.6445 - val_mae: 118.1223\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 33489.3906 - mse: 33489.3906 - mae: 115.1538 - val_loss: 32725.3574 - val_mse: 32725.3574 - val_mae: 112.2320\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 30774.2012 - mse: 30774.2012 - mae: 107.4059 - val_loss: 29930.1309 - val_mse: 29930.1309 - val_mae: 103.3647\n","163/163 [==============================] - 0s 936us/step\n","Epoch 10/10\n","16/16 loss: 30774.2012 mean_squared_error: 30774.2012 mean_absolute_error: 107.4059 val_loss: 29930.1309 val_mean_squared_error: 29930.1309 val_mean_absolute_error: 103.3647\n","Model: \"sequential_142\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_451 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_452 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_167 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_453 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 3ms/step - loss: 37728.1094 - mse: 37728.1094 - mae: 141.4694 - val_loss: 24141.8770 - val_mse: 24141.8770 - val_mae: 121.6135\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19377.6797 - mse: 19377.6797 - mae: 102.0966 - val_loss: 15849.1221 - val_mse: 15849.1221 - val_mae: 88.0190\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15314.6318 - mse: 15314.6318 - mae: 86.6725 - val_loss: 14051.2021 - val_mse: 14051.2021 - val_mae: 80.4309\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14141.7773 - mse: 14141.7773 - mae: 83.3290 - val_loss: 13080.0098 - val_mse: 13080.0098 - val_mae: 81.7347\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13843.4561 - mse: 13843.4561 - mae: 81.7889 - val_loss: 12718.4277 - val_mse: 12718.4277 - val_mae: 78.1115\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13538.4805 - mse: 13538.4805 - mae: 80.5572 - val_loss: 12613.5352 - val_mse: 12613.5352 - val_mae: 75.6599\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13230.5947 - mse: 13230.5947 - mae: 79.7163 - val_loss: 12260.2676 - val_mse: 12260.2676 - val_mae: 78.4515\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13053.8506 - mse: 13053.8506 - mae: 78.5160 - val_loss: 12146.9092 - val_mse: 12146.9092 - val_mae: 74.6289\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12649.0693 - mse: 12649.0693 - mae: 77.0241 - val_loss: 11755.9209 - val_mse: 11755.9209 - val_mae: 75.5678\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12480.3496 - mse: 12480.3496 - mae: 76.1016 - val_loss: 11530.4102 - val_mse: 11530.4102 - val_mae: 74.4440\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 12480.3496 mean_squared_error: 12480.3496 mean_absolute_error: 76.1016 val_loss: 11530.4102 val_mean_squared_error: 11530.4102 val_mean_absolute_error: 74.4440\n","Model: \"sequential_143\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_454 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_455 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_168 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_456 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 37730.2891 - mse: 37730.2891 - mae: 141.2260 - val_loss: 23633.4297 - val_mse: 23633.4297 - val_mae: 117.5073\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 20315.6172 - mse: 20315.6172 - mae: 106.1852 - val_loss: 16875.2773 - val_mse: 16875.2773 - val_mae: 95.1294\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16262.8721 - mse: 16262.8721 - mae: 89.8349 - val_loss: 14807.0635 - val_mse: 14807.0635 - val_mae: 84.6742\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15063.0664 - mse: 15063.0664 - mae: 84.7745 - val_loss: 13813.8652 - val_mse: 13813.8652 - val_mae: 81.9822\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14425.2441 - mse: 14425.2441 - mae: 82.9113 - val_loss: 13501.2725 - val_mse: 13501.2725 - val_mae: 78.4463\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14070.5859 - mse: 14070.5859 - mae: 81.8287 - val_loss: 13098.7314 - val_mse: 13098.7314 - val_mae: 79.1562\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13998.9717 - mse: 13998.9717 - mae: 81.2918 - val_loss: 12882.5195 - val_mse: 12882.5195 - val_mae: 78.7477\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13691.9287 - mse: 13691.9287 - mae: 80.3624 - val_loss: 12725.2539 - val_mse: 12725.2539 - val_mae: 78.5682\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13585.7207 - mse: 13585.7207 - mae: 79.8737 - val_loss: 12661.9189 - val_mse: 12661.9189 - val_mae: 75.7693\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13295.5801 - mse: 13295.5801 - mae: 78.9819 - val_loss: 12531.2363 - val_mse: 12531.2363 - val_mae: 80.6016\n","163/163 [==============================] - 0s 887us/step\n","Epoch 10/10\n","16/16 loss: 13295.5801 mean_squared_error: 13295.5801 mean_absolute_error: 78.9819 val_loss: 12531.2363 val_mean_squared_error: 12531.2363 val_mean_absolute_error: 80.6016\n","Model: \"sequential_144\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_457 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_458 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_169 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_459 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 35074.2070 - mse: 35074.2070 - mae: 137.5145 - val_loss: 22704.3613 - val_mse: 22704.3613 - val_mae: 115.7512\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19128.7578 - mse: 19128.7578 - mae: 102.7887 - val_loss: 16370.4307 - val_mse: 16370.4307 - val_mae: 92.6205\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15604.7275 - mse: 15604.7275 - mae: 89.0477 - val_loss: 14471.9092 - val_mse: 14471.9092 - val_mae: 85.3673\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14479.2227 - mse: 14479.2227 - mae: 84.5970 - val_loss: 13834.0654 - val_mse: 13834.0654 - val_mae: 80.8281\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13926.1436 - mse: 13926.1436 - mae: 82.3678 - val_loss: 13346.9521 - val_mse: 13346.9521 - val_mae: 80.2458\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13624.6621 - mse: 13624.6621 - mae: 81.4958 - val_loss: 13139.2852 - val_mse: 13139.2852 - val_mae: 80.6200\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13717.9473 - mse: 13717.9473 - mae: 81.6247 - val_loss: 13233.9795 - val_mse: 13233.9795 - val_mae: 78.1939\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13566.9346 - mse: 13566.9346 - mae: 81.2844 - val_loss: 12993.9912 - val_mse: 12993.9912 - val_mae: 79.9369\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13583.7109 - mse: 13583.7109 - mae: 80.9390 - val_loss: 12946.8447 - val_mse: 12946.8447 - val_mae: 80.4868\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13584.0283 - mse: 13584.0283 - mae: 81.1563 - val_loss: 12937.9316 - val_mse: 12937.9316 - val_mae: 80.2135\n","163/163 [==============================] - 0s 965us/step\n","Epoch 10/10\n","16/16 loss: 13584.0283 mean_squared_error: 13584.0283 mean_absolute_error: 81.1563 val_loss: 12937.9316 val_mean_squared_error: 12937.9316 val_mean_absolute_error: 80.2135\n","Model: \"sequential_145\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_460 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_461 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_170 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_462 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_171 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_463 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 28437.3203 - mse: 28437.3203 - mae: 120.4403 - val_loss: 15149.1729 - val_mse: 15149.1729 - val_mae: 84.7202\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15022.0059 - mse: 15022.0059 - mae: 84.6785 - val_loss: 12894.4297 - val_mse: 12894.4297 - val_mae: 80.5029\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14102.7656 - mse: 14102.7656 - mae: 81.0452 - val_loss: 12306.0430 - val_mse: 12306.0430 - val_mae: 77.4839\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13527.0479 - mse: 13527.0479 - mae: 78.7500 - val_loss: 11709.9541 - val_mse: 11709.9541 - val_mae: 73.3727\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12820.9141 - mse: 12820.9141 - mae: 76.3527 - val_loss: 11794.6562 - val_mse: 11794.6562 - val_mae: 68.1513\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12262.4844 - mse: 12262.4844 - mae: 73.7425 - val_loss: 11083.0312 - val_mse: 11083.0312 - val_mae: 76.0450\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12061.1211 - mse: 12061.1211 - mae: 72.6311 - val_loss: 10179.9990 - val_mse: 10179.9990 - val_mae: 66.7774\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11528.3066 - mse: 11528.3066 - mae: 70.2930 - val_loss: 9924.9990 - val_mse: 9924.9990 - val_mae: 65.6917\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11458.9453 - mse: 11458.9453 - mae: 70.2977 - val_loss: 9780.8721 - val_mse: 9780.8721 - val_mae: 68.4656\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11138.8516 - mse: 11138.8516 - mae: 69.1363 - val_loss: 10172.0410 - val_mse: 10172.0410 - val_mae: 63.0056\n","163/163 [==============================] - 0s 909us/step\n","Epoch 10/10\n","16/16 loss: 11138.8516 mean_squared_error: 11138.8516 mean_absolute_error: 69.1363 val_loss: 10172.0410 val_mean_squared_error: 10172.0410 val_mean_absolute_error: 63.0056\n","Model: \"sequential_146\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_464 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_465 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_172 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_466 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_173 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_467 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 63741.1211 - mse: 63741.1211 - mae: 177.4529 - val_loss: 61572.9180 - val_mse: 61572.9180 - val_mae: 172.3625\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 58251.8867 - mse: 58251.8867 - mae: 167.1210 - val_loss: 56573.1992 - val_mse: 56573.1992 - val_mae: 163.7241\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 53626.9688 - mse: 53626.9688 - mae: 159.5164 - val_loss: 52249.4219 - val_mse: 52249.4219 - val_mae: 156.9056\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 49668.1328 - mse: 49668.1328 - mae: 153.5211 - val_loss: 48554.8438 - val_mse: 48554.8438 - val_mae: 151.5204\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 46251.1836 - mse: 46251.1836 - mae: 148.8532 - val_loss: 45392.2227 - val_mse: 45392.2227 - val_mae: 147.2879\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 43440.8281 - mse: 43440.8281 - mae: 145.3667 - val_loss: 42756.2734 - val_mse: 42756.2734 - val_mae: 144.1285\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 41038.5195 - mse: 41038.5195 - mae: 142.6655 - val_loss: 40564.8477 - val_mse: 40564.8477 - val_mae: 141.8473\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 39128.3672 - mse: 39128.3672 - mae: 140.8121 - val_loss: 38762.4375 - val_mse: 38762.4375 - val_mae: 140.3083\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 37099.1719 - mse: 37099.1719 - mae: 136.2710 - val_loss: 35086.6094 - val_mse: 35086.6094 - val_mae: 125.0238\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 32273.3125 - mse: 32273.3125 - mae: 113.1415 - val_loss: 31108.9609 - val_mse: 31108.9609 - val_mae: 107.8914\n","163/163 [==============================] - 0s 993us/step\n","Epoch 10/10\n","16/16 loss: 32273.3125 mean_squared_error: 32273.3125 mean_absolute_error: 113.1415 val_loss: 31108.9609 val_mean_squared_error: 31108.9609 val_mean_absolute_error: 107.8914\n","Model: \"sequential_147\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_468 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_469 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_174 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_470 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_175 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_471 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 26676.3320 - mse: 26676.3320 - mae: 117.0576 - val_loss: 14704.7383 - val_mse: 14704.7383 - val_mae: 85.4804\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14675.7158 - mse: 14675.7158 - mae: 83.6763 - val_loss: 12769.2803 - val_mse: 12769.2803 - val_mae: 79.6678\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13473.8271 - mse: 13473.8271 - mae: 79.9456 - val_loss: 12117.8867 - val_mse: 12117.8867 - val_mae: 73.9745\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12978.6016 - mse: 12978.6016 - mae: 77.6821 - val_loss: 11564.3857 - val_mse: 11564.3857 - val_mae: 72.0315\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12274.6533 - mse: 12274.6533 - mae: 74.9514 - val_loss: 10988.7783 - val_mse: 10988.7783 - val_mae: 69.1421\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11587.8760 - mse: 11587.8760 - mae: 71.7220 - val_loss: 10596.3496 - val_mse: 10596.3496 - val_mae: 67.2079\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11287.7402 - mse: 11287.7402 - mae: 70.8604 - val_loss: 10198.0645 - val_mse: 10198.0645 - val_mae: 65.5120\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10943.5752 - mse: 10943.5752 - mae: 70.1565 - val_loss: 10117.1826 - val_mse: 10117.1826 - val_mae: 65.2894\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11027.0811 - mse: 11027.0811 - mae: 70.1123 - val_loss: 9821.4561 - val_mse: 9821.4561 - val_mae: 67.4686\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 10783.9580 - mse: 10783.9580 - mae: 69.5225 - val_loss: 10278.4199 - val_mse: 10278.4199 - val_mae: 65.3733\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 10783.9580 mean_squared_error: 10783.9580 mean_absolute_error: 69.5225 val_loss: 10278.4199 val_mean_squared_error: 10278.4199 val_mean_absolute_error: 65.3733\n","Model: \"sequential_148\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_472 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_473 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_176 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_474 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_177 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_475 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 27898.1777 - mse: 27898.1777 - mae: 119.8109 - val_loss: 15009.4326 - val_mse: 15009.4326 - val_mae: 87.1205\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14745.9980 - mse: 14745.9980 - mae: 83.6698 - val_loss: 12988.4932 - val_mse: 12988.4932 - val_mae: 80.4283\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14276.6826 - mse: 14276.6826 - mae: 81.4974 - val_loss: 13366.7100 - val_mse: 13366.7100 - val_mae: 87.9008\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13717.5195 - mse: 13717.5195 - mae: 79.9184 - val_loss: 12118.4961 - val_mse: 12118.4961 - val_mae: 74.3814\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13158.2363 - mse: 13158.2363 - mae: 77.8939 - val_loss: 11665.6211 - val_mse: 11665.6211 - val_mae: 74.1803\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12751.4824 - mse: 12751.4824 - mae: 76.0440 - val_loss: 11251.6230 - val_mse: 11251.6230 - val_mae: 73.3911\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12328.9375 - mse: 12328.9375 - mae: 74.4074 - val_loss: 10984.4463 - val_mse: 10984.4463 - val_mae: 69.0644\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11984.7275 - mse: 11984.7275 - mae: 73.1726 - val_loss: 10679.6270 - val_mse: 10679.6270 - val_mae: 72.0150\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11898.4756 - mse: 11898.4756 - mae: 72.5865 - val_loss: 10603.9014 - val_mse: 10603.9014 - val_mae: 71.0136\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11827.5459 - mse: 11827.5459 - mae: 71.9872 - val_loss: 10372.2334 - val_mse: 10372.2334 - val_mae: 70.8484\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 11827.5459 mean_squared_error: 11827.5459 mean_absolute_error: 71.9872 val_loss: 10372.2334 val_mean_squared_error: 10372.2334 val_mean_absolute_error: 70.8484\n","Model: \"sequential_149\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_476 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_477 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_178 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_478 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_179 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_479 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 4ms/step - loss: 25354.8867 - mse: 25354.8867 - mae: 114.7879 - val_loss: 14865.0928 - val_mse: 14865.0928 - val_mae: 87.8364\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14577.5195 - mse: 14577.5195 - mae: 84.5813 - val_loss: 13498.4473 - val_mse: 13498.4473 - val_mae: 78.9269\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13974.2939 - mse: 13974.2939 - mae: 82.2635 - val_loss: 13047.0391 - val_mse: 13047.0391 - val_mae: 83.2904\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13964.4980 - mse: 13964.4980 - mae: 82.3222 - val_loss: 13368.9922 - val_mse: 13368.9922 - val_mae: 76.1617\n","Epoch 5/10\n","533/533 [==============================] - 2s 4ms/step - loss: 14027.7520 - mse: 14027.7520 - mae: 81.7465 - val_loss: 12979.3711 - val_mse: 12979.3711 - val_mae: 79.7032\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13785.4004 - mse: 13785.4004 - mae: 81.3050 - val_loss: 13281.9141 - val_mse: 13281.9141 - val_mae: 85.9601\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13723.7109 - mse: 13723.7109 - mae: 81.6051 - val_loss: 13222.5596 - val_mse: 13222.5596 - val_mae: 76.9032\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13926.3506 - mse: 13926.3506 - mae: 82.1552 - val_loss: 13970.4229 - val_mse: 13970.4229 - val_mae: 76.7860\n","Epoch 9/10\n","533/533 [==============================] - 2s 3ms/step - loss: 14006.9561 - mse: 14006.9561 - mae: 82.2462 - val_loss: 12930.8555 - val_mse: 12930.8555 - val_mae: 79.8602\n","Epoch 10/10\n","533/533 [==============================] - 1s 3ms/step - loss: 13895.1914 - mse: 13895.1914 - mae: 81.9194 - val_loss: 12990.3408 - val_mse: 12990.3408 - val_mae: 78.6300\n","163/163 [==============================] - 0s 978us/step\n","Epoch 10/10\n","16/16 loss: 13895.1914 mean_squared_error: 13895.1914 mean_absolute_error: 81.9194 val_loss: 12990.3408 val_mean_squared_error: 12990.3408 val_mean_absolute_error: 78.6300\n","Model: \"sequential_150\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_480 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_481 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 43679.1719 - mse: 43679.1719 - mae: 147.5426 - val_loss: 28235.8594 - val_mse: 28235.8594 - val_mae: 129.3168\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","8/8 loss: 43679.1719 mean_squared_error: 43679.1719 mean_absolute_error: 147.5426 val_loss: 28235.8594 val_mean_squared_error: 28235.8594 val_mean_absolute_error: 129.3168\n","Model: \"sequential_151\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_482 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_483 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 56174.3789 - mse: 56174.3789 - mae: 164.2585 - val_loss: 47261.9961 - val_mse: 47261.9961 - val_mae: 149.4756\n","163/163 [==============================] - 0s 930us/step\n","Epoch 1/1\n","8/8 loss: 56174.3789 mean_squared_error: 56174.3789 mean_absolute_error: 164.2585 val_loss: 47261.9961 val_mean_squared_error: 47261.9961 val_mean_absolute_error: 149.4756\n","Model: \"sequential_152\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_484 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_485 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 42270.3516 - mse: 42270.3516 - mae: 146.3636 - val_loss: 28506.8301 - val_mse: 28506.8301 - val_mae: 129.6688\n","163/163 [==============================] - 0s 982us/step\n","Epoch 1/1\n","8/8 loss: 42270.3516 mean_squared_error: 42270.3516 mean_absolute_error: 146.3636 val_loss: 28506.8301 val_mean_squared_error: 28506.8301 val_mean_absolute_error: 129.6688\n","Model: \"sequential_153\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_486 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_487 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 44656.1328 - mse: 44656.1328 - mae: 148.7509 - val_loss: 28416.3984 - val_mse: 28416.3984 - val_mae: 128.7653\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","8/8 loss: 44656.1328 mean_squared_error: 44656.1328 mean_absolute_error: 148.7509 val_loss: 28416.3984 val_mean_squared_error: 28416.3984 val_mean_absolute_error: 128.7653\n","Model: \"sequential_154\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_488 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_489 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 39587.8594 - mse: 39587.8594 - mae: 142.6178 - val_loss: 27499.3926 - val_mse: 27499.3926 - val_mae: 130.4107\n","163/163 [==============================] - 0s 996us/step\n","Epoch 1/1\n","8/8 loss: 39587.8594 mean_squared_error: 39587.8594 mean_absolute_error: 142.6178 val_loss: 27499.3926 val_mean_squared_error: 27499.3926 val_mean_absolute_error: 130.4107\n","Model: \"sequential_155\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_490 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_491 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_180 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_492 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 28871.3789 - mse: 28871.3789 - mae: 123.7973 - val_loss: 16954.8926 - val_mse: 16954.8926 - val_mae: 91.7826\n","163/163 [==============================] - 0s 918us/step\n","Epoch 1/1\n","8/8 loss: 28871.3789 mean_squared_error: 28871.3789 mean_absolute_error: 123.7973 val_loss: 16954.8926 val_mean_squared_error: 16954.8926 val_mean_absolute_error: 91.7826\n","Model: \"sequential_156\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_493 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_494 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_181 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_495 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 56274.8984 - mse: 56274.8984 - mae: 164.3985 - val_loss: 49198.4141 - val_mse: 49198.4141 - val_mae: 152.4179\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","8/8 loss: 56274.8984 mean_squared_error: 56274.8984 mean_absolute_error: 164.3985 val_loss: 49198.4141 val_mean_squared_error: 49198.4141 val_mean_absolute_error: 152.4179\n","Model: \"sequential_157\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_496 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_497 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_182 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_498 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 25424.5098 - mse: 25424.5098 - mae: 114.4921 - val_loss: 15102.4580 - val_mse: 15102.4580 - val_mae: 87.1006\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 25424.5098 mean_squared_error: 25424.5098 mean_absolute_error: 114.4921 val_loss: 15102.4580 val_mean_squared_error: 15102.4580 val_mean_absolute_error: 87.1006\n","Model: \"sequential_158\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_499 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_500 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_183 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_501 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 29255.5547 - mse: 29255.5547 - mae: 124.8960 - val_loss: 17057.5254 - val_mse: 17057.5254 - val_mae: 94.4801\n","163/163 [==============================] - 0s 975us/step\n","Epoch 1/1\n","8/8 loss: 29255.5547 mean_squared_error: 29255.5547 mean_absolute_error: 124.8960 val_loss: 17057.5254 val_mean_squared_error: 17057.5254 val_mean_absolute_error: 94.4801\n","Model: \"sequential_159\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_502 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_503 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_184 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_504 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 24938.2324 - mse: 24938.2324 - mae: 114.9662 - val_loss: 15601.7334 - val_mse: 15601.7334 - val_mae: 87.3009\n","163/163 [==============================] - 0s 925us/step\n","Epoch 1/1\n","8/8 loss: 24938.2324 mean_squared_error: 24938.2324 mean_absolute_error: 114.9662 val_loss: 15601.7334 val_mean_squared_error: 15601.7334 val_mean_absolute_error: 87.3009\n","Model: \"sequential_160\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_505 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_506 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_185 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_507 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_186 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_508 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 21476.1309 - mse: 21476.1309 - mae: 101.1511 - val_loss: 13780.7207 - val_mse: 13780.7207 - val_mae: 74.9993\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","8/8 loss: 21476.1309 mean_squared_error: 21476.1309 mean_absolute_error: 101.1511 val_loss: 13780.7207 val_mean_squared_error: 13780.7207 val_mean_absolute_error: 74.9993\n","Model: \"sequential_161\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_509 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_510 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_187 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_511 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_188 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_512 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 56231.2031 - mse: 56231.2031 - mae: 164.1264 - val_loss: 49258.2891 - val_mse: 49258.2891 - val_mae: 152.5150\n","163/163 [==============================] - 1s 2ms/step\n","Epoch 1/1\n","8/8 loss: 56231.2031 mean_squared_error: 56231.2031 mean_absolute_error: 164.1264 val_loss: 49258.2891 val_mean_squared_error: 49258.2891 val_mean_absolute_error: 152.5150\n","Model: \"sequential_162\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_513 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_514 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_189 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_515 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_190 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_516 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 19762.5742 - mse: 19762.5742 - mae: 97.8580 - val_loss: 12722.9199 - val_mse: 12722.9199 - val_mae: 79.5971\n","163/163 [==============================] - 1s 2ms/step\n","Epoch 1/1\n","8/8 loss: 19762.5742 mean_squared_error: 19762.5742 mean_absolute_error: 97.8580 val_loss: 12722.9199 val_mean_squared_error: 12722.9199 val_mean_absolute_error: 79.5971\n","Model: \"sequential_163\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_517 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_518 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_191 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_519 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_192 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_520 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 21542.5469 - mse: 21542.5469 - mae: 102.4210 - val_loss: 13097.7568 - val_mse: 13097.7568 - val_mae: 78.9267\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 21542.5469 mean_squared_error: 21542.5469 mean_absolute_error: 102.4210 val_loss: 13097.7568 val_mean_squared_error: 13097.7568 val_mean_absolute_error: 78.9267\n","Model: \"sequential_164\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_521 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_522 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_193 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_523 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_194 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_524 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 18689.9883 - mse: 18689.9883 - mae: 95.9363 - val_loss: 13589.0859 - val_mse: 13589.0859 - val_mae: 78.0062\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 18689.9883 mean_squared_error: 18689.9883 mean_absolute_error: 95.9363 val_loss: 13589.0859 val_mean_squared_error: 13589.0859 val_mean_absolute_error: 78.0062\n","Model: \"sequential_165\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_525 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_526 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_195 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_527 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 33760.6016 - mse: 33760.6016 - mae: 134.2037 - val_loss: 20070.3301 - val_mse: 20070.3301 - val_mae: 105.8568\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 33760.6016 mean_squared_error: 33760.6016 mean_absolute_error: 134.2037 val_loss: 20070.3301 val_mean_squared_error: 20070.3301 val_mean_absolute_error: 105.8568\n","Model: \"sequential_166\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_528 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_529 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_196 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_530 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 3ms/step - loss: 61735.9336 - mse: 61735.9336 - mae: 173.7264 - val_loss: 57482.1992 - val_mse: 57482.1992 - val_mae: 165.2123\n","163/163 [==============================] - 0s 987us/step\n","Epoch 1/1\n","8/8 loss: 61735.9336 mean_squared_error: 61735.9336 mean_absolute_error: 173.7264 val_loss: 57482.1992 val_mean_squared_error: 57482.1992 val_mean_absolute_error: 165.2123\n","Model: \"sequential_167\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_531 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_532 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_197 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_533 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 33948.0312 - mse: 33948.0312 - mae: 133.1485 - val_loss: 19135.9453 - val_mse: 19135.9453 - val_mae: 98.2972\n","163/163 [==============================] - 0s 968us/step\n","Epoch 1/1\n","8/8 loss: 33948.0312 mean_squared_error: 33948.0312 mean_absolute_error: 133.1485 val_loss: 19135.9453 val_mean_squared_error: 19135.9453 val_mean_absolute_error: 98.2972\n","Model: \"sequential_168\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_534 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_535 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_198 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_536 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 32171.3086 - mse: 32171.3086 - mae: 131.7691 - val_loss: 19974.1484 - val_mse: 19974.1484 - val_mae: 104.7651\n","163/163 [==============================] - 0s 930us/step\n","Epoch 1/1\n","8/8 loss: 32171.3086 mean_squared_error: 32171.3086 mean_absolute_error: 131.7691 val_loss: 19974.1484 val_mean_squared_error: 19974.1484 val_mean_absolute_error: 104.7651\n","Model: \"sequential_169\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_537 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_538 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_199 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_539 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 29552.1602 - mse: 29552.1602 - mae: 127.9111 - val_loss: 19394.2656 - val_mse: 19394.2656 - val_mae: 101.9815\n","163/163 [==============================] - 0s 883us/step\n","Epoch 1/1\n","8/8 loss: 29552.1602 mean_squared_error: 29552.1602 mean_absolute_error: 127.9111 val_loss: 19394.2656 val_mean_squared_error: 19394.2656 val_mean_absolute_error: 101.9815\n","Model: \"sequential_170\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_540 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_541 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_200 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_542 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_201 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_543 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 26018.2188 - mse: 26018.2188 - mae: 114.0058 - val_loss: 14313.0498 - val_mse: 14313.0498 - val_mae: 80.2897\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 26018.2188 mean_squared_error: 26018.2188 mean_absolute_error: 114.0058 val_loss: 14313.0498 val_mean_squared_error: 14313.0498 val_mean_absolute_error: 80.2897\n","Model: \"sequential_171\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_544 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_545 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_202 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_546 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_203 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_547 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 61764.9922 - mse: 61764.9922 - mae: 173.5755 - val_loss: 57615.0039 - val_mse: 57615.0039 - val_mae: 165.4381\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 61764.9922 mean_squared_error: 61764.9922 mean_absolute_error: 173.5755 val_loss: 57615.0039 val_mean_squared_error: 57615.0039 val_mean_absolute_error: 165.4381\n","Model: \"sequential_172\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_548 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_549 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_204 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_550 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_205 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_551 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 23790.6465 - mse: 23790.6465 - mae: 108.2472 - val_loss: 14273.1680 - val_mse: 14273.1680 - val_mae: 90.0589\n","163/163 [==============================] - 0s 938us/step\n","Epoch 1/1\n","8/8 loss: 23790.6465 mean_squared_error: 23790.6465 mean_absolute_error: 108.2472 val_loss: 14273.1680 val_mean_squared_error: 14273.1680 val_mean_absolute_error: 90.0589\n","Model: \"sequential_173\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_552 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_553 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_206 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_554 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_207 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_555 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24635.8047 - mse: 24635.8047 - mae: 110.8937 - val_loss: 13575.3252 - val_mse: 13575.3252 - val_mae: 78.5689\n","163/163 [==============================] - 0s 930us/step\n","Epoch 1/1\n","8/8 loss: 24635.8047 mean_squared_error: 24635.8047 mean_absolute_error: 110.8937 val_loss: 13575.3252 val_mean_squared_error: 13575.3252 val_mean_absolute_error: 78.5689\n","Model: \"sequential_174\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_556 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_557 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_208 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_558 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_209 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_559 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 22336.4375 - mse: 22336.4375 - mae: 105.5512 - val_loss: 13827.1992 - val_mse: 13827.1992 - val_mae: 80.3216\n","163/163 [==============================] - 0s 956us/step\n","Epoch 1/1\n","8/8 loss: 22336.4375 mean_squared_error: 22336.4375 mean_absolute_error: 105.5512 val_loss: 13827.1992 val_mean_squared_error: 13827.1992 val_mean_absolute_error: 80.3216\n","Model: \"sequential_175\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_560 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_561 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 43286.7852 - mse: 43286.7852 - mae: 147.4432 - val_loss: 28161.3203 - val_mse: 28161.3203 - val_mae: 128.9968\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25214.0527 - mse: 25214.0527 - mae: 121.6088 - val_loss: 22716.0938 - val_mse: 22716.0938 - val_mae: 114.9301\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20432.1895 - mse: 20432.1895 - mae: 107.2500 - val_loss: 18851.0469 - val_mse: 18851.0469 - val_mae: 101.9039\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17538.9551 - mse: 17538.9551 - mae: 97.0354 - val_loss: 16747.2598 - val_mse: 16747.2598 - val_mae: 94.7792\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15949.6514 - mse: 15949.6514 - mae: 90.9823 - val_loss: 15541.0674 - val_mse: 15541.0674 - val_mae: 89.9301\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15017.2041 - mse: 15017.2041 - mae: 87.0667 - val_loss: 14753.8096 - val_mse: 14753.8096 - val_mae: 87.7537\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14385.9521 - mse: 14385.9521 - mae: 84.6262 - val_loss: 14218.2900 - val_mse: 14218.2900 - val_mae: 84.6157\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13941.8066 - mse: 13941.8066 - mae: 82.7544 - val_loss: 13814.7441 - val_mse: 13814.7441 - val_mae: 83.7247\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13630.1104 - mse: 13630.1104 - mae: 81.6452 - val_loss: 13544.5117 - val_mse: 13544.5117 - val_mae: 81.4763\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13401.0762 - mse: 13401.0762 - mae: 80.7484 - val_loss: 13311.4717 - val_mse: 13311.4717 - val_mae: 81.4462\n","163/163 [==============================] - 0s 882us/step\n","Epoch 10/10\n","8/8 loss: 13401.0762 mean_squared_error: 13401.0762 mean_absolute_error: 80.7484 val_loss: 13311.4717 val_mean_squared_error: 13311.4717 val_mean_absolute_error: 81.4462\n","Model: \"sequential_176\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_562 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_563 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 55535.6484 - mse: 55535.6484 - mae: 163.7584 - val_loss: 46672.7734 - val_mse: 46672.7734 - val_mae: 148.6647\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 41184.9102 - mse: 41184.9102 - mae: 142.4141 - val_loss: 38087.8789 - val_mse: 38087.8789 - val_mae: 139.0016\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 34344.9648 - mse: 34344.9648 - mae: 131.0833 - val_loss: 31469.7109 - val_mse: 31469.7109 - val_mae: 121.8602\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 27972.7383 - mse: 27972.7383 - mae: 112.8846 - val_loss: 26028.3613 - val_mse: 26028.3613 - val_mae: 106.9694\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 23462.9141 - mse: 23462.9141 - mae: 101.7764 - val_loss: 22250.7949 - val_mse: 22250.7949 - val_mae: 99.8846\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20219.1602 - mse: 20219.1602 - mae: 94.5034 - val_loss: 19386.6250 - val_mse: 19386.6250 - val_mae: 92.6866\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17679.5020 - mse: 17679.5020 - mae: 88.1784 - val_loss: 17102.8828 - val_mse: 17102.8828 - val_mae: 88.7519\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15691.2803 - mse: 15691.2803 - mae: 83.0684 - val_loss: 15345.6309 - val_mse: 15345.6309 - val_mae: 83.0330\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14232.8633 - mse: 14232.8633 - mae: 78.9789 - val_loss: 14063.7754 - val_mse: 14063.7754 - val_mae: 80.9594\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13213.1934 - mse: 13213.1934 - mae: 76.2802 - val_loss: 13202.8545 - val_mse: 13202.8545 - val_mae: 79.2286\n","163/163 [==============================] - 0s 914us/step\n","Epoch 10/10\n","8/8 loss: 13213.1934 mean_squared_error: 13213.1934 mean_absolute_error: 76.2802 val_loss: 13202.8545 val_mean_squared_error: 13202.8545 val_mean_absolute_error: 79.2286\n","Model: \"sequential_177\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_564 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_565 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 41726.4375 - mse: 41726.4375 - mae: 144.7207 - val_loss: 28417.7383 - val_mse: 28417.7383 - val_mae: 131.0312\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25515.9961 - mse: 25515.9961 - mae: 122.8942 - val_loss: 22662.0234 - val_mse: 22662.0234 - val_mae: 115.2961\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20189.0410 - mse: 20189.0410 - mae: 106.6207 - val_loss: 18389.2383 - val_mse: 18389.2383 - val_mae: 100.6065\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16931.2500 - mse: 16931.2500 - mae: 94.5723 - val_loss: 16086.5391 - val_mse: 16086.5391 - val_mae: 93.4423\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15305.1699 - mse: 15305.1699 - mae: 88.3675 - val_loss: 14896.6631 - val_mse: 14896.6631 - val_mae: 87.8264\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14423.1348 - mse: 14423.1348 - mae: 84.7868 - val_loss: 14187.2129 - val_mse: 14187.2129 - val_mae: 85.5169\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13853.8652 - mse: 13853.8652 - mae: 82.5797 - val_loss: 13752.1279 - val_mse: 13752.1279 - val_mae: 82.1083\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13516.2119 - mse: 13516.2119 - mae: 81.3374 - val_loss: 13602.1865 - val_mse: 13602.1865 - val_mae: 79.4452\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13249.9072 - mse: 13249.9072 - mae: 80.1452 - val_loss: 13170.9238 - val_mse: 13170.9238 - val_mae: 81.9673\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13068.5078 - mse: 13068.5078 - mae: 79.7212 - val_loss: 13009.7480 - val_mse: 13009.7480 - val_mae: 79.3898\n","163/163 [==============================] - 0s 969us/step\n","Epoch 10/10\n","8/8 loss: 13068.5078 mean_squared_error: 13068.5078 mean_absolute_error: 79.7212 val_loss: 13009.7480 val_mean_squared_error: 13009.7480 val_mean_absolute_error: 79.3898\n","Model: \"sequential_178\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_566 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_567 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 42246.7852 - mse: 42246.7852 - mae: 145.7957 - val_loss: 27851.0898 - val_mse: 27851.0898 - val_mae: 128.5352\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25112.0625 - mse: 25112.0625 - mae: 121.6960 - val_loss: 22742.1465 - val_mse: 22742.1465 - val_mae: 114.1066\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20447.3828 - mse: 20447.3828 - mae: 107.2253 - val_loss: 18844.4160 - val_mse: 18844.4160 - val_mae: 103.4870\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17525.5391 - mse: 17525.5391 - mae: 97.2867 - val_loss: 16796.0508 - val_mse: 16796.0508 - val_mae: 93.2165\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15918.6055 - mse: 15918.6055 - mae: 90.7399 - val_loss: 15474.8545 - val_mse: 15474.8545 - val_mae: 90.4255\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14944.2627 - mse: 14944.2627 - mae: 87.0110 - val_loss: 14686.2324 - val_mse: 14686.2324 - val_mae: 86.5604\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14314.5801 - mse: 14314.5801 - mae: 84.1253 - val_loss: 14135.3145 - val_mse: 14135.3145 - val_mae: 84.6584\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13889.8945 - mse: 13889.8945 - mae: 82.6667 - val_loss: 13767.9482 - val_mse: 13767.9482 - val_mae: 82.5736\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13583.7246 - mse: 13583.7246 - mae: 81.1587 - val_loss: 13492.2490 - val_mse: 13492.2490 - val_mae: 83.0446\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13368.9434 - mse: 13368.9434 - mae: 80.7850 - val_loss: 13364.3613 - val_mse: 13364.3613 - val_mae: 79.6502\n","163/163 [==============================] - 0s 998us/step\n","Epoch 10/10\n","8/8 loss: 13368.9434 mean_squared_error: 13368.9434 mean_absolute_error: 80.7850 val_loss: 13364.3613 val_mean_squared_error: 13364.3613 val_mean_absolute_error: 79.6502\n","Model: \"sequential_179\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_568 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_569 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 39516.8555 - mse: 39516.8555 - mae: 142.3384 - val_loss: 27435.2480 - val_mse: 27435.2480 - val_mae: 128.9767\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25330.9414 - mse: 25330.9414 - mae: 123.6780 - val_loss: 23717.6582 - val_mse: 23717.6582 - val_mae: 118.1860\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 21784.0137 - mse: 21784.0137 - mae: 113.1681 - val_loss: 20337.3301 - val_mse: 20337.3301 - val_mae: 108.1316\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18836.2891 - mse: 18836.2891 - mae: 102.6418 - val_loss: 17794.6348 - val_mse: 17794.6348 - val_mae: 100.3484\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16819.1133 - mse: 16819.1133 - mae: 94.9484 - val_loss: 16259.8477 - val_mse: 16259.8477 - val_mae: 92.6185\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 15602.7910 - mse: 15602.7910 - mae: 89.4678 - val_loss: 15274.5947 - val_mse: 15274.5947 - val_mae: 88.9228\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14820.0117 - mse: 14820.0117 - mae: 86.1078 - val_loss: 14606.1875 - val_mse: 14606.1875 - val_mae: 87.1282\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14296.0596 - mse: 14296.0596 - mae: 84.1129 - val_loss: 14138.4658 - val_mse: 14138.4658 - val_mae: 85.1573\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13921.8965 - mse: 13921.8965 - mae: 82.5305 - val_loss: 13820.0811 - val_mse: 13820.0811 - val_mae: 84.2991\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13693.0508 - mse: 13693.0508 - mae: 81.9230 - val_loss: 13591.7568 - val_mse: 13591.7568 - val_mae: 82.8246\n","163/163 [==============================] - 0s 959us/step\n","Epoch 10/10\n","8/8 loss: 13693.0508 mean_squared_error: 13693.0508 mean_absolute_error: 81.9230 val_loss: 13591.7568 val_mean_squared_error: 13591.7568 val_mean_absolute_error: 82.8246\n","Model: \"sequential_180\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_570 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_571 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_210 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_572 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 27171.0391 - mse: 27171.0391 - mae: 119.0804 - val_loss: 15828.7705 - val_mse: 15828.7705 - val_mae: 90.7595\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15489.0635 - mse: 15489.0635 - mae: 86.8606 - val_loss: 13507.6953 - val_mse: 13507.6953 - val_mae: 79.3323\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14403.2217 - mse: 14403.2217 - mae: 82.2352 - val_loss: 13046.8379 - val_mse: 13046.8379 - val_mae: 76.7304\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13924.6426 - mse: 13924.6426 - mae: 80.5853 - val_loss: 12668.2842 - val_mse: 12668.2842 - val_mae: 80.5306\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13761.5928 - mse: 13761.5928 - mae: 80.3437 - val_loss: 12375.6865 - val_mse: 12375.6865 - val_mae: 75.3540\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13481.5596 - mse: 13481.5596 - mae: 79.0150 - val_loss: 12018.6738 - val_mse: 12018.6738 - val_mae: 75.4290\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13318.8027 - mse: 13318.8027 - mae: 78.0157 - val_loss: 11809.6514 - val_mse: 11809.6514 - val_mae: 74.0911\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12917.0127 - mse: 12917.0127 - mae: 76.3170 - val_loss: 11561.2910 - val_mse: 11561.2910 - val_mae: 72.0907\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12689.7275 - mse: 12689.7275 - mae: 75.7487 - val_loss: 11306.6299 - val_mse: 11306.6299 - val_mae: 73.5338\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 12516.5508 - mse: 12516.5508 - mae: 74.7951 - val_loss: 11155.2979 - val_mse: 11155.2979 - val_mae: 73.2066\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","8/8 loss: 12516.5508 mean_squared_error: 12516.5508 mean_absolute_error: 74.7951 val_loss: 11155.2979 val_mean_squared_error: 11155.2979 val_mean_absolute_error: 73.2066\n","Model: \"sequential_181\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_573 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_574 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_211 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_575 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 56379.3711 - mse: 56379.3711 - mae: 164.6071 - val_loss: 49198.3203 - val_mse: 49198.3203 - val_mae: 152.4163\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 43072.5273 - mse: 43072.5273 - mae: 141.9344 - val_loss: 38194.6211 - val_mse: 38194.6211 - val_mae: 126.7087\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 33185.3125 - mse: 33185.3125 - mae: 116.3732 - val_loss: 29823.6699 - val_mse: 29823.6699 - val_mae: 107.0266\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 26123.4570 - mse: 26123.4570 - mae: 98.2589 - val_loss: 23516.5957 - val_mse: 23516.5957 - val_mae: 90.5500\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 21265.9961 - mse: 21265.9961 - mae: 88.2033 - val_loss: 19446.5625 - val_mse: 19446.5625 - val_mae: 82.5881\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18142.6055 - mse: 18142.6055 - mae: 82.2012 - val_loss: 16783.5039 - val_mse: 16783.5039 - val_mae: 78.9742\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 16042.3457 - mse: 16042.3457 - mae: 79.3041 - val_loss: 14783.9395 - val_mse: 14783.9395 - val_mae: 73.0769\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14702.5225 - mse: 14702.5225 - mae: 76.5258 - val_loss: 13480.3350 - val_mse: 13480.3350 - val_mae: 70.0550\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13486.9453 - mse: 13486.9453 - mae: 74.9867 - val_loss: 12749.1191 - val_mse: 12749.1191 - val_mae: 68.8451\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12970.6289 - mse: 12970.6289 - mae: 74.8295 - val_loss: 11788.0010 - val_mse: 11788.0010 - val_mae: 67.2929\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 12970.6289 mean_squared_error: 12970.6289 mean_absolute_error: 74.8295 val_loss: 11788.0010 val_mean_squared_error: 11788.0010 val_mean_absolute_error: 67.2929\n","Model: \"sequential_182\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_576 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_577 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_212 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_578 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 26408.5117 - mse: 26408.5117 - mae: 116.9210 - val_loss: 15297.1904 - val_mse: 15297.1904 - val_mae: 86.5073\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15370.7852 - mse: 15370.7852 - mae: 86.3692 - val_loss: 13312.6377 - val_mse: 13312.6377 - val_mae: 78.9071\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14221.6816 - mse: 14221.6816 - mae: 82.2758 - val_loss: 12549.9443 - val_mse: 12549.9443 - val_mae: 79.9438\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13372.9932 - mse: 13372.9932 - mae: 79.0619 - val_loss: 11934.4121 - val_mse: 11934.4121 - val_mae: 72.7557\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12637.6514 - mse: 12637.6514 - mae: 75.9230 - val_loss: 11372.4561 - val_mse: 11372.4561 - val_mae: 70.5028\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12013.6953 - mse: 12013.6953 - mae: 73.0634 - val_loss: 10849.9453 - val_mse: 10849.9453 - val_mae: 72.2651\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11752.9707 - mse: 11752.9707 - mae: 72.3831 - val_loss: 10673.1396 - val_mse: 10673.1396 - val_mae: 67.7639\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11620.2139 - mse: 11620.2139 - mae: 71.4581 - val_loss: 10430.8193 - val_mse: 10430.8193 - val_mae: 69.6602\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11285.2158 - mse: 11285.2158 - mae: 70.3832 - val_loss: 10386.0127 - val_mse: 10386.0127 - val_mae: 66.5324\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11343.5254 - mse: 11343.5254 - mae: 70.4904 - val_loss: 10518.5723 - val_mse: 10518.5723 - val_mae: 70.6852\n","163/163 [==============================] - 0s 925us/step\n","Epoch 10/10\n","8/8 loss: 11343.5254 mean_squared_error: 11343.5254 mean_absolute_error: 70.4904 val_loss: 10518.5723 val_mean_squared_error: 10518.5723 val_mean_absolute_error: 70.6852\n","Model: \"sequential_183\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_579 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_580 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_213 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_581 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 26169.4922 - mse: 26169.4922 - mae: 116.9571 - val_loss: 15698.5020 - val_mse: 15698.5020 - val_mae: 91.8084\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15266.2080 - mse: 15266.2080 - mae: 85.5347 - val_loss: 13737.8691 - val_mse: 13737.8691 - val_mae: 86.3863\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14423.4189 - mse: 14423.4189 - mae: 82.2359 - val_loss: 12874.7168 - val_mse: 12874.7168 - val_mae: 79.2202\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13783.6592 - mse: 13783.6592 - mae: 80.6278 - val_loss: 12638.7822 - val_mse: 12638.7822 - val_mae: 75.9250\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13617.0400 - mse: 13617.0400 - mae: 79.3137 - val_loss: 12437.6162 - val_mse: 12437.6162 - val_mae: 74.5344\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13569.5977 - mse: 13569.5977 - mae: 78.6668 - val_loss: 12195.6943 - val_mse: 12195.6943 - val_mae: 79.7131\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12921.4062 - mse: 12921.4062 - mae: 76.9996 - val_loss: 11783.1895 - val_mse: 11783.1895 - val_mae: 74.4161\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12747.3525 - mse: 12747.3525 - mae: 75.7540 - val_loss: 11513.3027 - val_mse: 11513.3027 - val_mae: 71.9705\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12598.8564 - mse: 12598.8564 - mae: 75.0351 - val_loss: 12092.2500 - val_mse: 12092.2500 - val_mae: 67.7412\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12314.2891 - mse: 12314.2891 - mae: 74.0338 - val_loss: 11118.3652 - val_mse: 11118.3652 - val_mae: 70.2766\n","163/163 [==============================] - 0s 916us/step\n","Epoch 10/10\n","8/8 loss: 12314.2891 mean_squared_error: 12314.2891 mean_absolute_error: 74.0338 val_loss: 11118.3652 val_mean_squared_error: 11118.3652 val_mean_absolute_error: 70.2766\n","Model: \"sequential_184\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_582 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_583 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_214 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_584 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 23997.1621 - mse: 23997.1621 - mae: 113.4681 - val_loss: 15189.5771 - val_mse: 15189.5771 - val_mae: 89.6239\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14676.8779 - mse: 14676.8779 - mae: 84.9308 - val_loss: 13688.0430 - val_mse: 13688.0430 - val_mae: 87.3614\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13937.4570 - mse: 13937.4570 - mae: 82.3818 - val_loss: 13065.5264 - val_mse: 13065.5264 - val_mae: 79.7399\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13717.9502 - mse: 13717.9502 - mae: 81.5107 - val_loss: 12944.3799 - val_mse: 12944.3799 - val_mae: 80.3955\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13702.3457 - mse: 13702.3457 - mae: 81.3754 - val_loss: 14012.4961 - val_mse: 14012.4961 - val_mae: 92.3643\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13778.7207 - mse: 13778.7207 - mae: 81.8400 - val_loss: 13134.2998 - val_mse: 13134.2998 - val_mae: 77.7831\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13722.0771 - mse: 13722.0771 - mae: 81.5543 - val_loss: 13058.2158 - val_mse: 13058.2158 - val_mae: 77.5677\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13728.1611 - mse: 13728.1611 - mae: 81.3116 - val_loss: 12922.2803 - val_mse: 12922.2803 - val_mae: 80.2482\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13836.3574 - mse: 13836.3574 - mae: 81.2914 - val_loss: 12928.8730 - val_mse: 12928.8730 - val_mae: 81.3484\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13720.9180 - mse: 13720.9180 - mae: 81.6137 - val_loss: 13188.6660 - val_mse: 13188.6660 - val_mae: 85.2576\n","163/163 [==============================] - 0s 902us/step\n","Epoch 10/10\n","8/8 loss: 13720.9180 mean_squared_error: 13720.9180 mean_absolute_error: 81.6137 val_loss: 13188.6660 val_mean_squared_error: 13188.6660 val_mean_absolute_error: 85.2576\n","Model: \"sequential_185\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_585 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_586 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_215 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_587 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_216 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_588 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 3ms/step - loss: 21827.3398 - mse: 21827.3398 - mae: 103.6129 - val_loss: 13952.6436 - val_mse: 13952.6436 - val_mae: 76.7661\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14995.2266 - mse: 14995.2266 - mae: 83.7597 - val_loss: 12553.8818 - val_mse: 12553.8818 - val_mae: 74.0876\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14214.0557 - mse: 14214.0557 - mae: 79.9478 - val_loss: 11369.5283 - val_mse: 11369.5283 - val_mae: 71.7509\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13107.9473 - mse: 13107.9473 - mae: 76.2897 - val_loss: 10393.7900 - val_mse: 10393.7900 - val_mae: 70.5296\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12333.8008 - mse: 12333.8008 - mae: 73.4061 - val_loss: 10052.1602 - val_mse: 10052.1602 - val_mae: 64.7917\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12021.8828 - mse: 12021.8828 - mae: 72.0066 - val_loss: 9496.7031 - val_mse: 9496.7031 - val_mae: 65.6255\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11847.4688 - mse: 11847.4688 - mae: 71.0953 - val_loss: 9282.5596 - val_mse: 9282.5596 - val_mae: 62.5318\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11396.6982 - mse: 11396.6982 - mae: 69.1305 - val_loss: 9146.2627 - val_mse: 9146.2627 - val_mae: 64.1515\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11038.1055 - mse: 11038.1055 - mae: 67.8495 - val_loss: 9632.6348 - val_mse: 9632.6348 - val_mae: 60.6062\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10936.0098 - mse: 10936.0098 - mae: 67.0904 - val_loss: 9153.2520 - val_mse: 9153.2520 - val_mae: 67.4604\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 10936.0098 mean_squared_error: 10936.0098 mean_absolute_error: 67.0904 val_loss: 9153.2520 val_mean_squared_error: 9153.2520 val_mean_absolute_error: 67.4604\n","Model: \"sequential_186\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_589 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_590 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_217 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_591 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_218 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_592 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 56281.3281 - mse: 56281.3281 - mae: 164.3783 - val_loss: 49227.3438 - val_mse: 49227.3438 - val_mae: 152.4708\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 43668.6836 - mse: 43668.6836 - mae: 145.8337 - val_loss: 40262.8789 - val_mse: 40262.8789 - val_mae: 141.5610\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 34529.4883 - mse: 34529.4883 - mae: 121.9732 - val_loss: 30050.5156 - val_mse: 30050.5156 - val_mae: 105.6211\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 26516.9609 - mse: 26516.9609 - mae: 98.9329 - val_loss: 23790.1211 - val_mse: 23790.1211 - val_mae: 89.8079\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 21495.2090 - mse: 21495.2090 - mae: 88.4592 - val_loss: 19465.3301 - val_mse: 19465.3301 - val_mae: 81.0135\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 18183.4531 - mse: 18183.4531 - mae: 82.6449 - val_loss: 16559.9453 - val_mse: 16559.9453 - val_mae: 74.4756\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16084.8926 - mse: 16084.8926 - mae: 79.1930 - val_loss: 14535.1670 - val_mse: 14535.1670 - val_mae: 71.9447\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14780.5723 - mse: 14780.5723 - mae: 77.0333 - val_loss: 13696.5352 - val_mse: 13696.5352 - val_mae: 75.8885\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13454.8271 - mse: 13454.8271 - mae: 74.0426 - val_loss: 11472.6201 - val_mse: 11472.6201 - val_mae: 66.7972\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11782.0898 - mse: 11782.0898 - mae: 69.9194 - val_loss: 9940.7295 - val_mse: 9940.7295 - val_mae: 59.3754\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 11782.0898 mean_squared_error: 11782.0898 mean_absolute_error: 69.9194 val_loss: 9940.7295 val_mean_squared_error: 9940.7295 val_mean_absolute_error: 59.3754\n","Model: \"sequential_187\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_593 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_594 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_219 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_595 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_220 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_596 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 3ms/step - loss: 19611.8613 - mse: 19611.8613 - mae: 97.4950 - val_loss: 13505.5098 - val_mse: 13505.5098 - val_mae: 73.8015\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13932.2285 - mse: 13932.2285 - mae: 79.7466 - val_loss: 11499.2646 - val_mse: 11499.2646 - val_mae: 73.9711\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12618.3467 - mse: 12618.3467 - mae: 74.5511 - val_loss: 11418.3398 - val_mse: 11418.3398 - val_mae: 78.6665\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 11871.5664 - mse: 11871.5664 - mae: 72.9667 - val_loss: 10045.1924 - val_mse: 10045.1924 - val_mae: 64.9010\n","Epoch 5/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 11459.9697 - mse: 11459.9697 - mae: 70.1482 - val_loss: 10274.8486 - val_mse: 10274.8486 - val_mae: 63.3247\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11050.7754 - mse: 11050.7754 - mae: 68.8918 - val_loss: 9656.7227 - val_mse: 9656.7227 - val_mae: 63.0148\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11085.1885 - mse: 11085.1885 - mae: 68.8441 - val_loss: 9709.3008 - val_mse: 9709.3008 - val_mae: 67.3193\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11015.2959 - mse: 11015.2959 - mae: 68.5617 - val_loss: 9595.3662 - val_mse: 9595.3662 - val_mae: 68.1132\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 10877.0029 - mse: 10877.0029 - mae: 68.1503 - val_loss: 9853.2969 - val_mse: 9853.2969 - val_mae: 70.0315\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 10746.0312 - mse: 10746.0312 - mae: 68.0441 - val_loss: 9345.7188 - val_mse: 9345.7188 - val_mae: 63.2521\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 10746.0312 mean_squared_error: 10746.0312 mean_absolute_error: 68.0441 val_loss: 9345.7188 val_mean_squared_error: 9345.7188 val_mean_absolute_error: 63.2521\n","Model: \"sequential_188\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_597 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_598 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_221 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_599 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_222 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_600 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 3ms/step - loss: 21404.2852 - mse: 21404.2852 - mae: 101.8024 - val_loss: 13217.7988 - val_mse: 13217.7988 - val_mae: 76.0563\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14547.5049 - mse: 14547.5049 - mae: 81.9976 - val_loss: 12422.7627 - val_mse: 12422.7627 - val_mae: 71.7972\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13927.6562 - mse: 13927.6562 - mae: 79.2770 - val_loss: 11501.0352 - val_mse: 11501.0352 - val_mae: 70.4451\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13111.1670 - mse: 13111.1670 - mae: 76.7479 - val_loss: 10936.6982 - val_mse: 10936.6982 - val_mae: 67.5057\n","Epoch 5/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12804.5557 - mse: 12804.5557 - mae: 74.5882 - val_loss: 10348.1807 - val_mse: 10348.1807 - val_mae: 69.6268\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 11902.8389 - mse: 11902.8389 - mae: 72.3388 - val_loss: 10332.6074 - val_mse: 10332.6074 - val_mae: 72.0142\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11628.3691 - mse: 11628.3691 - mae: 70.5409 - val_loss: 10001.1230 - val_mse: 10001.1230 - val_mae: 62.3393\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 11304.0068 - mse: 11304.0068 - mae: 69.5074 - val_loss: 9592.7949 - val_mse: 9592.7949 - val_mae: 62.7162\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 11194.1836 - mse: 11194.1836 - mae: 68.0081 - val_loss: 8988.3594 - val_mse: 8988.3594 - val_mae: 62.5071\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 11104.9414 - mse: 11104.9414 - mae: 67.5229 - val_loss: 9523.0391 - val_mse: 9523.0391 - val_mae: 60.4319\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","8/8 loss: 11104.9414 mean_squared_error: 11104.9414 mean_absolute_error: 67.5229 val_loss: 9523.0391 val_mean_squared_error: 9523.0391 val_mean_absolute_error: 60.4319\n","Model: \"sequential_189\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_601 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_602 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_223 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_603 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_224 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_604 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 19131.3594 - mse: 19131.3594 - mae: 97.8925 - val_loss: 13156.3018 - val_mse: 13156.3018 - val_mae: 79.3757\n","Epoch 2/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 14335.4346 - mse: 14335.4346 - mae: 83.2883 - val_loss: 13040.4844 - val_mse: 13040.4844 - val_mae: 79.5411\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14501.5977 - mse: 14501.5977 - mae: 83.3954 - val_loss: 13367.7656 - val_mse: 13367.7656 - val_mae: 77.1026\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14380.3975 - mse: 14380.3975 - mae: 83.5146 - val_loss: 12990.1006 - val_mse: 12990.1006 - val_mae: 79.9275\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14533.9971 - mse: 14533.9971 - mae: 83.3349 - val_loss: 12975.7646 - val_mse: 12975.7646 - val_mae: 82.6737\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14173.5430 - mse: 14173.5430 - mae: 82.5804 - val_loss: 12980.0566 - val_mse: 12980.0566 - val_mae: 82.8580\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14495.5977 - mse: 14495.5977 - mae: 83.5196 - val_loss: 12955.6133 - val_mse: 12955.6133 - val_mae: 80.8775\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14135.3184 - mse: 14135.3184 - mae: 82.5404 - val_loss: 13010.2949 - val_mse: 13010.2949 - val_mae: 83.3020\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14395.0566 - mse: 14395.0566 - mae: 83.4943 - val_loss: 13075.5332 - val_mse: 13075.5332 - val_mae: 77.8773\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14390.2725 - mse: 14390.2725 - mae: 83.3256 - val_loss: 13591.9404 - val_mse: 13591.9404 - val_mae: 78.0255\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 14390.2725 mean_squared_error: 14390.2725 mean_absolute_error: 83.3256 val_loss: 13591.9404 val_mean_squared_error: 13591.9404 val_mean_absolute_error: 78.0255\n","Model: \"sequential_190\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_605 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_606 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_225 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_607 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 32504.8516 - mse: 32504.8516 - mae: 132.4242 - val_loss: 20221.9297 - val_mse: 20221.9297 - val_mae: 105.2968\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18646.2168 - mse: 18646.2168 - mae: 98.1888 - val_loss: 15161.0684 - val_mse: 15161.0684 - val_mae: 84.2571\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16206.1982 - mse: 16206.1982 - mae: 87.4843 - val_loss: 13699.2939 - val_mse: 13699.2939 - val_mae: 80.5694\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15366.1475 - mse: 15366.1475 - mae: 85.0391 - val_loss: 13151.5869 - val_mse: 13151.5869 - val_mae: 79.5067\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15357.9590 - mse: 15357.9590 - mae: 84.3908 - val_loss: 13034.0381 - val_mse: 13034.0381 - val_mae: 77.5252\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15114.9551 - mse: 15114.9551 - mae: 83.6544 - val_loss: 12760.2686 - val_mse: 12760.2686 - val_mae: 77.2181\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14785.4805 - mse: 14785.4805 - mae: 82.9848 - val_loss: 13020.1543 - val_mse: 13020.1543 - val_mae: 73.8339\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14908.0381 - mse: 14908.0381 - mae: 82.9431 - val_loss: 12327.3008 - val_mse: 12327.3008 - val_mae: 74.2794\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14060.5811 - mse: 14060.5811 - mae: 80.2818 - val_loss: 12114.6094 - val_mse: 12114.6094 - val_mae: 73.5666\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14152.8223 - mse: 14152.8223 - mae: 80.0879 - val_loss: 11808.1260 - val_mse: 11808.1260 - val_mae: 73.3636\n","163/163 [==============================] - 0s 888us/step\n","Epoch 10/10\n","8/8 loss: 14152.8223 mean_squared_error: 14152.8223 mean_absolute_error: 80.0879 val_loss: 11808.1260 val_mean_squared_error: 11808.1260 val_mean_absolute_error: 73.3636\n","Model: \"sequential_191\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_608 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_609 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_226 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_610 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 61729.7773 - mse: 61729.7773 - mae: 173.7229 - val_loss: 57388.4180 - val_mse: 57388.4180 - val_mae: 165.0573\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 52623.3438 - mse: 52623.3438 - mae: 158.0698 - val_loss: 49753.1055 - val_mse: 49753.1055 - val_mae: 153.2144\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 46095.2109 - mse: 46095.2109 - mae: 148.2357 - val_loss: 43614.8242 - val_mse: 43614.8242 - val_mae: 138.4057\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 39774.3477 - mse: 39774.3477 - mae: 130.0518 - val_loss: 37545.5742 - val_mse: 37545.5742 - val_mae: 123.5774\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 34854.5430 - mse: 34854.5430 - mae: 119.0341 - val_loss: 32962.8789 - val_mse: 32962.8789 - val_mae: 113.6451\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 30757.2871 - mse: 30757.2871 - mae: 109.6058 - val_loss: 28688.2695 - val_mse: 28688.2695 - val_mae: 101.6586\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 26791.0723 - mse: 26791.0723 - mae: 99.5972 - val_loss: 25221.8066 - val_mse: 25221.8066 - val_mae: 93.8432\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 23818.9648 - mse: 23818.9648 - mae: 93.8594 - val_loss: 22450.1387 - val_mse: 22450.1387 - val_mae: 87.2606\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 21545.4395 - mse: 21545.4395 - mae: 89.6577 - val_loss: 20197.6992 - val_mse: 20197.6992 - val_mae: 82.9299\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19495.5410 - mse: 19495.5410 - mae: 85.8264 - val_loss: 18428.2227 - val_mse: 18428.2227 - val_mae: 80.2755\n","163/163 [==============================] - 0s 921us/step\n","Epoch 10/10\n","8/8 loss: 19495.5410 mean_squared_error: 19495.5410 mean_absolute_error: 85.8264 val_loss: 18428.2227 val_mean_squared_error: 18428.2227 val_mean_absolute_error: 80.2755\n","Model: \"sequential_192\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_611 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_612 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_227 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_613 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 31394.2539 - mse: 31394.2539 - mae: 129.1790 - val_loss: 17523.4648 - val_mse: 17523.4648 - val_mae: 95.9109\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17224.8555 - mse: 17224.8555 - mae: 92.4037 - val_loss: 13797.6426 - val_mse: 13797.6426 - val_mae: 81.1955\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15419.4131 - mse: 15419.4131 - mae: 86.0470 - val_loss: 12972.9609 - val_mse: 12972.9609 - val_mae: 78.5648\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14986.8340 - mse: 14986.8340 - mae: 83.4545 - val_loss: 12400.6084 - val_mse: 12400.6084 - val_mae: 75.8614\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14084.1084 - mse: 14084.1084 - mae: 80.8268 - val_loss: 12002.3877 - val_mse: 12002.3877 - val_mae: 73.9160\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13498.3740 - mse: 13498.3740 - mae: 78.8452 - val_loss: 11488.5479 - val_mse: 11488.5479 - val_mae: 72.9934\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13359.2061 - mse: 13359.2061 - mae: 77.0491 - val_loss: 11386.1465 - val_mse: 11386.1465 - val_mae: 77.1565\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12979.0781 - mse: 12979.0781 - mae: 75.2454 - val_loss: 10760.2891 - val_mse: 10760.2891 - val_mae: 71.0352\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12251.9941 - mse: 12251.9941 - mae: 73.2968 - val_loss: 10490.6357 - val_mse: 10490.6357 - val_mae: 66.9356\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12244.7930 - mse: 12244.7930 - mae: 73.3180 - val_loss: 10380.8252 - val_mse: 10380.8252 - val_mae: 65.4410\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 12244.7930 mean_squared_error: 12244.7930 mean_absolute_error: 73.3180 val_loss: 10380.8252 val_mean_squared_error: 10380.8252 val_mean_absolute_error: 65.4410\n","Model: \"sequential_193\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_614 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_615 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_228 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_616 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 34076.5938 - mse: 34076.5938 - mae: 135.1907 - val_loss: 20452.8203 - val_mse: 20452.8203 - val_mae: 106.9925\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19200.1738 - mse: 19200.1738 - mae: 98.9977 - val_loss: 15140.1719 - val_mse: 15140.1719 - val_mae: 87.4348\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16693.0664 - mse: 16693.0664 - mae: 88.9739 - val_loss: 13909.1504 - val_mse: 13909.1504 - val_mae: 79.5655\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16164.2207 - mse: 16164.2207 - mae: 87.2991 - val_loss: 13402.9229 - val_mse: 13402.9229 - val_mae: 77.5522\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15793.7246 - mse: 15793.7246 - mae: 85.4767 - val_loss: 13017.3779 - val_mse: 13017.3779 - val_mae: 81.9404\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15316.7480 - mse: 15316.7480 - mae: 84.9172 - val_loss: 12949.3037 - val_mse: 12949.3037 - val_mae: 75.8502\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15226.1348 - mse: 15226.1348 - mae: 83.9528 - val_loss: 12612.2852 - val_mse: 12612.2852 - val_mae: 76.0806\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15103.4287 - mse: 15103.4287 - mae: 83.2074 - val_loss: 12366.3516 - val_mse: 12366.3516 - val_mae: 75.9572\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15025.4111 - mse: 15025.4111 - mae: 82.9530 - val_loss: 12156.6816 - val_mse: 12156.6816 - val_mae: 76.1561\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14289.5771 - mse: 14289.5771 - mae: 80.5814 - val_loss: 12109.6982 - val_mse: 12109.6982 - val_mae: 73.1425\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 14289.5771 mean_squared_error: 14289.5771 mean_absolute_error: 80.5814 val_loss: 12109.6982 val_mean_squared_error: 12109.6982 val_mean_absolute_error: 73.1425\n","Model: \"sequential_194\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_617 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_618 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_229 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_619 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 29801.8730 - mse: 29801.8730 - mae: 127.4520 - val_loss: 18813.3809 - val_mse: 18813.3809 - val_mae: 103.7437\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17062.0312 - mse: 17062.0312 - mae: 93.6430 - val_loss: 14502.6875 - val_mse: 14502.6875 - val_mae: 87.0495\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 15309.8730 - mse: 15309.8730 - mae: 86.3092 - val_loss: 13515.7217 - val_mse: 13515.7217 - val_mae: 82.6825\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14481.8076 - mse: 14481.8076 - mae: 83.6424 - val_loss: 13305.7031 - val_mse: 13305.7031 - val_mae: 84.6327\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14208.6543 - mse: 14208.6543 - mae: 82.9738 - val_loss: 13146.1865 - val_mse: 13146.1865 - val_mae: 78.7068\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 14381.5391 - mse: 14381.5391 - mae: 82.8043 - val_loss: 13106.3408 - val_mse: 13106.3408 - val_mae: 78.1606\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14245.6084 - mse: 14245.6084 - mae: 82.8713 - val_loss: 12960.9980 - val_mse: 12960.9980 - val_mae: 80.1265\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14370.3623 - mse: 14370.3623 - mae: 82.9724 - val_loss: 12940.0205 - val_mse: 12940.0205 - val_mae: 79.9272\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14456.9385 - mse: 14456.9385 - mae: 83.4015 - val_loss: 12965.2051 - val_mse: 12965.2051 - val_mae: 82.3321\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 14153.2754 - mse: 14153.2754 - mae: 82.7646 - val_loss: 12935.2607 - val_mse: 12935.2607 - val_mae: 79.1407\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","8/8 loss: 14153.2754 mean_squared_error: 14153.2754 mean_absolute_error: 82.7646 val_loss: 12935.2607 val_mean_squared_error: 12935.2607 val_mean_absolute_error: 79.1407\n","Model: \"sequential_195\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_620 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_621 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_230 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_622 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_231 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_623 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 24686.3516 - mse: 24686.3516 - mae: 110.7357 - val_loss: 13834.5664 - val_mse: 13834.5664 - val_mae: 79.7314\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 16282.6133 - mse: 16282.6133 - mae: 86.9267 - val_loss: 13392.5215 - val_mse: 13392.5215 - val_mae: 74.3192\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15395.5039 - mse: 15395.5039 - mae: 83.4520 - val_loss: 11924.0732 - val_mse: 11924.0732 - val_mae: 78.7458\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 14151.4736 - mse: 14151.4736 - mae: 79.4440 - val_loss: 11210.6260 - val_mse: 11210.6260 - val_mae: 67.0299\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14016.5684 - mse: 14016.5684 - mae: 77.6415 - val_loss: 11542.7012 - val_mse: 11542.7012 - val_mae: 65.4210\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13554.6289 - mse: 13554.6289 - mae: 76.1765 - val_loss: 10115.2158 - val_mse: 10115.2158 - val_mae: 67.7389\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13008.0156 - mse: 13008.0156 - mae: 74.4043 - val_loss: 9771.1953 - val_mse: 9771.1953 - val_mae: 67.5823\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12834.3916 - mse: 12834.3916 - mae: 73.3531 - val_loss: 9892.1113 - val_mse: 9892.1113 - val_mae: 63.9518\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12745.6826 - mse: 12745.6826 - mae: 72.4087 - val_loss: 9970.2578 - val_mse: 9970.2578 - val_mae: 62.7875\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12593.1592 - mse: 12593.1592 - mae: 72.8288 - val_loss: 9302.6152 - val_mse: 9302.6152 - val_mae: 62.2186\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","8/8 loss: 12593.1592 mean_squared_error: 12593.1592 mean_absolute_error: 72.8288 val_loss: 9302.6152 val_mean_squared_error: 9302.6152 val_mean_absolute_error: 62.2186\n","Model: \"sequential_196\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_624 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_625 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_232 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_626 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_233 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_627 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 61854.6445 - mse: 61854.6445 - mae: 173.7415 - val_loss: 57692.0039 - val_mse: 57692.0039 - val_mae: 165.5666\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 52914.5781 - mse: 52914.5781 - mae: 158.4645 - val_loss: 49974.5898 - val_mse: 49974.5898 - val_mae: 153.5391\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 46363.6328 - mse: 46363.6328 - mae: 149.1577 - val_loss: 44320.9727 - val_mse: 44320.9727 - val_mae: 145.9376\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 41735.9492 - mse: 41735.9492 - mae: 143.5523 - val_loss: 40309.1016 - val_mse: 40309.1016 - val_mae: 141.6052\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 38559.7539 - mse: 38559.7539 - mae: 140.5878 - val_loss: 37592.5078 - val_mse: 37592.5078 - val_mae: 139.6025\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 33785.7617 - mse: 33785.7617 - mae: 123.2757 - val_loss: 31175.6523 - val_mse: 31175.6523 - val_mae: 113.2493\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 28727.9941 - mse: 28727.9941 - mae: 105.7415 - val_loss: 26743.1777 - val_mse: 26743.1777 - val_mae: 98.8348\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25344.0781 - mse: 25344.0781 - mae: 98.1642 - val_loss: 23659.2109 - val_mse: 23659.2109 - val_mae: 90.7560\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 22828.4961 - mse: 22828.4961 - mae: 93.1884 - val_loss: 21070.6016 - val_mse: 21070.6016 - val_mae: 84.4902\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 20705.3613 - mse: 20705.3613 - mae: 89.3085 - val_loss: 19082.4434 - val_mse: 19082.4434 - val_mae: 79.5223\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","8/8 loss: 20705.3613 mean_squared_error: 20705.3613 mean_absolute_error: 89.3085 val_loss: 19082.4434 val_mean_squared_error: 19082.4434 val_mean_absolute_error: 79.5223\n","Model: \"sequential_197\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_628 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_629 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_234 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_630 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_235 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_631 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24670.3906 - mse: 24670.3906 - mae: 109.8503 - val_loss: 15456.7314 - val_mse: 15456.7314 - val_mae: 78.5811\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15996.7383 - mse: 15996.7383 - mae: 85.7727 - val_loss: 12383.1377 - val_mse: 12383.1377 - val_mae: 73.7890\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15019.1807 - mse: 15019.1807 - mae: 82.0186 - val_loss: 12171.7217 - val_mse: 12171.7217 - val_mae: 69.7837\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14244.8555 - mse: 14244.8555 - mae: 78.3543 - val_loss: 10896.1201 - val_mse: 10896.1201 - val_mae: 67.8715\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13415.7852 - mse: 13415.7852 - mae: 76.1054 - val_loss: 10756.6836 - val_mse: 10756.6836 - val_mae: 66.0426\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13022.8359 - mse: 13022.8359 - mae: 75.2366 - val_loss: 10680.6729 - val_mse: 10680.6729 - val_mae: 66.8932\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12738.8936 - mse: 12738.8936 - mae: 74.1205 - val_loss: 9981.9980 - val_mse: 9981.9980 - val_mae: 68.6513\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12637.0635 - mse: 12637.0635 - mae: 73.6735 - val_loss: 10300.5957 - val_mse: 10300.5957 - val_mae: 65.7614\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12672.3604 - mse: 12672.3604 - mae: 73.3850 - val_loss: 9963.9922 - val_mse: 9963.9922 - val_mae: 64.4071\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12569.0537 - mse: 12569.0537 - mae: 73.2080 - val_loss: 9881.3740 - val_mse: 9881.3740 - val_mae: 63.1903\n","163/163 [==============================] - 0s 957us/step\n","Epoch 10/10\n","8/8 loss: 12569.0537 mean_squared_error: 12569.0537 mean_absolute_error: 73.2080 val_loss: 9881.3740 val_mean_squared_error: 9881.3740 val_mean_absolute_error: 63.1903\n","Model: \"sequential_198\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_632 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_633 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_236 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_634 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_237 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_635 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 27405.4570 - mse: 27405.4570 - mae: 116.2321 - val_loss: 14220.8506 - val_mse: 14220.8506 - val_mae: 82.5256\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17734.2168 - mse: 17734.2168 - mae: 90.3094 - val_loss: 13180.6279 - val_mse: 13180.6279 - val_mae: 76.3676\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16525.6504 - mse: 16525.6504 - mae: 86.7006 - val_loss: 12702.5264 - val_mse: 12702.5264 - val_mae: 83.0013\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16099.2393 - mse: 16099.2393 - mae: 85.0971 - val_loss: 12243.2920 - val_mse: 12243.2920 - val_mae: 72.1355\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15170.5420 - mse: 15170.5420 - mae: 82.3526 - val_loss: 11455.5547 - val_mse: 11455.5547 - val_mae: 68.9383\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14887.9453 - mse: 14887.9453 - mae: 80.4564 - val_loss: 11815.0752 - val_mse: 11815.0752 - val_mae: 66.4245\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14362.5166 - mse: 14362.5166 - mae: 78.6037 - val_loss: 11125.6475 - val_mse: 11125.6475 - val_mae: 65.0107\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14008.4609 - mse: 14008.4609 - mae: 77.4286 - val_loss: 10753.2568 - val_mse: 10753.2568 - val_mae: 74.9858\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13938.8721 - mse: 13938.8721 - mae: 76.6002 - val_loss: 10316.6816 - val_mse: 10316.6816 - val_mae: 62.6179\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13294.8232 - mse: 13294.8232 - mae: 74.6222 - val_loss: 9735.6348 - val_mse: 9735.6348 - val_mae: 64.0936\n","163/163 [==============================] - 0s 987us/step\n","Epoch 10/10\n","8/8 loss: 13294.8232 mean_squared_error: 13294.8232 mean_absolute_error: 74.6222 val_loss: 9735.6348 val_mean_squared_error: 9735.6348 val_mean_absolute_error: 64.0936\n","Model: \"sequential_199\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_636 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_637 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_238 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_638 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_239 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_639 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 21801.5078 - mse: 21801.5078 - mae: 104.8264 - val_loss: 13761.6953 - val_mse: 13761.6953 - val_mae: 84.1440\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15397.4297 - mse: 15397.4297 - mae: 85.4987 - val_loss: 13266.0977 - val_mse: 13266.0977 - val_mae: 77.6787\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14931.8262 - mse: 14931.8262 - mae: 84.6336 - val_loss: 13062.0391 - val_mse: 13062.0391 - val_mae: 83.7138\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15125.5127 - mse: 15125.5127 - mae: 85.1937 - val_loss: 13264.6787 - val_mse: 13264.6787 - val_mae: 78.0501\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14959.1084 - mse: 14959.1084 - mae: 84.7705 - val_loss: 13049.7402 - val_mse: 13049.7402 - val_mae: 77.6910\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15090.1299 - mse: 15090.1299 - mae: 84.3691 - val_loss: 13040.7959 - val_mse: 13040.7959 - val_mae: 79.0823\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15044.2266 - mse: 15044.2266 - mae: 84.7176 - val_loss: 12969.7451 - val_mse: 12969.7451 - val_mae: 81.1751\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15170.7617 - mse: 15170.7617 - mae: 84.8473 - val_loss: 13098.9756 - val_mse: 13098.9756 - val_mae: 84.4308\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15218.6670 - mse: 15218.6670 - mae: 85.0934 - val_loss: 13286.2881 - val_mse: 13286.2881 - val_mae: 77.1341\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15137.4727 - mse: 15137.4727 - mae: 85.1065 - val_loss: 13346.0361 - val_mse: 13346.0361 - val_mae: 76.8217\n","163/163 [==============================] - 0s 992us/step\n","Epoch 10/10\n","8/8 loss: 15137.4727 mean_squared_error: 15137.4727 mean_absolute_error: 85.1065 val_loss: 13346.0361 val_mean_squared_error: 13346.0361 val_mean_absolute_error: 76.8217\n","Model: \"sequential_200\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_640 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_641 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 51454.1094 - mse: 51454.1094 - mae: 158.5524 - val_loss: 31771.4922 - val_mse: 31771.4922 - val_mae: 128.0461\n","163/163 [==============================] - 0s 842us/step\n","Epoch 1/1\n","12/12 loss: 51454.1094 mean_squared_error: 51454.1094 mean_absolute_error: 158.5524 val_loss: 31771.4922 val_mean_squared_error: 31771.4922 val_mean_absolute_error: 128.0461\n","Model: \"sequential_201\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_642 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_643 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 59280.2930 - mse: 59280.2930 - mae: 169.7934 - val_loss: 51920.5391 - val_mse: 51920.5391 - val_mae: 156.2397\n","163/163 [==============================] - 0s 884us/step\n","Epoch 1/1\n","12/12 loss: 59280.2930 mean_squared_error: 59280.2930 mean_absolute_error: 169.7934 val_loss: 51920.5391 val_mean_squared_error: 51920.5391 val_mean_absolute_error: 156.2397\n","Model: \"sequential_202\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_644 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_645 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 47823.1367 - mse: 47823.1367 - mae: 152.4337 - val_loss: 30783.2715 - val_mse: 30783.2715 - val_mae: 129.8013\n","163/163 [==============================] - 0s 918us/step\n","Epoch 1/1\n","12/12 loss: 47823.1367 mean_squared_error: 47823.1367 mean_absolute_error: 152.4337 val_loss: 30783.2715 val_mean_squared_error: 30783.2715 val_mean_absolute_error: 129.8013\n","Model: \"sequential_203\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_646 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_647 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 52319.4453 - mse: 52319.4453 - mae: 158.8282 - val_loss: 32541.9551 - val_mse: 32541.9551 - val_mae: 128.5507\n","163/163 [==============================] - 0s 888us/step\n","Epoch 1/1\n","12/12 loss: 52319.4453 mean_squared_error: 52319.4453 mean_absolute_error: 158.8282 val_loss: 32541.9551 val_mean_squared_error: 32541.9551 val_mean_absolute_error: 128.5507\n","Model: \"sequential_204\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_648 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_649 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 44874.8086 - mse: 44874.8125 - mae: 148.6415 - val_loss: 28706.3730 - val_mse: 28706.3730 - val_mae: 130.5527\n","163/163 [==============================] - 0s 971us/step\n","Epoch 1/1\n","12/12 loss: 44874.8086 mean_squared_error: 44874.8125 mean_absolute_error: 148.6415 val_loss: 28706.3730 val_mean_squared_error: 28706.3730 val_mean_absolute_error: 130.5527\n","Model: \"sequential_205\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_650 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_651 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_240 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_652 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 29728.1738 - mse: 29728.1738 - mae: 126.9069 - val_loss: 17857.2344 - val_mse: 17857.2344 - val_mae: 96.9315\n","163/163 [==============================] - 0s 987us/step\n","Epoch 1/1\n","12/12 loss: 29728.1738 mean_squared_error: 29728.1738 mean_absolute_error: 126.9069 val_loss: 17857.2344 val_mean_squared_error: 17857.2344 val_mean_absolute_error: 96.9315\n","Model: \"sequential_206\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_653 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_654 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_241 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_655 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 59176.8164 - mse: 59176.8164 - mae: 169.2833 - val_loss: 53643.4062 - val_mse: 53643.4023 - val_mae: 159.0409\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 59176.8164 mean_squared_error: 59176.8164 mean_absolute_error: 169.2833 val_loss: 53643.4062 val_mean_squared_error: 53643.4023 val_mean_absolute_error: 159.0409\n","Model: \"sequential_207\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_656 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_657 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_242 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_658 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 28309.2656 - mse: 28309.2656 - mae: 123.2347 - val_loss: 16464.4121 - val_mse: 16464.4121 - val_mae: 93.8223\n","163/163 [==============================] - 0s 982us/step\n","Epoch 1/1\n","12/12 loss: 28309.2656 mean_squared_error: 28309.2656 mean_absolute_error: 123.2347 val_loss: 16464.4121 val_mean_squared_error: 16464.4121 val_mean_absolute_error: 93.8223\n","Model: \"sequential_208\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_659 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_660 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_243 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_661 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 30917.1387 - mse: 30917.1387 - mae: 128.8336 - val_loss: 18452.3613 - val_mse: 18452.3613 - val_mae: 100.2819\n","163/163 [==============================] - 0s 910us/step\n","Epoch 1/1\n","12/12 loss: 30917.1387 mean_squared_error: 30917.1387 mean_absolute_error: 128.8336 val_loss: 18452.3613 val_mean_squared_error: 18452.3613 val_mean_absolute_error: 100.2819\n","Model: \"sequential_209\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_662 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_663 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_244 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_664 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 26994.5098 - mse: 26994.5078 - mae: 121.2107 - val_loss: 16886.9082 - val_mse: 16886.9082 - val_mae: 94.8273\n","163/163 [==============================] - 0s 990us/step\n","Epoch 1/1\n","12/12 loss: 26994.5098 mean_squared_error: 26994.5078 mean_absolute_error: 121.2107 val_loss: 16886.9082 val_mean_squared_error: 16886.9082 val_mean_absolute_error: 94.8273\n","Model: \"sequential_210\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_665 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_666 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_245 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_667 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_246 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_668 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 23264.3828 - mse: 23264.3828 - mae: 107.0024 - val_loss: 13549.2344 - val_mse: 13549.2344 - val_mae: 80.0010\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","12/12 loss: 23264.3828 mean_squared_error: 23264.3828 mean_absolute_error: 107.0024 val_loss: 13549.2344 val_mean_squared_error: 13549.2344 val_mean_absolute_error: 80.0010\n","Model: \"sequential_211\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_669 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_670 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_247 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_671 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_248 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_672 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 2ms/step - loss: 58677.8555 - mse: 58677.8555 - mae: 168.2261 - val_loss: 53417.7344 - val_mse: 53417.7344 - val_mae: 158.6994\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 58677.8555 mean_squared_error: 58677.8555 mean_absolute_error: 168.2261 val_loss: 53417.7344 val_mean_squared_error: 53417.7344 val_mean_absolute_error: 158.6994\n","Model: \"sequential_212\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_673 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_674 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_249 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_675 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_250 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_676 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 3ms/step - loss: 21531.9863 - mse: 21531.9863 - mae: 102.8429 - val_loss: 13238.7998 - val_mse: 13238.7998 - val_mae: 79.2651\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 21531.9863 mean_squared_error: 21531.9863 mean_absolute_error: 102.8429 val_loss: 13238.7998 val_mean_squared_error: 13238.7998 val_mean_absolute_error: 79.2651\n","Model: \"sequential_213\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_677 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_678 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_251 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_679 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_252 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_680 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 4ms/step - loss: 24437.7188 - mse: 24437.7188 - mae: 109.9716 - val_loss: 13631.8311 - val_mse: 13631.8311 - val_mae: 79.9300\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","12/12 loss: 24437.7188 mean_squared_error: 24437.7188 mean_absolute_error: 109.9716 val_loss: 13631.8311 val_mean_squared_error: 13631.8311 val_mean_absolute_error: 79.9300\n","Model: \"sequential_214\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_681 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_682 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_253 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_683 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_254 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_684 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 19582.7539 - mse: 19582.7539 - mae: 99.6372 - val_loss: 13390.7764 - val_mse: 13390.7764 - val_mae: 80.1556\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 19582.7539 mean_squared_error: 19582.7539 mean_absolute_error: 99.6372 val_loss: 13390.7764 val_mean_squared_error: 13390.7764 val_mean_absolute_error: 80.1556\n","Model: \"sequential_215\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_685 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_686 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_255 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_687 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 3ms/step - loss: 36359.3359 - mse: 36359.3359 - mae: 139.6619 - val_loss: 22900.4922 - val_mse: 22900.4922 - val_mae: 117.2231\n","163/163 [==============================] - 0s 961us/step\n","Epoch 1/1\n","12/12 loss: 36359.3359 mean_squared_error: 36359.3359 mean_absolute_error: 139.6619 val_loss: 22900.4922 val_mean_squared_error: 22900.4922 val_mean_absolute_error: 117.2231\n","Model: \"sequential_216\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_688 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_689 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_256 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_690 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 63104.1562 - mse: 63104.1562 - mae: 176.2828 - val_loss: 60020.9727 - val_mse: 60020.9805 - val_mae: 169.5492\n","163/163 [==============================] - 0s 949us/step\n","Epoch 1/1\n","12/12 loss: 63104.1562 mean_squared_error: 63104.1562 mean_absolute_error: 176.2828 val_loss: 60020.9727 val_mean_squared_error: 60020.9805 val_mean_absolute_error: 169.5492\n","Model: \"sequential_217\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_691 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_692 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_257 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_693 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 34619.4141 - mse: 34619.4141 - mae: 136.1060 - val_loss: 21085.9688 - val_mse: 21085.9688 - val_mae: 108.9136\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 34619.4141 mean_squared_error: 34619.4141 mean_absolute_error: 136.1060 val_loss: 21085.9688 val_mean_squared_error: 21085.9688 val_mean_absolute_error: 108.9136\n","Model: \"sequential_218\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_694 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_695 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_258 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_696 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 34414.3164 - mse: 34414.3164 - mae: 135.3726 - val_loss: 20846.8203 - val_mse: 20846.8164 - val_mae: 110.7183\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","12/12 loss: 34414.3164 mean_squared_error: 34414.3164 mean_absolute_error: 135.3726 val_loss: 20846.8203 val_mean_squared_error: 20846.8164 val_mean_absolute_error: 110.7183\n","Model: \"sequential_219\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_697 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_698 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_259 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_699 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 31964.6250 - mse: 31964.6250 - mae: 131.7285 - val_loss: 20790.8281 - val_mse: 20790.8281 - val_mae: 108.8281\n","163/163 [==============================] - 0s 930us/step\n","Epoch 1/1\n","12/12 loss: 31964.6250 mean_squared_error: 31964.6250 mean_absolute_error: 131.7285 val_loss: 20790.8281 val_mean_squared_error: 20790.8281 val_mean_absolute_error: 108.8281\n","Model: \"sequential_220\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_700 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_701 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_260 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_702 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_261 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_703 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 4ms/step - loss: 27514.4766 - mse: 27514.4766 - mae: 117.7070 - val_loss: 14988.6631 - val_mse: 14988.6631 - val_mae: 82.2648\n","163/163 [==============================] - 0s 995us/step\n","Epoch 1/1\n","12/12 loss: 27514.4766 mean_squared_error: 27514.4766 mean_absolute_error: 117.7070 val_loss: 14988.6631 val_mean_squared_error: 14988.6631 val_mean_absolute_error: 82.2648\n","Model: \"sequential_221\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_704 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_705 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_262 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_706 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_263 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_707 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 63634.6484 - mse: 63634.6484 - mae: 177.2553 - val_loss: 60757.4375 - val_mse: 60757.4414 - val_mae: 170.8680\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 63634.6484 mean_squared_error: 63634.6484 mean_absolute_error: 177.2553 val_loss: 60757.4375 val_mean_squared_error: 60757.4414 val_mean_absolute_error: 170.8680\n","Model: \"sequential_222\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_708 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_709 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_264 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_710 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_265 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_711 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 25727.8477 - mse: 25727.8477 - mae: 112.6976 - val_loss: 14322.9434 - val_mse: 14322.9434 - val_mae: 80.7087\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 25727.8477 mean_squared_error: 25727.8477 mean_absolute_error: 112.6976 val_loss: 14322.9434 val_mean_squared_error: 14322.9434 val_mean_absolute_error: 80.7087\n","Model: \"sequential_223\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_712 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_713 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_266 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_714 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_267 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_715 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 4ms/step - loss: 27358.1465 - mse: 27358.1465 - mae: 116.5388 - val_loss: 14430.0244 - val_mse: 14430.0254 - val_mae: 83.2119\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 27358.1465 mean_squared_error: 27358.1465 mean_absolute_error: 116.5388 val_loss: 14430.0244 val_mean_squared_error: 14430.0254 val_mean_absolute_error: 83.2119\n","Model: \"sequential_224\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_716 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_717 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_268 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_718 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_269 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_719 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 24951.2969 - mse: 24951.2969 - mae: 112.9097 - val_loss: 14334.8789 - val_mse: 14334.8789 - val_mae: 85.8740\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","12/12 loss: 24951.2969 mean_squared_error: 24951.2969 mean_absolute_error: 112.9097 val_loss: 14334.8789 val_mean_squared_error: 14334.8789 val_mean_absolute_error: 85.8740\n","Model: \"sequential_225\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_720 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_721 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 50197.5195 - mse: 50197.5195 - mae: 156.3112 - val_loss: 31142.4004 - val_mse: 31142.4004 - val_mae: 128.1162\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27700.1211 - mse: 27700.1211 - mae: 126.6149 - val_loss: 25673.5371 - val_mse: 25673.5371 - val_mae: 122.8735\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23423.6973 - mse: 23423.6973 - mae: 116.2613 - val_loss: 21646.9355 - val_mse: 21646.9355 - val_mae: 111.3927\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19888.4395 - mse: 19888.4395 - mae: 105.1038 - val_loss: 18718.3145 - val_mse: 18718.3145 - val_mae: 101.9940\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 17595.5117 - mse: 17595.5117 - mae: 97.1264 - val_loss: 16935.0371 - val_mse: 16935.0371 - val_mae: 96.0892\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16181.1260 - mse: 16181.1260 - mae: 92.0802 - val_loss: 15929.0205 - val_mse: 15929.0205 - val_mae: 89.6047\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15272.8877 - mse: 15272.8877 - mae: 88.3349 - val_loss: 15056.4326 - val_mse: 15056.4326 - val_mae: 87.9491\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 14638.9482 - mse: 14638.9482 - mae: 85.6823 - val_loss: 14507.3115 - val_mse: 14507.3115 - val_mae: 85.3527\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 14167.6875 - mse: 14167.6865 - mae: 83.5748 - val_loss: 14112.4229 - val_mse: 14112.4229 - val_mae: 86.5553\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13828.9531 - mse: 13828.9531 - mae: 82.5871 - val_loss: 13740.7031 - val_mse: 13740.7031 - val_mae: 83.4952\n","163/163 [==============================] - 0s 879us/step\n","Epoch 10/10\n","12/12 loss: 13828.9531 mean_squared_error: 13828.9531 mean_absolute_error: 82.5871 val_loss: 13740.7031 val_mean_squared_error: 13740.7031 val_mean_absolute_error: 83.4952\n","Model: \"sequential_226\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_722 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_723 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 3ms/step - loss: 59367.9688 - mse: 59367.9688 - mae: 170.0018 - val_loss: 51921.0078 - val_mse: 51921.0078 - val_mae: 156.2293\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 46320.4766 - mse: 46320.4766 - mae: 148.9210 - val_loss: 42964.7266 - val_mse: 42964.7266 - val_mae: 144.0071\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 39566.2070 - mse: 39566.2070 - mae: 140.6803 - val_loss: 37895.7578 - val_mse: 37895.7578 - val_mae: 138.9075\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 35113.6133 - mse: 35113.6133 - mae: 133.4389 - val_loss: 33154.9297 - val_mse: 33154.9297 - val_mae: 125.5661\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 30210.3984 - mse: 30210.3984 - mae: 118.3078 - val_loss: 28621.9707 - val_mse: 28621.9707 - val_mae: 113.4218\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 26233.5312 - mse: 26233.5312 - mae: 108.2396 - val_loss: 25236.5000 - val_mse: 25236.5000 - val_mae: 105.1515\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23255.7598 - mse: 23255.7578 - mae: 101.0339 - val_loss: 22589.6348 - val_mse: 22589.6348 - val_mae: 101.5987\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 20858.9199 - mse: 20858.9199 - mae: 95.7558 - val_loss: 20343.4590 - val_mse: 20343.4590 - val_mae: 96.1329\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 18792.8809 - mse: 18792.8828 - mae: 90.7811 - val_loss: 18364.3555 - val_mse: 18364.3555 - val_mae: 90.0390\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17008.7188 - mse: 17008.7188 - mae: 85.8151 - val_loss: 16705.0410 - val_mse: 16705.0410 - val_mae: 86.7576\n","163/163 [==============================] - 0s 904us/step\n","Epoch 10/10\n","12/12 loss: 17008.7188 mean_squared_error: 17008.7188 mean_absolute_error: 85.8151 val_loss: 16705.0410 val_mean_squared_error: 16705.0410 val_mean_absolute_error: 86.7576\n","Model: \"sequential_227\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_724 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_725 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 47942.4531 - mse: 47942.4531 - mae: 152.8804 - val_loss: 30362.2930 - val_mse: 30362.2930 - val_mae: 129.7702\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 28050.1523 - mse: 28050.1523 - mae: 129.0348 - val_loss: 26493.4160 - val_mse: 26493.4160 - val_mae: 125.7658\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23812.2266 - mse: 23812.2266 - mae: 117.6784 - val_loss: 21828.8711 - val_mse: 21828.8711 - val_mae: 112.6421\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19960.8438 - mse: 19960.8438 - mae: 105.5921 - val_loss: 18742.2109 - val_mse: 18742.2109 - val_mae: 105.3539\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17411.9648 - mse: 17411.9648 - mae: 97.0366 - val_loss: 16705.1992 - val_mse: 16705.1992 - val_mae: 93.2170\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15900.2549 - mse: 15900.2549 - mae: 90.5130 - val_loss: 15497.8867 - val_mse: 15497.8867 - val_mae: 89.9259\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14990.9033 - mse: 14990.9033 - mae: 87.1391 - val_loss: 14752.3340 - val_mse: 14752.3340 - val_mae: 86.9643\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14371.3359 - mse: 14371.3359 - mae: 84.5690 - val_loss: 14228.2256 - val_mse: 14228.2256 - val_mae: 85.2270\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13950.5449 - mse: 13950.5449 - mae: 83.1610 - val_loss: 13975.9248 - val_mse: 13975.9248 - val_mae: 81.6442\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13645.2773 - mse: 13645.2773 - mae: 81.6095 - val_loss: 13545.9082 - val_mse: 13545.9082 - val_mae: 82.9306\n","163/163 [==============================] - 0s 872us/step\n","Epoch 10/10\n","12/12 loss: 13645.2773 mean_squared_error: 13645.2773 mean_absolute_error: 81.6095 val_loss: 13545.9082 val_mean_squared_error: 13545.9082 val_mean_absolute_error: 82.9306\n","Model: \"sequential_228\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_726 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_727 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 49375.8555 - mse: 49375.8555 - mae: 155.3086 - val_loss: 30687.6582 - val_mse: 30687.6582 - val_mae: 128.0176\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27455.7871 - mse: 27455.7891 - mae: 126.2667 - val_loss: 25406.2949 - val_mse: 25406.2949 - val_mae: 123.5389\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 22917.2188 - mse: 22917.2168 - mae: 115.0111 - val_loss: 21046.7305 - val_mse: 21046.7305 - val_mae: 109.0071\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19357.5449 - mse: 19357.5449 - mae: 103.2686 - val_loss: 18302.3594 - val_mse: 18302.3594 - val_mae: 99.4340\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17252.3750 - mse: 17252.3750 - mae: 95.9341 - val_loss: 16687.2266 - val_mse: 16687.2266 - val_mae: 94.2188\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15990.3057 - mse: 15990.3057 - mae: 91.3530 - val_loss: 15780.0918 - val_mse: 15780.0918 - val_mae: 89.1200\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15186.0234 - mse: 15186.0234 - mae: 87.8053 - val_loss: 14975.2041 - val_mse: 14975.2041 - val_mae: 88.1021\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14596.8936 - mse: 14596.8936 - mae: 85.5654 - val_loss: 14458.2891 - val_mse: 14458.2891 - val_mae: 85.6875\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14155.3701 - mse: 14155.3721 - mae: 83.6596 - val_loss: 14084.8164 - val_mse: 14084.8164 - val_mae: 86.1383\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13832.1016 - mse: 13832.1016 - mae: 82.5717 - val_loss: 13782.4014 - val_mse: 13782.4014 - val_mae: 82.1489\n","163/163 [==============================] - 0s 985us/step\n","Epoch 10/10\n","12/12 loss: 13832.1016 mean_squared_error: 13832.1016 mean_absolute_error: 82.5717 val_loss: 13782.4014 val_mean_squared_error: 13782.4014 val_mean_absolute_error: 82.1489\n","Model: \"sequential_229\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_728 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_729 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 44927.9062 - mse: 44927.9062 - mae: 148.8802 - val_loss: 28635.3750 - val_mse: 28635.3750 - val_mae: 130.0706\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 26912.1777 - mse: 26912.1777 - mae: 127.3008 - val_loss: 25722.7188 - val_mse: 25722.7188 - val_mae: 125.1027\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 24167.9023 - mse: 24167.9023 - mae: 120.5441 - val_loss: 22965.7461 - val_mse: 22965.7461 - val_mae: 117.2470\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 21527.9512 - mse: 21527.9512 - mae: 112.4135 - val_loss: 20451.1992 - val_mse: 20451.1973 - val_mae: 109.3671\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19267.3984 - mse: 19267.3984 - mae: 104.4352 - val_loss: 18453.9844 - val_mse: 18453.9844 - val_mae: 102.1965\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17541.2148 - mse: 17541.2148 - mae: 97.6383 - val_loss: 17028.7832 - val_mse: 17028.7832 - val_mae: 97.6345\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16362.0186 - mse: 16362.0186 - mae: 93.1151 - val_loss: 16071.6328 - val_mse: 16071.6328 - val_mae: 91.6898\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15548.2695 - mse: 15548.2705 - mae: 89.4642 - val_loss: 15396.8271 - val_mse: 15396.8271 - val_mae: 88.3284\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14959.1758 - mse: 14959.1758 - mae: 86.7818 - val_loss: 14806.1172 - val_mse: 14806.1172 - val_mae: 87.3113\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14503.4062 - mse: 14503.4062 - mae: 85.0107 - val_loss: 14400.1436 - val_mse: 14400.1436 - val_mae: 85.1084\n","163/163 [==============================] - 0s 887us/step\n","Epoch 10/10\n","12/12 loss: 14503.4062 mean_squared_error: 14503.4062 mean_absolute_error: 85.0107 val_loss: 14400.1436 val_mean_squared_error: 14400.1436 val_mean_absolute_error: 85.1084\n","Model: \"sequential_230\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_730 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_731 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_270 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_732 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 30714.1348 - mse: 30714.1348 - mae: 127.9097 - val_loss: 18248.8203 - val_mse: 18248.8203 - val_mae: 98.5903\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16917.4336 - mse: 16917.4336 - mae: 91.7073 - val_loss: 14291.8027 - val_mse: 14291.8027 - val_mae: 83.2520\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15078.3047 - mse: 15078.3047 - mae: 84.5132 - val_loss: 13472.1729 - val_mse: 13472.1758 - val_mae: 78.1556\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14513.3086 - mse: 14513.3096 - mae: 82.5159 - val_loss: 13107.4326 - val_mse: 13107.4326 - val_mae: 77.4319\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14458.3535 - mse: 14458.3535 - mae: 82.2553 - val_loss: 12767.6953 - val_mse: 12767.6953 - val_mae: 81.1630\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14093.0771 - mse: 14093.0771 - mae: 81.2611 - val_loss: 12548.9072 - val_mse: 12548.9072 - val_mae: 80.3515\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13923.5293 - mse: 13923.5293 - mae: 80.7539 - val_loss: 12241.2568 - val_mse: 12241.2568 - val_mae: 77.1487\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13827.1133 - mse: 13827.1133 - mae: 79.6203 - val_loss: 12054.5596 - val_mse: 12054.5596 - val_mae: 76.9218\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13401.2979 - mse: 13401.2979 - mae: 77.9288 - val_loss: 11812.8486 - val_mse: 11812.8486 - val_mae: 74.9602\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13060.2031 - mse: 13060.2031 - mae: 77.4318 - val_loss: 11595.8467 - val_mse: 11595.8467 - val_mae: 72.6345\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 13060.2031 mean_squared_error: 13060.2031 mean_absolute_error: 77.4318 val_loss: 11595.8467 val_mean_squared_error: 11595.8467 val_mean_absolute_error: 72.6345\n","Model: \"sequential_231\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_733 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_734 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_271 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_735 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 59332.8203 - mse: 59332.8203 - mae: 169.4306 - val_loss: 53749.1914 - val_mse: 53749.1875 - val_mae: 159.2047\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 48433.3008 - mse: 48433.3008 - mae: 151.8913 - val_loss: 45138.2305 - val_mse: 45138.2305 - val_mae: 146.9218\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 40442.3828 - mse: 40442.3828 - mae: 133.6412 - val_loss: 37062.0312 - val_mse: 37062.0312 - val_mae: 123.1998\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 33439.4805 - mse: 33439.4805 - mae: 115.5536 - val_loss: 30954.1172 - val_mse: 30954.1172 - val_mae: 107.2846\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27994.5176 - mse: 27994.5176 - mae: 101.9774 - val_loss: 26037.6973 - val_mse: 26037.6973 - val_mae: 95.4659\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23867.9863 - mse: 23867.9863 - mae: 93.1785 - val_loss: 22306.6797 - val_mse: 22306.6797 - val_mae: 88.0029\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20720.2109 - mse: 20720.2109 - mae: 86.3801 - val_loss: 19474.5078 - val_mse: 19474.5078 - val_mae: 81.3651\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18345.7031 - mse: 18345.7031 - mae: 82.2305 - val_loss: 17290.7676 - val_mse: 17290.7676 - val_mae: 77.0917\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16651.5586 - mse: 16651.5586 - mae: 79.5523 - val_loss: 15660.5078 - val_mse: 15660.5098 - val_mae: 74.7787\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15349.0869 - mse: 15349.0869 - mae: 77.7281 - val_loss: 14394.6299 - val_mse: 14394.6299 - val_mae: 72.6752\n","163/163 [==============================] - 0s 901us/step\n","Epoch 10/10\n","12/12 loss: 15349.0869 mean_squared_error: 15349.0869 mean_absolute_error: 77.7281 val_loss: 14394.6299 val_mean_squared_error: 14394.6299 val_mean_absolute_error: 72.6752\n","Model: \"sequential_232\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_736 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_737 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_272 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_738 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 28633.0254 - mse: 28633.0254 - mae: 123.8581 - val_loss: 16793.1875 - val_mse: 16793.1875 - val_mae: 95.3753\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16214.1201 - mse: 16214.1201 - mae: 89.7456 - val_loss: 13750.9932 - val_mse: 13750.9951 - val_mae: 81.3937\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14525.0088 - mse: 14525.0088 - mae: 83.4948 - val_loss: 12871.5000 - val_mse: 12871.5000 - val_mae: 82.1006\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13788.7910 - mse: 13788.7910 - mae: 81.4416 - val_loss: 12548.4766 - val_mse: 12548.4766 - val_mae: 74.6431\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13333.6709 - mse: 13333.6709 - mae: 78.8337 - val_loss: 11885.3438 - val_mse: 11885.3447 - val_mae: 72.9683\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12932.1689 - mse: 12932.1689 - mae: 76.2666 - val_loss: 11276.6211 - val_mse: 11276.6211 - val_mae: 74.2968\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12155.3691 - mse: 12155.3691 - mae: 73.8123 - val_loss: 10920.3770 - val_mse: 10920.3779 - val_mae: 72.9979\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11635.0391 - mse: 11635.0391 - mae: 71.7520 - val_loss: 10853.7139 - val_mse: 10853.7139 - val_mae: 67.1551\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11497.3281 - mse: 11497.3281 - mae: 71.4031 - val_loss: 10589.0029 - val_mse: 10589.0029 - val_mae: 68.0267\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11343.9521 - mse: 11343.9521 - mae: 70.5669 - val_loss: 10425.2363 - val_mse: 10425.2363 - val_mae: 68.1410\n","163/163 [==============================] - 0s 934us/step\n","Epoch 10/10\n","12/12 loss: 11343.9521 mean_squared_error: 11343.9521 mean_absolute_error: 70.5669 val_loss: 10425.2363 val_mean_squared_error: 10425.2363 val_mean_absolute_error: 68.1410\n","Model: \"sequential_233\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_739 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_740 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_273 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_741 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 31029.6855 - mse: 31029.6855 - mae: 128.8974 - val_loss: 18636.0664 - val_mse: 18636.0664 - val_mae: 101.9323\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17369.3574 - mse: 17369.3574 - mae: 93.3469 - val_loss: 14330.6289 - val_mse: 14330.6289 - val_mae: 83.3830\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14999.3408 - mse: 14999.3408 - mae: 84.1953 - val_loss: 13257.5361 - val_mse: 13257.5361 - val_mae: 79.9742\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14255.6035 - mse: 14255.6035 - mae: 81.7120 - val_loss: 12895.2852 - val_mse: 12895.2852 - val_mae: 76.8386\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14091.4512 - mse: 14091.4512 - mae: 81.3135 - val_loss: 12546.3984 - val_mse: 12546.4014 - val_mae: 78.8070\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13807.0801 - mse: 13807.0801 - mae: 80.0729 - val_loss: 12413.9961 - val_mse: 12413.9961 - val_mae: 74.5106\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13560.5869 - mse: 13560.5869 - mae: 78.9737 - val_loss: 12000.2080 - val_mse: 12000.2080 - val_mae: 74.6840\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13138.8496 - mse: 13138.8496 - mae: 77.9750 - val_loss: 11711.3096 - val_mse: 11711.3096 - val_mae: 73.5227\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12966.9209 - mse: 12966.9209 - mae: 76.4347 - val_loss: 11860.4062 - val_mse: 11860.4062 - val_mae: 69.7539\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12596.6416 - mse: 12596.6416 - mae: 75.6912 - val_loss: 11670.4092 - val_mse: 11670.4092 - val_mae: 68.4461\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 12596.6416 mean_squared_error: 12596.6416 mean_absolute_error: 75.6912 val_loss: 11670.4092 val_mean_squared_error: 11670.4092 val_mean_absolute_error: 68.4461\n","Model: \"sequential_234\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_742 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_743 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_274 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_744 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 4ms/step - loss: 27148.7500 - mse: 27148.7500 - mae: 121.1158 - val_loss: 16854.3086 - val_mse: 16854.3086 - val_mae: 92.8161\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15381.6641 - mse: 15381.6641 - mae: 87.7584 - val_loss: 13832.3574 - val_mse: 13832.3574 - val_mae: 84.2258\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14278.0527 - mse: 14278.0527 - mae: 83.1213 - val_loss: 13431.1445 - val_mse: 13431.1445 - val_mae: 79.0036\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13827.9971 - mse: 13827.9971 - mae: 81.9329 - val_loss: 13149.3604 - val_mse: 13149.3613 - val_mae: 78.1130\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13917.2031 - mse: 13917.2031 - mae: 81.8883 - val_loss: 12991.1191 - val_mse: 12991.1191 - val_mae: 79.4717\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13730.2959 - mse: 13730.2959 - mae: 81.4202 - val_loss: 12951.0381 - val_mse: 12951.0381 - val_mae: 81.6404\n","Epoch 7/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13680.7168 - mse: 13680.7168 - mae: 81.3381 - val_loss: 12974.1279 - val_mse: 12974.1279 - val_mae: 82.6627\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13508.5195 - mse: 13508.5195 - mae: 80.7538 - val_loss: 12926.7393 - val_mse: 12926.7393 - val_mae: 81.0480\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13551.7021 - mse: 13551.7021 - mae: 81.5953 - val_loss: 12936.3877 - val_mse: 12936.3877 - val_mae: 79.2578\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13731.0547 - mse: 13731.0547 - mae: 81.7477 - val_loss: 13041.2725 - val_mse: 13041.2725 - val_mae: 77.9310\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 13731.0547 mean_squared_error: 13731.0547 mean_absolute_error: 81.7477 val_loss: 13041.2725 val_mean_squared_error: 13041.2725 val_mean_absolute_error: 77.9310\n","Model: \"sequential_235\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_745 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_746 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_275 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_747 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_276 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_748 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 2ms/step - loss: 23331.5332 - mse: 23331.5332 - mae: 106.4365 - val_loss: 13520.5186 - val_mse: 13520.5186 - val_mae: 80.0680\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 15305.9365 - mse: 15305.9365 - mae: 84.0141 - val_loss: 14200.5391 - val_mse: 14200.5410 - val_mae: 73.4376\n","Epoch 3/10\n","710/710 [==============================] - 3s 4ms/step - loss: 14117.9932 - mse: 14117.9932 - mae: 79.7835 - val_loss: 11311.8047 - val_mse: 11311.8047 - val_mae: 73.1579\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13068.6074 - mse: 13068.6074 - mae: 75.9465 - val_loss: 10589.4336 - val_mse: 10589.4336 - val_mae: 70.2170\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12492.3467 - mse: 12492.3467 - mae: 73.7607 - val_loss: 10156.7695 - val_mse: 10156.7695 - val_mae: 68.3795\n","Epoch 6/10\n","710/710 [==============================] - 3s 4ms/step - loss: 11687.6904 - mse: 11687.6904 - mae: 71.6933 - val_loss: 9846.5732 - val_mse: 9846.5732 - val_mae: 63.7234\n","Epoch 7/10\n","710/710 [==============================] - 2s 2ms/step - loss: 11698.5352 - mse: 11698.5352 - mae: 71.6807 - val_loss: 10088.9199 - val_mse: 10088.9199 - val_mae: 63.2444\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 11451.3506 - mse: 11451.3506 - mae: 69.9215 - val_loss: 9290.3672 - val_mse: 9290.3672 - val_mae: 64.8566\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 11417.1807 - mse: 11417.1807 - mae: 69.9499 - val_loss: 9128.8809 - val_mse: 9128.8809 - val_mae: 63.5772\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 11251.4434 - mse: 11251.4434 - mae: 68.9045 - val_loss: 9037.8896 - val_mse: 9037.8896 - val_mae: 62.4661\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 11251.4434 mean_squared_error: 11251.4434 mean_absolute_error: 68.9045 val_loss: 9037.8896 val_mean_squared_error: 9037.8896 val_mean_absolute_error: 62.4661\n","Model: \"sequential_236\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_749 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_750 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_277 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_751 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_278 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_752 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 4ms/step - loss: 59560.1719 - mse: 59560.1719 - mae: 169.7146 - val_loss: 54161.9609 - val_mse: 54161.9609 - val_mae: 159.8608\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 48866.6133 - mse: 48866.6133 - mae: 152.5203 - val_loss: 45466.9141 - val_mse: 45466.9141 - val_mae: 147.3838\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 42052.2500 - mse: 42052.2500 - mae: 143.8527 - val_loss: 39988.1055 - val_mse: 39988.1055 - val_mae: 141.3046\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 35387.7461 - mse: 35387.7500 - mae: 124.2685 - val_loss: 31943.7676 - val_mse: 31943.7715 - val_mae: 109.8823\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 28965.0449 - mse: 28965.0449 - mae: 104.4038 - val_loss: 26671.5996 - val_mse: 26671.5996 - val_mae: 96.9329\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 24440.0488 - mse: 24440.0488 - mae: 94.5046 - val_loss: 23469.8398 - val_mse: 23469.8398 - val_mae: 91.1809\n","Epoch 7/10\n","710/710 [==============================] - 2s 3ms/step - loss: 21336.8008 - mse: 21336.8008 - mae: 88.1959 - val_loss: 19811.9492 - val_mse: 19811.9492 - val_mae: 82.8676\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 18913.0254 - mse: 18913.0254 - mae: 84.2150 - val_loss: 17493.4531 - val_mse: 17493.4531 - val_mae: 77.5054\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 16894.6484 - mse: 16894.6484 - mae: 79.9648 - val_loss: 15503.6650 - val_mse: 15503.6650 - val_mae: 72.5714\n","Epoch 10/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15642.4424 - mse: 15642.4424 - mae: 77.5852 - val_loss: 13696.0967 - val_mse: 13696.0967 - val_mae: 67.2111\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 15642.4424 mean_squared_error: 15642.4424 mean_absolute_error: 77.5852 val_loss: 13696.0967 val_mean_squared_error: 13696.0967 val_mean_absolute_error: 67.2111\n","Model: \"sequential_237\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_753 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_754 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_279 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_755 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_280 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_756 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 4ms/step - loss: 21707.1895 - mse: 21707.1895 - mae: 102.4821 - val_loss: 13387.6748 - val_mse: 13387.6748 - val_mae: 77.1578\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 14284.2354 - mse: 14284.2354 - mae: 81.6921 - val_loss: 12141.1318 - val_mse: 12141.1318 - val_mae: 73.5955\n","Epoch 3/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13188.4365 - mse: 13188.4365 - mae: 77.2646 - val_loss: 11263.1895 - val_mse: 11263.1895 - val_mae: 75.0166\n","Epoch 4/10\n","710/710 [==============================] - 3s 4ms/step - loss: 12255.1650 - mse: 12255.1650 - mae: 73.7964 - val_loss: 10428.2656 - val_mse: 10428.2656 - val_mae: 66.6957\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 11426.3369 - mse: 11426.3369 - mae: 71.5208 - val_loss: 9957.6357 - val_mse: 9957.6357 - val_mae: 66.5107\n","Epoch 6/10\n","710/710 [==============================] - 2s 2ms/step - loss: 11674.1416 - mse: 11674.1416 - mae: 71.8466 - val_loss: 9849.4893 - val_mse: 9849.4893 - val_mae: 65.5589\n","Epoch 7/10\n","710/710 [==============================] - 3s 4ms/step - loss: 11399.8291 - mse: 11399.8291 - mae: 71.0921 - val_loss: 9810.6348 - val_mse: 9810.6348 - val_mae: 63.7152\n","Epoch 8/10\n","710/710 [==============================] - 2s 2ms/step - loss: 11222.2246 - mse: 11222.2246 - mae: 70.1458 - val_loss: 9703.5410 - val_mse: 9703.5410 - val_mae: 65.6951\n","Epoch 9/10\n","710/710 [==============================] - 2s 2ms/step - loss: 11230.8984 - mse: 11230.8984 - mae: 69.9687 - val_loss: 9785.6660 - val_mse: 9785.6660 - val_mae: 67.2496\n","Epoch 10/10\n","710/710 [==============================] - 3s 4ms/step - loss: 10900.8779 - mse: 10900.8779 - mae: 68.4575 - val_loss: 10094.3701 - val_mse: 10094.3701 - val_mae: 62.5642\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 10900.8779 mean_squared_error: 10900.8779 mean_absolute_error: 68.4575 val_loss: 10094.3701 val_mean_squared_error: 10094.3701 val_mean_absolute_error: 62.5642\n","Model: \"sequential_238\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_757 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_758 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_281 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_759 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_282 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_760 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 3ms/step - loss: 23306.7949 - mse: 23306.7949 - mae: 106.9238 - val_loss: 13836.2773 - val_mse: 13836.2773 - val_mae: 75.5925\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 14659.9814 - mse: 14659.9814 - mae: 81.9383 - val_loss: 12045.0576 - val_mse: 12045.0586 - val_mae: 75.5090\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13331.9980 - mse: 13331.9980 - mae: 78.0733 - val_loss: 11187.9316 - val_mse: 11187.9316 - val_mae: 70.2709\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12882.6133 - mse: 12882.6133 - mae: 75.5193 - val_loss: 10495.3740 - val_mse: 10495.3740 - val_mae: 67.0002\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12239.5781 - mse: 12239.5781 - mae: 73.3951 - val_loss: 10806.1777 - val_mse: 10806.1777 - val_mae: 65.2421\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11676.4053 - mse: 11676.4053 - mae: 71.2325 - val_loss: 10308.1436 - val_mse: 10308.1436 - val_mae: 74.3999\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11498.1768 - mse: 11498.1768 - mae: 70.4479 - val_loss: 9764.5400 - val_mse: 9764.5391 - val_mae: 63.6064\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11298.5137 - mse: 11298.5137 - mae: 69.4447 - val_loss: 9363.8604 - val_mse: 9363.8604 - val_mae: 61.7186\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 11007.4678 - mse: 11007.4668 - mae: 68.6821 - val_loss: 9631.0840 - val_mse: 9631.0840 - val_mae: 60.9955\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 10893.3457 - mse: 10893.3457 - mae: 67.5516 - val_loss: 8866.3984 - val_mse: 8866.3984 - val_mae: 63.1599\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 10893.3457 mean_squared_error: 10893.3457 mean_absolute_error: 67.5516 val_loss: 8866.3984 val_mean_squared_error: 8866.3984 val_mean_absolute_error: 63.1599\n","Model: \"sequential_239\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_761 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_762 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_283 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_763 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_284 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_764 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 19844.5996 - mse: 19844.5996 - mae: 99.9624 - val_loss: 13323.3447 - val_mse: 13323.3457 - val_mae: 83.0120\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14595.6094 - mse: 14595.6094 - mae: 83.9056 - val_loss: 12986.6748 - val_mse: 12986.6748 - val_mae: 80.4234\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14202.3066 - mse: 14202.3066 - mae: 82.7283 - val_loss: 13431.0127 - val_mse: 13431.0127 - val_mae: 77.7103\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14257.2305 - mse: 14257.2305 - mae: 82.6081 - val_loss: 12915.9932 - val_mse: 12915.9932 - val_mae: 79.4532\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14197.3291 - mse: 14197.3291 - mae: 82.7050 - val_loss: 13383.1426 - val_mse: 13383.1416 - val_mae: 87.1204\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14355.0742 - mse: 14355.0732 - mae: 83.0462 - val_loss: 13604.5107 - val_mse: 13604.5107 - val_mae: 88.8748\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14259.1055 - mse: 14259.1055 - mae: 82.9519 - val_loss: 13045.3643 - val_mse: 13045.3643 - val_mae: 78.2672\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14127.6533 - mse: 14127.6533 - mae: 82.2245 - val_loss: 13224.6748 - val_mse: 13224.6748 - val_mae: 84.9795\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14180.4648 - mse: 14180.4648 - mae: 83.1873 - val_loss: 12986.3438 - val_mse: 12986.3438 - val_mae: 80.2974\n","Epoch 9: early stopping\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 14180.4648 mean_squared_error: 14180.4648 mean_absolute_error: 83.1873 val_loss: 12986.3438 val_mean_squared_error: 12986.3438 val_mean_absolute_error: 80.2974\n","Model: \"sequential_240\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_765 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_766 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_285 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_767 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 36184.9609 - mse: 36184.9609 - mae: 137.8126 - val_loss: 21674.0879 - val_mse: 21674.0918 - val_mae: 110.8457\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19804.5586 - mse: 19804.5586 - mae: 102.1427 - val_loss: 15694.8525 - val_mse: 15694.8525 - val_mae: 88.9067\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16715.1504 - mse: 16715.1504 - mae: 90.3277 - val_loss: 15047.1289 - val_mse: 15047.1289 - val_mae: 80.3573\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15836.7715 - mse: 15836.7715 - mae: 86.6082 - val_loss: 13601.4639 - val_mse: 13601.4639 - val_mae: 78.3463\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15410.4062 - mse: 15410.4062 - mae: 84.5288 - val_loss: 13101.5488 - val_mse: 13101.5479 - val_mae: 81.0421\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14701.1514 - mse: 14701.1514 - mae: 82.8557 - val_loss: 12866.6641 - val_mse: 12866.6641 - val_mae: 77.7672\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14775.4482 - mse: 14775.4482 - mae: 83.4125 - val_loss: 12795.2471 - val_mse: 12795.2461 - val_mae: 76.0132\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14697.6582 - mse: 14697.6582 - mae: 83.0725 - val_loss: 12486.5830 - val_mse: 12486.5830 - val_mae: 77.0226\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14675.2920 - mse: 14675.2920 - mae: 82.2393 - val_loss: 12279.6182 - val_mse: 12279.6182 - val_mae: 75.3530\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14439.8926 - mse: 14439.8926 - mae: 81.3306 - val_loss: 12055.5713 - val_mse: 12055.5713 - val_mae: 75.1809\n","163/163 [==============================] - 0s 949us/step\n","Epoch 10/10\n","12/12 loss: 14439.8926 mean_squared_error: 14439.8926 mean_absolute_error: 81.3306 val_loss: 12055.5713 val_mean_squared_error: 12055.5713 val_mean_absolute_error: 75.1809\n","Model: \"sequential_241\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_768 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_769 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_286 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_770 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 63366.3594 - mse: 63366.3594 - mae: 176.7557 - val_loss: 60373.6328 - val_mse: 60373.6328 - val_mae: 170.1774\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 56540.2383 - mse: 56540.2383 - mae: 164.3775 - val_loss: 54333.9961 - val_mse: 54333.9961 - val_mae: 160.1278\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 51052.2773 - mse: 51052.2852 - mae: 155.7503 - val_loss: 49329.0664 - val_mse: 49329.0664 - val_mae: 152.6112\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 46729.7578 - mse: 46729.7578 - mae: 149.7499 - val_loss: 45313.3633 - val_mse: 45313.3555 - val_mae: 147.0407\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 42237.3242 - mse: 42237.3242 - mae: 136.4563 - val_loss: 40467.8633 - val_mse: 40467.8633 - val_mae: 129.0751\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 37981.0430 - mse: 37981.0430 - mae: 125.1630 - val_loss: 36536.8672 - val_mse: 36536.8672 - val_mae: 120.8685\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 34392.0273 - mse: 34392.0273 - mae: 117.2507 - val_loss: 33052.4023 - val_mse: 33052.4023 - val_mae: 111.7577\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 31279.9961 - mse: 31279.9961 - mae: 109.0440 - val_loss: 29911.5586 - val_mse: 29911.5586 - val_mae: 103.8639\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 28318.5586 - mse: 28318.5586 - mae: 102.5561 - val_loss: 27235.8242 - val_mse: 27235.8242 - val_mae: 97.3112\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 25925.6484 - mse: 25925.6484 - mae: 97.6047 - val_loss: 24870.5059 - val_mse: 24870.5059 - val_mae: 92.1003\n","163/163 [==============================] - 0s 925us/step\n","Epoch 10/10\n","12/12 loss: 25925.6484 mean_squared_error: 25925.6484 mean_absolute_error: 97.6047 val_loss: 24870.5059 val_mean_squared_error: 24870.5059 val_mean_absolute_error: 92.1003\n","Model: \"sequential_242\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_771 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_772 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_287 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_773 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 35190.5391 - mse: 35190.5352 - mae: 136.3558 - val_loss: 21992.7754 - val_mse: 21992.7754 - val_mae: 109.3866\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19492.3574 - mse: 19492.3574 - mae: 100.1041 - val_loss: 15371.6494 - val_mse: 15371.6494 - val_mae: 86.0762\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16575.5566 - mse: 16575.5566 - mae: 90.2761 - val_loss: 13737.1895 - val_mse: 13737.1895 - val_mae: 82.7759\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15618.8662 - mse: 15618.8662 - mae: 86.5681 - val_loss: 13110.7383 - val_mse: 13110.7383 - val_mae: 80.9336\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15022.1143 - mse: 15022.1143 - mae: 84.5009 - val_loss: 12727.8193 - val_mse: 12727.8193 - val_mae: 76.6209\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14788.0381 - mse: 14788.0381 - mae: 83.1715 - val_loss: 12427.7256 - val_mse: 12427.7246 - val_mae: 76.0940\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14156.0664 - mse: 14156.0664 - mae: 81.0199 - val_loss: 11921.6709 - val_mse: 11921.6709 - val_mae: 74.9669\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14119.7158 - mse: 14119.7158 - mae: 80.3073 - val_loss: 12135.9697 - val_mse: 12135.9697 - val_mae: 69.4870\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13494.6865 - mse: 13494.6865 - mae: 77.3576 - val_loss: 11335.5527 - val_mse: 11335.5527 - val_mae: 69.8674\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13182.2480 - mse: 13182.2480 - mae: 75.8797 - val_loss: 11072.6904 - val_mse: 11072.6904 - val_mae: 71.0899\n","163/163 [==============================] - 0s 998us/step\n","Epoch 10/10\n","12/12 loss: 13182.2480 mean_squared_error: 13182.2480 mean_absolute_error: 75.8797 val_loss: 11072.6904 val_mean_squared_error: 11072.6904 val_mean_absolute_error: 71.0899\n","Model: \"sequential_243\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_774 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_775 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_288 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_776 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 37116.1875 - mse: 37116.1875 - mae: 140.6481 - val_loss: 22498.6543 - val_mse: 22498.6543 - val_mae: 112.8475\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20712.7773 - mse: 20712.7773 - mae: 104.7275 - val_loss: 16786.3926 - val_mse: 16786.3926 - val_mae: 89.0006\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17545.5859 - mse: 17545.5859 - mae: 92.5294 - val_loss: 14854.1738 - val_mse: 14854.1738 - val_mae: 81.3711\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16655.5957 - mse: 16655.5957 - mae: 88.0602 - val_loss: 13743.0205 - val_mse: 13743.0205 - val_mae: 80.0973\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16154.5674 - mse: 16154.5674 - mae: 87.3202 - val_loss: 13448.9590 - val_mse: 13448.9580 - val_mae: 78.1320\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15947.5020 - mse: 15947.5020 - mae: 86.0659 - val_loss: 13062.4375 - val_mse: 13062.4365 - val_mae: 80.9441\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15478.0068 - mse: 15478.0068 - mae: 85.0234 - val_loss: 12922.1934 - val_mse: 12922.1934 - val_mae: 77.4532\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15899.1035 - mse: 15899.1035 - mae: 85.8123 - val_loss: 12740.0996 - val_mse: 12740.0996 - val_mae: 80.8779\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15490.4648 - mse: 15490.4648 - mae: 84.3888 - val_loss: 12588.3662 - val_mse: 12588.3662 - val_mae: 76.3589\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15250.3545 - mse: 15250.3545 - mae: 83.8637 - val_loss: 12637.6572 - val_mse: 12637.6572 - val_mae: 74.4376\n","163/163 [==============================] - 0s 883us/step\n","Epoch 10/10\n","12/12 loss: 15250.3545 mean_squared_error: 15250.3545 mean_absolute_error: 83.8637 val_loss: 12637.6572 val_mean_squared_error: 12637.6572 val_mean_absolute_error: 74.4376\n","Model: \"sequential_244\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_777 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_778 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_289 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_779 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 32738.3340 - mse: 32738.3340 - mae: 133.0270 - val_loss: 21482.5215 - val_mse: 21482.5215 - val_mae: 108.7836\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18801.0801 - mse: 18801.0801 - mae: 100.1393 - val_loss: 15653.6025 - val_mse: 15653.6025 - val_mae: 88.1986\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15655.0889 - mse: 15655.0869 - mae: 88.1556 - val_loss: 13988.5713 - val_mse: 13988.5713 - val_mae: 82.3266\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14862.0068 - mse: 14862.0068 - mae: 85.1190 - val_loss: 13492.8672 - val_mse: 13492.8672 - val_mae: 79.8753\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14631.9287 - mse: 14631.9287 - mae: 84.1830 - val_loss: 13271.2129 - val_mse: 13271.2158 - val_mae: 79.2924\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14084.8330 - mse: 14084.8330 - mae: 82.7114 - val_loss: 13304.7188 - val_mse: 13304.7188 - val_mae: 77.4783\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14407.6865 - mse: 14407.6865 - mae: 83.5159 - val_loss: 13313.1992 - val_mse: 13313.1992 - val_mae: 77.0336\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14242.3799 - mse: 14242.3799 - mae: 82.9020 - val_loss: 13140.0039 - val_mse: 13140.0039 - val_mae: 77.9916\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14315.1426 - mse: 14315.1426 - mae: 82.7111 - val_loss: 13020.4688 - val_mse: 13020.4688 - val_mae: 78.4601\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14554.0908 - mse: 14554.0908 - mae: 83.3604 - val_loss: 12952.8047 - val_mse: 12952.8047 - val_mae: 79.0976\n","163/163 [==============================] - 0s 874us/step\n","Epoch 10/10\n","12/12 loss: 14554.0908 mean_squared_error: 14554.0908 mean_absolute_error: 83.3604 val_loss: 12952.8047 val_mean_squared_error: 12952.8047 val_mean_absolute_error: 79.0976\n","Model: \"sequential_245\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_780 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_781 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_290 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_782 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_291 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_783 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 27492.1582 - mse: 27492.1582 - mae: 117.4238 - val_loss: 14347.1602 - val_mse: 14347.1602 - val_mae: 88.3407\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16258.9258 - mse: 16258.9258 - mae: 87.2911 - val_loss: 13162.8105 - val_mse: 13162.8105 - val_mae: 77.0118\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15658.7471 - mse: 15658.7471 - mae: 84.5007 - val_loss: 12808.3965 - val_mse: 12808.3965 - val_mae: 84.4810\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15386.1113 - mse: 15386.1113 - mae: 83.3425 - val_loss: 11782.1230 - val_mse: 11782.1230 - val_mae: 73.2454\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14725.9971 - mse: 14725.9971 - mae: 81.0445 - val_loss: 11910.6748 - val_mse: 11910.6748 - val_mae: 67.6673\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14370.9561 - mse: 14370.9561 - mae: 79.4103 - val_loss: 10919.7480 - val_mse: 10919.7480 - val_mae: 71.0364\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14054.1572 - mse: 14054.1572 - mae: 78.4707 - val_loss: 10604.8047 - val_mse: 10604.8047 - val_mae: 70.4495\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13745.4980 - mse: 13745.4980 - mae: 78.1438 - val_loss: 10938.6445 - val_mse: 10938.6445 - val_mae: 67.8231\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13405.8311 - mse: 13405.8311 - mae: 76.0968 - val_loss: 10185.9297 - val_mse: 10185.9297 - val_mae: 67.5803\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13100.2695 - mse: 13100.2695 - mae: 75.2459 - val_loss: 10228.5752 - val_mse: 10228.5762 - val_mae: 70.0360\n","163/163 [==============================] - 0s 986us/step\n","Epoch 10/10\n","12/12 loss: 13100.2695 mean_squared_error: 13100.2695 mean_absolute_error: 75.2459 val_loss: 10228.5752 val_mean_squared_error: 10228.5762 val_mean_absolute_error: 70.0360\n","Model: \"sequential_246\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_784 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_785 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_292 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_786 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_293 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_787 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 63593.3477 - mse: 63593.3477 - mae: 177.1810 - val_loss: 60682.4609 - val_mse: 60682.4609 - val_mae: 170.7320\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 56775.6562 - mse: 56775.6602 - mae: 164.7353 - val_loss: 54601.6992 - val_mse: 54601.6992 - val_mae: 160.5534\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 51276.3828 - mse: 51276.3828 - mae: 156.0379 - val_loss: 49607.0898 - val_mse: 49607.0898 - val_mae: 153.0127\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 46964.4336 - mse: 46964.4336 - mae: 150.0103 - val_loss: 45533.8477 - val_mse: 45533.8477 - val_mae: 147.4706\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 43312.8672 - mse: 43312.8672 - mae: 145.1217 - val_loss: 42281.3555 - val_mse: 42281.3555 - val_mae: 143.6027\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 40502.0391 - mse: 40502.0391 - mae: 142.4188 - val_loss: 39747.6875 - val_mse: 39747.6914 - val_mae: 141.0936\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 38425.5352 - mse: 38425.5352 - mae: 140.7509 - val_loss: 37820.3281 - val_mse: 37820.3281 - val_mae: 139.7168\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 34331.6016 - mse: 34331.6016 - mae: 124.1900 - val_loss: 32106.8867 - val_mse: 32106.8867 - val_mae: 112.6250\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 30481.4277 - mse: 30481.4277 - mae: 109.5131 - val_loss: 29384.2715 - val_mse: 29384.2715 - val_mae: 103.0761\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27337.0332 - mse: 27337.0332 - mae: 101.4961 - val_loss: 26062.5703 - val_mse: 26062.5703 - val_mae: 94.9773\n","163/163 [==============================] - 0s 996us/step\n","Epoch 10/10\n","12/12 loss: 27337.0332 mean_squared_error: 27337.0332 mean_absolute_error: 101.4961 val_loss: 26062.5703 val_mean_squared_error: 26062.5703 val_mean_absolute_error: 94.9773\n","Model: \"sequential_247\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_788 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_789 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_294 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_790 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_295 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_791 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 26110.7578 - mse: 26110.7578 - mae: 113.9678 - val_loss: 14138.2217 - val_mse: 14138.2227 - val_mae: 84.4419\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16469.0957 - mse: 16469.0957 - mae: 87.9545 - val_loss: 14153.4023 - val_mse: 14153.4023 - val_mae: 75.7757\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15614.7725 - mse: 15614.7725 - mae: 84.3243 - val_loss: 13131.1816 - val_mse: 13131.1816 - val_mae: 70.9602\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14794.3516 - mse: 14794.3516 - mae: 81.3951 - val_loss: 11817.7109 - val_mse: 11817.7109 - val_mae: 73.6116\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14497.5098 - mse: 14497.5098 - mae: 79.5928 - val_loss: 11625.8906 - val_mse: 11625.8906 - val_mae: 68.0158\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13712.7930 - mse: 13712.7930 - mae: 77.0560 - val_loss: 10568.0068 - val_mse: 10568.0068 - val_mae: 70.4288\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12799.0127 - mse: 12799.0127 - mae: 74.6802 - val_loss: 10324.3496 - val_mse: 10324.3496 - val_mae: 65.7447\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12966.4502 - mse: 12966.4502 - mae: 74.8625 - val_loss: 10691.4043 - val_mse: 10691.4043 - val_mae: 65.9571\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12584.2900 - mse: 12584.2900 - mae: 74.1732 - val_loss: 10115.4531 - val_mse: 10115.4531 - val_mae: 62.8937\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12518.9736 - mse: 12518.9736 - mae: 72.9870 - val_loss: 9880.5791 - val_mse: 9880.5791 - val_mae: 63.2183\n","163/163 [==============================] - 0s 993us/step\n","Epoch 10/10\n","12/12 loss: 12518.9736 mean_squared_error: 12518.9736 mean_absolute_error: 72.9870 val_loss: 9880.5791 val_mean_squared_error: 9880.5791 val_mean_absolute_error: 63.2183\n","Model: \"sequential_248\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_792 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_793 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_296 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_794 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_297 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_795 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 30544.3262 - mse: 30544.3262 - mae: 125.1192 - val_loss: 16633.5566 - val_mse: 16633.5566 - val_mae: 85.3740\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17924.4961 - mse: 17924.4961 - mae: 91.3906 - val_loss: 14396.3223 - val_mse: 14396.3223 - val_mae: 76.3241\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16807.6387 - mse: 16807.6387 - mae: 88.0111 - val_loss: 12847.4795 - val_mse: 12847.4795 - val_mae: 78.5439\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16038.6748 - mse: 16038.6748 - mae: 85.9518 - val_loss: 13153.8105 - val_mse: 13153.8105 - val_mae: 73.2268\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15979.7236 - mse: 15979.7236 - mae: 85.2783 - val_loss: 12719.7129 - val_mse: 12719.7129 - val_mae: 74.0848\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15174.4346 - mse: 15174.4346 - mae: 82.9096 - val_loss: 12535.1543 - val_mse: 12535.1543 - val_mae: 71.7229\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15112.9248 - mse: 15112.9248 - mae: 82.2579 - val_loss: 12035.2744 - val_mse: 12035.2744 - val_mae: 71.0098\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15193.2344 - mse: 15193.2344 - mae: 82.0993 - val_loss: 11865.2070 - val_mse: 11865.2070 - val_mae: 68.1972\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14790.6621 - mse: 14790.6621 - mae: 79.9311 - val_loss: 11165.3525 - val_mse: 11165.3525 - val_mae: 69.4900\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14462.1074 - mse: 14462.1074 - mae: 79.0805 - val_loss: 11254.7500 - val_mse: 11254.7500 - val_mae: 65.9077\n","163/163 [==============================] - 0s 981us/step\n","Epoch 10/10\n","12/12 loss: 14462.1074 mean_squared_error: 14462.1074 mean_absolute_error: 79.0805 val_loss: 11254.7500 val_mean_squared_error: 11254.7500 val_mean_absolute_error: 65.9077\n","Model: \"sequential_249\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_796 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_797 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_298 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_798 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_299 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_799 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 23680.1113 - mse: 23680.1113 - mae: 109.4378 - val_loss: 14284.1865 - val_mse: 14284.1865 - val_mae: 85.7201\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15588.2246 - mse: 15588.2246 - mae: 86.5028 - val_loss: 13427.7793 - val_mse: 13427.7793 - val_mae: 86.5250\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15142.9229 - mse: 15142.9229 - mae: 85.5146 - val_loss: 12995.7998 - val_mse: 12995.7998 - val_mae: 79.9548\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15193.4023 - mse: 15193.4023 - mae: 85.1061 - val_loss: 13384.8574 - val_mse: 13384.8574 - val_mae: 78.0855\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15070.6621 - mse: 15070.6621 - mae: 84.7782 - val_loss: 12948.5703 - val_mse: 12948.5703 - val_mae: 79.1924\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15183.5078 - mse: 15183.5078 - mae: 85.2405 - val_loss: 13145.3076 - val_mse: 13145.3076 - val_mae: 78.0788\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15032.3711 - mse: 15032.3711 - mae: 84.8719 - val_loss: 13028.1348 - val_mse: 13028.1348 - val_mae: 78.7470\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14985.3037 - mse: 14985.3037 - mae: 85.0117 - val_loss: 13093.4062 - val_mse: 13093.4062 - val_mae: 79.4443\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15031.9248 - mse: 15031.9248 - mae: 84.4151 - val_loss: 12960.3867 - val_mse: 12960.3887 - val_mae: 81.2657\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14957.2939 - mse: 14957.2939 - mae: 84.4471 - val_loss: 12971.4131 - val_mse: 12971.4131 - val_mae: 78.9925\n","Epoch 10: early stopping\n","163/163 [==============================] - 0s 991us/step\n","Epoch 10/10\n","12/12 loss: 14957.2939 mean_squared_error: 14957.2939 mean_absolute_error: 84.4471 val_loss: 12971.4131 val_mean_squared_error: 12971.4131 val_mean_absolute_error: 78.9925\n","Model: \"sequential_250\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_800 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_801 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 54399.7734 - mse: 54399.7734 - mae: 162.1337 - val_loss: 35415.1094 - val_mse: 35415.1094 - val_mae: 131.5924\n","163/163 [==============================] - 0s 868us/step\n","Epoch 1/1\n","16/16 loss: 54399.7734 mean_squared_error: 54399.7734 mean_absolute_error: 162.1337 val_loss: 35415.1094 val_mean_squared_error: 35415.1094 val_mean_absolute_error: 131.5924\n","Model: \"sequential_251\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_802 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_803 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 61403.0703 - mse: 61403.0703 - mae: 173.4480 - val_loss: 55038.4609 - val_mse: 55038.4609 - val_mae: 161.1261\n","163/163 [==============================] - 0s 913us/step\n","Epoch 1/1\n","16/16 loss: 61403.0703 mean_squared_error: 61403.0703 mean_absolute_error: 173.4480 val_loss: 55038.4609 val_mean_squared_error: 55038.4609 val_mean_absolute_error: 161.1261\n","Model: \"sequential_252\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_804 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_805 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 4ms/step - loss: 52819.2969 - mse: 52819.2969 - mae: 159.6001 - val_loss: 35250.4883 - val_mse: 35250.4883 - val_mae: 131.9706\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 52819.2969 mean_squared_error: 52819.2969 mean_absolute_error: 159.6001 val_loss: 35250.4883 val_mean_squared_error: 35250.4883 val_mean_absolute_error: 131.9706\n","Model: \"sequential_253\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_806 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_807 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 56566.3672 - mse: 56566.3672 - mae: 166.0424 - val_loss: 39252.4180 - val_mse: 39252.4180 - val_mae: 136.5091\n","163/163 [==============================] - 0s 962us/step\n","Epoch 1/1\n","16/16 loss: 56566.3672 mean_squared_error: 56566.3672 mean_absolute_error: 166.0424 val_loss: 39252.4180 val_mean_squared_error: 39252.4180 val_mean_absolute_error: 136.5091\n","Model: \"sequential_254\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_808 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_809 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 49979.9180 - mse: 49979.9180 - mae: 156.1666 - val_loss: 30734.9473 - val_mse: 30734.9473 - val_mae: 128.2282\n","163/163 [==============================] - 0s 945us/step\n","Epoch 1/1\n","16/16 loss: 49979.9180 mean_squared_error: 49979.9180 mean_absolute_error: 156.1666 val_loss: 30734.9473 val_mean_squared_error: 30734.9473 val_mean_absolute_error: 128.2282\n","Model: \"sequential_255\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_810 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_811 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_300 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_812 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 33274.9102 - mse: 33274.9102 - mae: 133.1033 - val_loss: 20013.5137 - val_mse: 20013.5137 - val_mae: 105.2503\n","163/163 [==============================] - 0s 974us/step\n","Epoch 1/1\n","16/16 loss: 33274.9102 mean_squared_error: 33274.9102 mean_absolute_error: 133.1033 val_loss: 20013.5137 val_mean_squared_error: 20013.5137 val_mean_absolute_error: 105.2503\n","Model: \"sequential_256\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_813 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_814 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_301 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_815 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 60585.9844 - mse: 60585.9844 - mae: 171.6547 - val_loss: 56141.0234 - val_mse: 56141.0234 - val_mae: 163.0101\n","163/163 [==============================] - 0s 987us/step\n","Epoch 1/1\n","16/16 loss: 60585.9844 mean_squared_error: 60585.9844 mean_absolute_error: 171.6547 val_loss: 56141.0234 val_mean_squared_error: 56141.0234 val_mean_absolute_error: 163.0101\n","Model: \"sequential_257\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_816 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_817 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_302 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_818 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 31724.1348 - mse: 31724.1348 - mae: 129.6460 - val_loss: 19365.9883 - val_mse: 19365.9883 - val_mae: 98.9472\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 31724.1348 mean_squared_error: 31724.1348 mean_absolute_error: 129.6460 val_loss: 19365.9883 val_mean_squared_error: 19365.9883 val_mean_absolute_error: 98.9472\n","Model: \"sequential_258\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_819 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_820 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_303 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_821 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 33761.0312 - mse: 33761.0312 - mae: 133.8011 - val_loss: 20179.7949 - val_mse: 20179.7949 - val_mae: 106.4418\n","163/163 [==============================] - 0s 937us/step\n","Epoch 1/1\n","16/16 loss: 33761.0312 mean_squared_error: 33761.0312 mean_absolute_error: 133.8011 val_loss: 20179.7949 val_mean_squared_error: 20179.7949 val_mean_absolute_error: 106.4418\n","Model: \"sequential_259\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_822 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_823 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_304 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_824 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 30064.6055 - mse: 30064.6055 - mae: 128.4745 - val_loss: 18654.4043 - val_mse: 18654.4043 - val_mae: 102.5769\n","163/163 [==============================] - 0s 972us/step\n","Epoch 1/1\n","16/16 loss: 30064.6055 mean_squared_error: 30064.6055 mean_absolute_error: 128.4745 val_loss: 18654.4043 val_mean_squared_error: 18654.4043 val_mean_absolute_error: 102.5769\n","Model: \"sequential_260\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_825 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_826 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_305 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_827 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_306 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_828 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 25425.3086 - mse: 25425.3086 - mae: 112.3138 - val_loss: 13841.2314 - val_mse: 13841.2314 - val_mae: 80.0506\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 25425.3086 mean_squared_error: 25425.3086 mean_absolute_error: 112.3138 val_loss: 13841.2314 val_mean_squared_error: 13841.2314 val_mean_absolute_error: 80.0506\n","Model: \"sequential_261\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_829 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_830 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_307 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_831 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_308 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_832 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 2ms/step - loss: 61206.5469 - mse: 61206.5469 - mae: 172.6783 - val_loss: 56867.8789 - val_mse: 56867.8789 - val_mae: 164.2064\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 61206.5469 mean_squared_error: 61206.5469 mean_absolute_error: 172.6783 val_loss: 56867.8789 val_mean_squared_error: 56867.8789 val_mean_absolute_error: 164.2064\n","Model: \"sequential_262\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_833 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_834 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_309 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_835 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_310 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_836 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 23713.6641 - mse: 23713.6641 - mae: 108.8005 - val_loss: 13541.9551 - val_mse: 13541.9551 - val_mae: 83.4799\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 23713.6641 mean_squared_error: 23713.6641 mean_absolute_error: 108.8005 val_loss: 13541.9551 val_mean_squared_error: 13541.9551 val_mean_absolute_error: 83.4799\n","Model: \"sequential_263\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_837 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_838 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_311 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_839 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_312 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_840 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 25129.6016 - mse: 25129.6016 - mae: 112.0661 - val_loss: 14616.1270 - val_mse: 14616.1270 - val_mae: 92.0764\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 25129.6016 mean_squared_error: 25129.6016 mean_absolute_error: 112.0661 val_loss: 14616.1270 val_mean_squared_error: 14616.1270 val_mean_absolute_error: 92.0764\n","Model: \"sequential_264\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_841 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_842 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_313 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_843 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_314 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_844 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 21398.7070 - mse: 21398.7070 - mae: 103.9020 - val_loss: 13648.5557 - val_mse: 13648.5557 - val_mae: 80.7193\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 21398.7070 mean_squared_error: 21398.7070 mean_absolute_error: 103.9020 val_loss: 13648.5557 val_mean_squared_error: 13648.5557 val_mean_absolute_error: 80.7193\n","Model: \"sequential_265\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_845 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_846 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_315 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_847 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 39250.1875 - mse: 39250.1875 - mae: 143.3295 - val_loss: 24970.2578 - val_mse: 24970.2578 - val_mae: 119.4374\n","163/163 [==============================] - 0s 906us/step\n","Epoch 1/1\n","16/16 loss: 39250.1875 mean_squared_error: 39250.1875 mean_absolute_error: 143.3295 val_loss: 24970.2578 val_mean_squared_error: 24970.2578 val_mean_absolute_error: 119.4374\n","Model: \"sequential_266\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_848 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_849 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_316 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_850 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 63875.3984 - mse: 63875.3984 - mae: 177.7799 - val_loss: 61498.0312 - val_mse: 61498.0312 - val_mae: 172.2229\n","163/163 [==============================] - 0s 967us/step\n","Epoch 1/1\n","16/16 loss: 63875.3984 mean_squared_error: 63875.3984 mean_absolute_error: 177.7799 val_loss: 61498.0312 val_mean_squared_error: 61498.0312 val_mean_absolute_error: 172.2229\n","Model: \"sequential_267\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_851 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_852 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_317 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_853 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 37371.1172 - mse: 37371.1172 - mae: 141.7141 - val_loss: 24669.6660 - val_mse: 24669.6660 - val_mae: 118.2534\n","163/163 [==============================] - 0s 926us/step\n","Epoch 1/1\n","16/16 loss: 37371.1172 mean_squared_error: 37371.1172 mean_absolute_error: 141.7141 val_loss: 24669.6660 val_mean_squared_error: 24669.6660 val_mean_absolute_error: 118.2534\n","Model: \"sequential_268\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_854 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_855 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_318 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_856 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 38973.9961 - mse: 38973.9961 - mae: 143.1538 - val_loss: 24894.5137 - val_mse: 24894.5137 - val_mae: 120.9990\n","163/163 [==============================] - 0s 947us/step\n","Epoch 1/1\n","16/16 loss: 38973.9961 mean_squared_error: 38973.9961 mean_absolute_error: 143.1538 val_loss: 24894.5137 val_mean_squared_error: 24894.5137 val_mean_absolute_error: 120.9990\n","Model: \"sequential_269\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_857 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_858 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_319 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_859 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 35362.6719 - mse: 35362.6719 - mae: 136.9323 - val_loss: 23200.7852 - val_mse: 23200.7852 - val_mae: 115.9608\n","163/163 [==============================] - 0s 868us/step\n","Epoch 1/1\n","16/16 loss: 35362.6719 mean_squared_error: 35362.6719 mean_absolute_error: 136.9323 val_loss: 23200.7852 val_mean_squared_error: 23200.7852 val_mean_absolute_error: 115.9608\n","Model: \"sequential_270\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_860 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_861 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_320 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_862 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_321 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_863 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 30020.8555 - mse: 30020.8555 - mae: 124.1842 - val_loss: 15382.1250 - val_mse: 15382.1250 - val_mae: 84.4760\n","163/163 [==============================] - 0s 935us/step\n","Epoch 1/1\n","16/16 loss: 30020.8555 mean_squared_error: 30020.8555 mean_absolute_error: 124.1842 val_loss: 15382.1250 val_mean_squared_error: 15382.1250 val_mean_absolute_error: 84.4760\n","Model: \"sequential_271\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_864 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_865 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_322 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_866 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_323 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_867 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 64392.3867 - mse: 64392.3867 - mae: 178.7076 - val_loss: 62219.5547 - val_mse: 62219.5547 - val_mae: 173.5693\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 64392.3867 mean_squared_error: 64392.3867 mean_absolute_error: 178.7076 val_loss: 62219.5547 val_mean_squared_error: 62219.5547 val_mean_absolute_error: 173.5693\n","Model: \"sequential_272\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_868 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_869 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_324 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_870 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_325 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_871 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 30218.0234 - mse: 30218.0234 - mae: 124.0272 - val_loss: 15819.7236 - val_mse: 15819.7236 - val_mae: 86.9603\n","163/163 [==============================] - 0s 972us/step\n","Epoch 1/1\n","16/16 loss: 30218.0234 mean_squared_error: 30218.0234 mean_absolute_error: 124.0272 val_loss: 15819.7236 val_mean_squared_error: 15819.7236 val_mean_absolute_error: 86.9603\n","Model: \"sequential_273\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_872 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_873 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_326 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_874 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_327 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_875 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 30712.5078 - mse: 30712.5078 - mae: 125.8832 - val_loss: 16043.5898 - val_mse: 16043.5898 - val_mae: 87.3430\n","163/163 [==============================] - 0s 958us/step\n","Epoch 1/1\n","16/16 loss: 30712.5078 mean_squared_error: 30712.5078 mean_absolute_error: 125.8832 val_loss: 16043.5898 val_mean_squared_error: 16043.5898 val_mean_absolute_error: 87.3430\n","Model: \"sequential_274\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_876 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_877 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_328 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_878 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_329 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_879 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 25518.6445 - mse: 25518.6445 - mae: 115.0167 - val_loss: 14920.1494 - val_mse: 14920.1494 - val_mae: 85.7567\n","163/163 [==============================] - 0s 928us/step\n","Epoch 1/1\n","16/16 loss: 25518.6445 mean_squared_error: 25518.6445 mean_absolute_error: 115.0167 val_loss: 14920.1494 val_mean_squared_error: 14920.1494 val_mean_absolute_error: 85.7567\n","Model: \"sequential_275\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_880 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_881 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 57076.2383 - mse: 57076.2383 - mae: 166.5445 - val_loss: 39636.3789 - val_mse: 39636.3789 - val_mae: 137.1536\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 31091.4941 - mse: 31091.4941 - mae: 129.2028 - val_loss: 27842.0566 - val_mse: 27842.0566 - val_mae: 127.1872\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25726.6387 - mse: 25726.6387 - mae: 122.4848 - val_loss: 24067.2988 - val_mse: 24067.2988 - val_mae: 118.7677\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22140.9395 - mse: 22140.9395 - mae: 112.2231 - val_loss: 20739.3477 - val_mse: 20739.3477 - val_mae: 109.2011\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19310.3574 - mse: 19310.3574 - mae: 103.0277 - val_loss: 18413.3418 - val_mse: 18413.3418 - val_mae: 100.2247\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17444.9961 - mse: 17444.9961 - mae: 96.4424 - val_loss: 16948.7070 - val_mse: 16948.7070 - val_mae: 95.6850\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16281.6416 - mse: 16281.6416 - mae: 92.2990 - val_loss: 16005.4375 - val_mse: 16005.4375 - val_mae: 91.5238\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15479.8447 - mse: 15479.8447 - mae: 89.1787 - val_loss: 15305.8271 - val_mse: 15305.8271 - val_mae: 88.9551\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14899.9863 - mse: 14899.9863 - mae: 86.8234 - val_loss: 14786.1982 - val_mse: 14786.1982 - val_mae: 86.5697\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14435.7432 - mse: 14435.7432 - mae: 85.1223 - val_loss: 14371.6406 - val_mse: 14371.6406 - val_mae: 84.8579\n","163/163 [==============================] - 0s 888us/step\n","Epoch 10/10\n","16/16 loss: 14435.7432 mean_squared_error: 14435.7432 mean_absolute_error: 85.1223 val_loss: 14371.6406 val_mean_squared_error: 14371.6406 val_mean_absolute_error: 84.8579\n","Model: \"sequential_276\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_882 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_883 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 61045.8164 - mse: 61045.8164 - mae: 173.1396 - val_loss: 54654.9336 - val_mse: 54654.9336 - val_mae: 160.5358\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 49489.4727 - mse: 49489.4727 - mae: 153.1289 - val_loss: 46413.4023 - val_mse: 46413.4023 - val_mae: 148.3199\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 42865.6445 - mse: 42865.6445 - mae: 144.2772 - val_loss: 41047.8555 - val_mse: 41047.8555 - val_mae: 141.8426\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 38589.0625 - mse: 38589.0625 - mae: 139.7015 - val_loss: 37561.2539 - val_mse: 37561.2539 - val_mae: 138.3850\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 35236.8242 - mse: 35236.8242 - mae: 133.7037 - val_loss: 33856.0625 - val_mse: 33856.0625 - val_mae: 128.3302\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 31332.0254 - mse: 31332.0254 - mae: 121.4972 - val_loss: 30070.5938 - val_mse: 30070.5938 - val_mae: 117.0080\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 27900.0957 - mse: 27900.0957 - mae: 111.9431 - val_loss: 27030.2129 - val_mse: 27030.2129 - val_mae: 110.4572\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25179.1973 - mse: 25179.1973 - mae: 105.6045 - val_loss: 24620.4453 - val_mse: 24620.4453 - val_mae: 103.5258\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22973.2500 - mse: 22973.2500 - mae: 100.1908 - val_loss: 22542.6855 - val_mse: 22542.6855 - val_mae: 100.0053\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21059.0840 - mse: 21059.0840 - mae: 95.9500 - val_loss: 20705.8828 - val_mse: 20705.8828 - val_mae: 95.4568\n","163/163 [==============================] - 0s 901us/step\n","Epoch 10/10\n","16/16 loss: 21059.0840 mean_squared_error: 21059.0840 mean_absolute_error: 95.9500 val_loss: 20705.8828 val_mean_squared_error: 20705.8828 val_mean_absolute_error: 95.4568\n","Model: \"sequential_277\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_884 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_885 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 51907.1523 - mse: 51907.1523 - mae: 158.2424 - val_loss: 33937.5156 - val_mse: 33937.5156 - val_mae: 130.7746\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29440.1191 - mse: 29440.1191 - mae: 129.9466 - val_loss: 28122.3242 - val_mse: 28122.3242 - val_mae: 130.4261\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 26442.4707 - mse: 26442.4707 - mae: 125.7212 - val_loss: 24805.2070 - val_mse: 24805.2070 - val_mae: 119.5929\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22779.4375 - mse: 22779.4375 - mae: 114.6407 - val_loss: 21369.1250 - val_mse: 21369.1250 - val_mae: 111.0986\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19881.5156 - mse: 19881.5156 - mae: 105.7326 - val_loss: 18847.2578 - val_mse: 18847.2578 - val_mae: 102.8926\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17759.5254 - mse: 17759.5254 - mae: 98.0587 - val_loss: 17147.4004 - val_mse: 17147.4004 - val_mae: 95.3612\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16351.4268 - mse: 16351.4268 - mae: 92.6328 - val_loss: 15989.3838 - val_mse: 15989.3838 - val_mae: 91.5140\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15436.8135 - mse: 15436.8135 - mae: 88.7561 - val_loss: 15219.6309 - val_mse: 15219.6309 - val_mae: 90.2702\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14796.2832 - mse: 14796.2832 - mae: 86.4593 - val_loss: 14665.9287 - val_mse: 14665.9287 - val_mae: 86.3857\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14337.3896 - mse: 14337.3896 - mae: 84.4048 - val_loss: 14230.1025 - val_mse: 14230.1025 - val_mae: 85.0779\n","163/163 [==============================] - 0s 924us/step\n","Epoch 10/10\n","16/16 loss: 14337.3896 mean_squared_error: 14337.3896 mean_absolute_error: 84.4048 val_loss: 14230.1025 val_mean_squared_error: 14230.1025 val_mean_absolute_error: 85.0779\n","Model: \"sequential_278\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_886 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_887 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 55584.2305 - mse: 55584.2305 - mae: 164.4620 - val_loss: 36837.7266 - val_mse: 36837.7266 - val_mae: 133.3399\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 30057.8301 - mse: 30057.8301 - mae: 128.7505 - val_loss: 27744.0527 - val_mse: 27744.0527 - val_mae: 128.2385\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25822.4023 - mse: 25822.4023 - mae: 123.4553 - val_loss: 24281.7910 - val_mse: 24281.7910 - val_mae: 118.4317\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22442.3770 - mse: 22442.3770 - mae: 113.3646 - val_loss: 21128.6973 - val_mse: 21128.6973 - val_mae: 111.5307\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19712.2520 - mse: 19712.2520 - mae: 104.8560 - val_loss: 18811.5723 - val_mse: 18811.5723 - val_mae: 101.8508\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17840.6914 - mse: 17840.6914 - mae: 98.0554 - val_loss: 17331.2168 - val_mse: 17331.2168 - val_mae: 95.8111\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16600.0273 - mse: 16600.0273 - mae: 93.5365 - val_loss: 16299.1904 - val_mse: 16299.1904 - val_mae: 92.6949\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15746.9512 - mse: 15746.9512 - mae: 89.9807 - val_loss: 15607.2129 - val_mse: 15607.2129 - val_mae: 92.5624\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15157.8857 - mse: 15157.8857 - mae: 88.1539 - val_loss: 15035.3359 - val_mse: 15035.3359 - val_mae: 87.5696\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14678.1621 - mse: 14678.1621 - mae: 85.7999 - val_loss: 14606.5312 - val_mse: 14606.5312 - val_mae: 85.7415\n","163/163 [==============================] - 0s 943us/step\n","Epoch 10/10\n","16/16 loss: 14678.1621 mean_squared_error: 14678.1621 mean_absolute_error: 85.7999 val_loss: 14606.5312 val_mean_squared_error: 14606.5312 val_mean_absolute_error: 85.7415\n","Model: \"sequential_279\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_888 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_889 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 50110.9297 - mse: 50110.9297 - mae: 155.5971 - val_loss: 30849.4922 - val_mse: 30849.4922 - val_mae: 128.0529\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 27989.9434 - mse: 27989.9434 - mae: 128.2775 - val_loss: 26882.9492 - val_mse: 26882.9492 - val_mae: 127.7050\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25543.1465 - mse: 25543.1465 - mae: 124.0374 - val_loss: 24599.1426 - val_mse: 24599.1426 - val_mae: 122.0588\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 23293.4551 - mse: 23293.4551 - mae: 117.9253 - val_loss: 22354.0938 - val_mse: 22354.0938 - val_mae: 115.1529\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21130.1426 - mse: 21130.1426 - mae: 111.0712 - val_loss: 20275.9961 - val_mse: 20275.9961 - val_mae: 109.3746\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19248.0859 - mse: 19248.0859 - mae: 104.5863 - val_loss: 18631.3516 - val_mse: 18631.3516 - val_mae: 102.0537\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17824.3203 - mse: 17824.3203 - mae: 98.7500 - val_loss: 17384.6289 - val_mse: 17384.6289 - val_mae: 97.6044\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16756.7207 - mse: 16756.7207 - mae: 94.5737 - val_loss: 16481.7910 - val_mse: 16481.7910 - val_mae: 94.0105\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15974.4492 - mse: 15974.4492 - mae: 91.0318 - val_loss: 15809.9395 - val_mse: 15809.9395 - val_mae: 92.9711\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15393.3867 - mse: 15393.3867 - mae: 88.8180 - val_loss: 15255.3848 - val_mse: 15255.3848 - val_mae: 89.4165\n","163/163 [==============================] - 0s 853us/step\n","Epoch 10/10\n","16/16 loss: 15393.3867 mean_squared_error: 15393.3867 mean_absolute_error: 88.8180 val_loss: 15255.3848 val_mean_squared_error: 15255.3848 val_mean_absolute_error: 89.4165\n","Model: \"sequential_280\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_890 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_891 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_330 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_892 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 33108.0781 - mse: 33108.0781 - mae: 132.8949 - val_loss: 20171.4746 - val_mse: 20171.4746 - val_mae: 106.1822\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17483.5625 - mse: 17483.5625 - mae: 95.0515 - val_loss: 14729.0059 - val_mse: 14729.0059 - val_mae: 86.9648\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15211.7920 - mse: 15211.7920 - mae: 85.0132 - val_loss: 13505.6924 - val_mse: 13505.6924 - val_mae: 81.3539\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14508.7734 - mse: 14508.7734 - mae: 82.5419 - val_loss: 13082.6201 - val_mse: 13082.6201 - val_mae: 79.3162\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14264.7158 - mse: 14264.7158 - mae: 82.3592 - val_loss: 12962.1338 - val_mse: 12962.1338 - val_mae: 76.5962\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14089.4990 - mse: 14089.4990 - mae: 81.5735 - val_loss: 12584.0479 - val_mse: 12584.0479 - val_mae: 79.1143\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13615.7744 - mse: 13615.7744 - mae: 79.7531 - val_loss: 12374.9365 - val_mse: 12374.9365 - val_mae: 76.6298\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13505.9492 - mse: 13505.9492 - mae: 78.9602 - val_loss: 12180.7178 - val_mse: 12180.7178 - val_mae: 75.8638\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13337.1670 - mse: 13337.1670 - mae: 78.3141 - val_loss: 12013.0771 - val_mse: 12013.0771 - val_mae: 76.7968\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13052.2607 - mse: 13052.2607 - mae: 77.4732 - val_loss: 11832.6406 - val_mse: 11832.6406 - val_mae: 73.3573\n","163/163 [==============================] - 0s 912us/step\n","Epoch 10/10\n","16/16 loss: 13052.2607 mean_squared_error: 13052.2607 mean_absolute_error: 77.4732 val_loss: 11832.6406 val_mean_squared_error: 11832.6406 val_mean_absolute_error: 73.3573\n","Model: \"sequential_281\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_893 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_894 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_331 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_895 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 60559.4258 - mse: 60559.4258 - mae: 171.5816 - val_loss: 56028.9961 - val_mse: 56028.9961 - val_mae: 162.8289\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 51323.4727 - mse: 51323.4727 - mae: 156.0640 - val_loss: 48431.2109 - val_mse: 48431.2109 - val_mae: 151.3328\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 44901.4844 - mse: 44901.4844 - mae: 146.9668 - val_loss: 42581.0312 - val_mse: 42581.0312 - val_mae: 138.7177\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 38739.8281 - mse: 38739.8281 - mae: 128.7309 - val_loss: 36556.0039 - val_mse: 36556.0039 - val_mae: 120.8820\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 33639.9648 - mse: 33639.9648 - mae: 116.5241 - val_loss: 31936.3438 - val_mse: 31936.3438 - val_mae: 111.2877\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29374.8965 - mse: 29374.8965 - mae: 105.9947 - val_loss: 27552.2188 - val_mse: 27552.2188 - val_mae: 99.2924\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25634.3887 - mse: 25634.3887 - mae: 96.2278 - val_loss: 24260.9922 - val_mse: 24260.9922 - val_mae: 91.6842\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22663.9590 - mse: 22663.9590 - mae: 90.2590 - val_loss: 21641.4688 - val_mse: 21641.4688 - val_mae: 87.2309\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 20313.2559 - mse: 20313.2559 - mae: 85.5183 - val_loss: 19438.0469 - val_mse: 19438.0469 - val_mae: 81.2429\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18588.5527 - mse: 18588.5527 - mae: 82.5592 - val_loss: 17680.9922 - val_mse: 17680.9922 - val_mae: 78.0820\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 18588.5527 mean_squared_error: 18588.5527 mean_absolute_error: 82.5592 val_loss: 17680.9922 val_mean_squared_error: 17680.9922 val_mean_absolute_error: 78.0820\n","Model: \"sequential_282\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_896 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_897 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_332 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_898 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 30900.5586 - mse: 30900.5586 - mae: 129.3902 - val_loss: 18739.6816 - val_mse: 18739.6816 - val_mae: 105.4673\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16625.1035 - mse: 16625.1035 - mae: 91.7862 - val_loss: 14052.3213 - val_mse: 14052.3213 - val_mae: 84.9215\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14759.4404 - mse: 14759.4404 - mae: 84.8902 - val_loss: 13396.9072 - val_mse: 13396.9072 - val_mae: 77.7949\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14070.2939 - mse: 14070.2939 - mae: 81.9892 - val_loss: 12671.5371 - val_mse: 12671.5371 - val_mae: 77.6334\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13464.2539 - mse: 13464.2539 - mae: 80.2753 - val_loss: 12637.6582 - val_mse: 12637.6582 - val_mae: 74.4885\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13109.6328 - mse: 13109.6328 - mae: 78.4717 - val_loss: 12031.2217 - val_mse: 12031.2217 - val_mae: 72.9532\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12671.4717 - mse: 12671.4717 - mae: 76.2059 - val_loss: 11463.9854 - val_mse: 11463.9854 - val_mae: 72.5512\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12157.1357 - mse: 12157.1357 - mae: 74.2202 - val_loss: 11201.2285 - val_mse: 11201.2285 - val_mae: 70.5430\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11922.0215 - mse: 11922.0215 - mae: 72.8249 - val_loss: 10876.1895 - val_mse: 10876.1895 - val_mae: 68.3214\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11769.9844 - mse: 11769.9844 - mae: 71.8984 - val_loss: 10819.4102 - val_mse: 10819.4102 - val_mae: 67.3087\n","163/163 [==============================] - 0s 928us/step\n","Epoch 10/10\n","16/16 loss: 11769.9844 mean_squared_error: 11769.9844 mean_absolute_error: 71.8984 val_loss: 10819.4102 val_mean_squared_error: 10819.4102 val_mean_absolute_error: 67.3087\n","Model: \"sequential_283\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_899 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_900 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_333 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_901 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 33413.3398 - mse: 33413.3398 - mae: 133.7974 - val_loss: 19942.0195 - val_mse: 19942.0195 - val_mae: 107.5257\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17847.1016 - mse: 17847.1016 - mae: 95.4089 - val_loss: 15109.7207 - val_mse: 15109.7207 - val_mae: 83.6031\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15228.2676 - mse: 15228.2676 - mae: 85.4193 - val_loss: 13648.8135 - val_mse: 13648.8135 - val_mae: 79.4353\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14608.8535 - mse: 14608.8535 - mae: 83.0289 - val_loss: 13412.8311 - val_mse: 13412.8311 - val_mae: 76.2994\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14414.1406 - mse: 14414.1406 - mae: 81.8096 - val_loss: 12853.1631 - val_mse: 12853.1631 - val_mae: 81.6826\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13820.0830 - mse: 13820.0830 - mae: 80.3547 - val_loss: 13195.4355 - val_mse: 13195.4355 - val_mae: 73.6553\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13820.3301 - mse: 13820.3301 - mae: 80.1833 - val_loss: 12418.7949 - val_mse: 12418.7949 - val_mae: 74.2663\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13495.4199 - mse: 13495.4199 - mae: 79.2081 - val_loss: 12382.8359 - val_mse: 12382.8359 - val_mae: 72.1559\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13274.8838 - mse: 13274.8838 - mae: 77.6337 - val_loss: 11910.2178 - val_mse: 11910.2178 - val_mae: 75.4008\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12995.4863 - mse: 12995.4863 - mae: 77.5706 - val_loss: 11840.9082 - val_mse: 11840.9082 - val_mae: 77.8474\n","163/163 [==============================] - 0s 930us/step\n","Epoch 10/10\n","16/16 loss: 12995.4863 mean_squared_error: 12995.4863 mean_absolute_error: 77.5706 val_loss: 11840.9082 val_mean_squared_error: 11840.9082 val_mean_absolute_error: 77.8474\n","Model: \"sequential_284\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_902 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_903 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_334 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_904 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 29223.7617 - mse: 29223.7617 - mae: 126.2725 - val_loss: 18278.4004 - val_mse: 18278.4004 - val_mae: 101.4888\n","Epoch 2/10\n","533/533 [==============================] - 2s 4ms/step - loss: 16302.6621 - mse: 16302.6621 - mae: 91.4079 - val_loss: 14424.0820 - val_mse: 14424.0820 - val_mae: 86.5086\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14518.9307 - mse: 14518.9307 - mae: 84.3218 - val_loss: 13457.9492 - val_mse: 13457.9492 - val_mae: 83.4639\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14080.3682 - mse: 14080.3682 - mae: 82.3769 - val_loss: 13486.6279 - val_mse: 13486.6279 - val_mae: 77.4333\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13794.5830 - mse: 13794.5830 - mae: 81.9961 - val_loss: 13148.6582 - val_mse: 13148.6582 - val_mae: 78.1153\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13549.9570 - mse: 13549.9570 - mae: 80.9680 - val_loss: 13023.6953 - val_mse: 13023.6953 - val_mae: 78.5174\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13713.5059 - mse: 13713.5059 - mae: 81.0512 - val_loss: 13028.5420 - val_mse: 13028.5420 - val_mae: 78.6223\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13744.7939 - mse: 13744.7939 - mae: 81.3974 - val_loss: 13095.6670 - val_mse: 13095.6670 - val_mae: 77.6584\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13822.0811 - mse: 13822.0811 - mae: 81.3266 - val_loss: 12933.5908 - val_mse: 12933.5908 - val_mae: 81.1819\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13686.6074 - mse: 13686.6074 - mae: 81.2229 - val_loss: 12914.3984 - val_mse: 12914.3984 - val_mae: 80.7484\n","163/163 [==============================] - 0s 973us/step\n","Epoch 10/10\n","16/16 loss: 13686.6074 mean_squared_error: 13686.6074 mean_absolute_error: 81.2229 val_loss: 12914.3984 val_mean_squared_error: 12914.3984 val_mean_absolute_error: 80.7484\n","Model: \"sequential_285\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_905 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_906 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_335 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_907 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_336 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_908 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 25292.5605 - mse: 25292.5605 - mae: 112.3234 - val_loss: 14007.9717 - val_mse: 14007.9717 - val_mae: 80.8013\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15259.9219 - mse: 15259.9219 - mae: 84.2912 - val_loss: 12710.4238 - val_mse: 12710.4238 - val_mae: 76.7865\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14176.1758 - mse: 14176.1758 - mae: 81.2738 - val_loss: 12124.2939 - val_mse: 12124.2939 - val_mae: 77.2850\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13550.8174 - mse: 13550.8174 - mae: 78.4488 - val_loss: 11470.4668 - val_mse: 11470.4668 - val_mae: 69.5923\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12872.5479 - mse: 12872.5479 - mae: 75.5839 - val_loss: 11246.0566 - val_mse: 11246.0566 - val_mae: 67.2298\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12483.7793 - mse: 12483.7793 - mae: 73.8700 - val_loss: 10415.9141 - val_mse: 10415.9141 - val_mae: 64.4956\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11925.1123 - mse: 11925.1123 - mae: 71.3859 - val_loss: 9888.3643 - val_mse: 9888.3643 - val_mae: 66.4512\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11645.7334 - mse: 11645.7334 - mae: 70.6437 - val_loss: 9628.3311 - val_mse: 9628.3311 - val_mae: 67.4491\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11448.2051 - mse: 11448.2051 - mae: 69.7064 - val_loss: 9385.8135 - val_mse: 9385.8135 - val_mae: 61.6404\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11243.1035 - mse: 11243.1035 - mae: 68.9604 - val_loss: 9377.4941 - val_mse: 9377.4941 - val_mae: 60.8456\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 11243.1035 mean_squared_error: 11243.1035 mean_absolute_error: 68.9604 val_loss: 9377.4941 val_mean_squared_error: 9377.4941 val_mean_absolute_error: 60.8456\n","Model: \"sequential_286\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_909 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_910 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_337 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_911 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_338 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_912 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 60628.0117 - mse: 60628.0117 - mae: 171.5807 - val_loss: 56379.7422 - val_mse: 56379.7422 - val_mae: 163.4099\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 51699.2422 - mse: 51699.2422 - mae: 156.7528 - val_loss: 48767.6016 - val_mse: 48767.6016 - val_mae: 151.8183\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 45258.4023 - mse: 45258.4023 - mae: 147.5880 - val_loss: 43283.6328 - val_mse: 43283.6328 - val_mae: 144.7232\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 40662.5312 - mse: 40662.5312 - mae: 142.1926 - val_loss: 39135.0391 - val_mse: 39135.0391 - val_mae: 138.2984\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 35367.8164 - mse: 35367.8164 - mae: 124.3246 - val_loss: 32931.4844 - val_mse: 32931.4844 - val_mae: 113.3947\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 30003.4648 - mse: 30003.4648 - mae: 106.8235 - val_loss: 28331.6973 - val_mse: 28331.6973 - val_mae: 102.4730\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 26188.5801 - mse: 26188.5801 - mae: 97.8159 - val_loss: 24661.0586 - val_mse: 24661.0586 - val_mae: 91.8828\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 23014.4746 - mse: 23014.4746 - mae: 91.1589 - val_loss: 21757.8438 - val_mse: 21757.8438 - val_mae: 85.7150\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 20738.4258 - mse: 20738.4258 - mae: 86.6969 - val_loss: 19533.5938 - val_mse: 19533.5938 - val_mae: 80.6431\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18733.6074 - mse: 18733.6074 - mae: 83.0127 - val_loss: 18267.2246 - val_mse: 18267.2246 - val_mae: 82.0352\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 18733.6074 mean_squared_error: 18733.6074 mean_absolute_error: 83.0127 val_loss: 18267.2246 val_mean_squared_error: 18267.2246 val_mean_absolute_error: 82.0352\n","Model: \"sequential_287\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_913 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_914 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_339 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_915 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_340 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_916 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 22291.8613 - mse: 22291.8613 - mae: 105.2323 - val_loss: 13325.5703 - val_mse: 13325.5703 - val_mae: 79.1070\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14118.3525 - mse: 14118.3525 - mae: 81.1283 - val_loss: 12137.4971 - val_mse: 12137.4971 - val_mae: 72.9787\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13314.0557 - mse: 13314.0557 - mae: 77.8324 - val_loss: 11357.3477 - val_mse: 11357.3477 - val_mae: 71.8120\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12275.1631 - mse: 12275.1631 - mae: 73.9483 - val_loss: 10655.1553 - val_mse: 10655.1553 - val_mae: 74.6029\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11864.5010 - mse: 11864.5010 - mae: 73.1341 - val_loss: 10631.0381 - val_mse: 10631.0381 - val_mae: 66.5278\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11475.4736 - mse: 11475.4736 - mae: 71.7313 - val_loss: 10183.9346 - val_mse: 10183.9346 - val_mae: 68.0077\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11440.7148 - mse: 11440.7148 - mae: 71.7076 - val_loss: 9885.6523 - val_mse: 9885.6523 - val_mae: 67.1135\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11143.0225 - mse: 11143.0225 - mae: 70.3043 - val_loss: 9717.6875 - val_mse: 9717.6875 - val_mae: 66.1243\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11313.1943 - mse: 11313.1943 - mae: 70.5037 - val_loss: 9621.9209 - val_mse: 9621.9209 - val_mae: 65.4586\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11220.8682 - mse: 11220.8682 - mae: 69.9958 - val_loss: 9864.2188 - val_mse: 9864.2188 - val_mae: 64.7036\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 11220.8682 mean_squared_error: 11220.8682 mean_absolute_error: 69.9958 val_loss: 9864.2188 val_mean_squared_error: 9864.2188 val_mean_absolute_error: 64.7036\n","Model: \"sequential_288\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_917 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_918 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_341 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_919 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_342 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_920 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 24066.7422 - mse: 24066.7422 - mae: 108.3552 - val_loss: 13406.4512 - val_mse: 13406.4512 - val_mae: 78.7594\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14814.0684 - mse: 14814.0684 - mae: 83.3653 - val_loss: 12820.0840 - val_mse: 12820.0840 - val_mae: 73.9456\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13794.5234 - mse: 13794.5234 - mae: 79.9243 - val_loss: 11675.8525 - val_mse: 11675.8525 - val_mae: 73.4048\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13171.1328 - mse: 13171.1328 - mae: 77.4541 - val_loss: 11105.6982 - val_mse: 11105.6982 - val_mae: 70.1424\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12430.3281 - mse: 12430.3281 - mae: 73.8755 - val_loss: 10332.2031 - val_mse: 10332.2031 - val_mae: 71.0391\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12065.4551 - mse: 12065.4551 - mae: 72.3084 - val_loss: 9800.1064 - val_mse: 9800.1064 - val_mae: 66.5580\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11584.8564 - mse: 11584.8564 - mae: 71.0265 - val_loss: 10478.7627 - val_mse: 10478.7627 - val_mae: 75.8109\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11412.7012 - mse: 11412.7012 - mae: 69.5688 - val_loss: 9659.6143 - val_mse: 9659.6143 - val_mae: 69.6060\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11301.3057 - mse: 11301.3057 - mae: 69.1758 - val_loss: 9224.3779 - val_mse: 9224.3779 - val_mae: 62.2988\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 11068.6816 - mse: 11068.6816 - mae: 67.9394 - val_loss: 9167.8105 - val_mse: 9167.8105 - val_mae: 65.7653\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 11068.6816 mean_squared_error: 11068.6816 mean_absolute_error: 67.9394 val_loss: 9167.8105 val_mean_squared_error: 9167.8105 val_mean_absolute_error: 65.7653\n","Model: \"sequential_289\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_921 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_922 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_343 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_923 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_344 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_924 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 4s 2ms/step - loss: 21458.3691 - mse: 21458.3691 - mae: 103.7141 - val_loss: 13969.5410 - val_mse: 13969.5410 - val_mae: 79.2833\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14802.6680 - mse: 14802.6680 - mae: 84.2826 - val_loss: 13315.9102 - val_mse: 13315.9102 - val_mae: 77.4408\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14398.1328 - mse: 14398.1328 - mae: 83.0719 - val_loss: 13693.6250 - val_mse: 13693.6250 - val_mae: 76.1280\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14397.4268 - mse: 14397.4268 - mae: 82.8021 - val_loss: 12949.1270 - val_mse: 12949.1270 - val_mae: 81.6576\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14233.6562 - mse: 14233.6562 - mae: 83.0233 - val_loss: 13549.4805 - val_mse: 13549.4805 - val_mae: 76.7322\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14175.1768 - mse: 14175.1768 - mae: 82.5773 - val_loss: 13260.1650 - val_mse: 13260.1650 - val_mae: 77.0885\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14295.7529 - mse: 14295.7529 - mae: 82.5866 - val_loss: 13466.6289 - val_mse: 13466.6289 - val_mae: 88.2533\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14180.0361 - mse: 14180.0361 - mae: 82.7118 - val_loss: 13130.4297 - val_mse: 13130.4297 - val_mae: 77.7611\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14227.5547 - mse: 14227.5547 - mae: 82.8302 - val_loss: 13051.2754 - val_mse: 13051.2754 - val_mae: 78.7059\n","Epoch 9: early stopping\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 14227.5547 mean_squared_error: 14227.5547 mean_absolute_error: 82.8302 val_loss: 13051.2754 val_mean_squared_error: 13051.2754 val_mean_absolute_error: 78.7059\n","Model: \"sequential_290\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_925 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_926 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_345 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_927 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 40346.8984 - mse: 40346.8984 - mae: 145.5274 - val_loss: 25623.2031 - val_mse: 25623.2031 - val_mae: 119.5861\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 23619.2188 - mse: 23619.2188 - mae: 114.6497 - val_loss: 18591.5332 - val_mse: 18591.5332 - val_mae: 97.6687\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18837.9961 - mse: 18837.9961 - mae: 97.5737 - val_loss: 15531.8223 - val_mse: 15531.8223 - val_mae: 87.0814\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17023.3301 - mse: 17023.3301 - mae: 91.1983 - val_loss: 14632.5146 - val_mse: 14632.5146 - val_mae: 81.0942\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16782.6387 - mse: 16782.6387 - mae: 88.7608 - val_loss: 13944.1250 - val_mse: 13944.1250 - val_mae: 78.6102\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16021.2314 - mse: 16021.2314 - mae: 86.3597 - val_loss: 13283.5850 - val_mse: 13283.5850 - val_mae: 81.1693\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15640.6719 - mse: 15640.6719 - mae: 85.8826 - val_loss: 13292.5312 - val_mse: 13292.5312 - val_mae: 77.0263\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15428.8418 - mse: 15428.8418 - mae: 84.9178 - val_loss: 12891.0195 - val_mse: 12891.0195 - val_mae: 79.1698\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15701.6650 - mse: 15701.6650 - mae: 85.3565 - val_loss: 12903.4014 - val_mse: 12903.4014 - val_mae: 76.3190\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15654.0293 - mse: 15654.0293 - mae: 85.5021 - val_loss: 13103.0869 - val_mse: 13103.0869 - val_mae: 74.5652\n","163/163 [==============================] - 0s 926us/step\n","Epoch 10/10\n","16/16 loss: 15654.0293 mean_squared_error: 15654.0293 mean_absolute_error: 85.5021 val_loss: 13103.0869 val_mean_squared_error: 13103.0869 val_mean_absolute_error: 74.5652\n","Model: \"sequential_291\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_928 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_929 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_346 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_930 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 64343.3438 - mse: 64343.3438 - mae: 178.5970 - val_loss: 62025.0078 - val_mse: 62025.0078 - val_mae: 173.2027\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 58734.2812 - mse: 58734.2812 - mae: 168.0078 - val_loss: 57029.1914 - val_mse: 57029.1914 - val_mae: 164.4670\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 54087.4492 - mse: 54087.4492 - mae: 160.2939 - val_loss: 52732.2422 - val_mse: 52732.2422 - val_mae: 157.6402\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 50110.3164 - mse: 50110.3164 - mae: 154.2437 - val_loss: 49032.0977 - val_mse: 49032.0977 - val_mae: 152.1880\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 46884.3008 - mse: 46884.3008 - mae: 149.8049 - val_loss: 45894.6992 - val_mse: 45894.6992 - val_mae: 147.9167\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 43329.0781 - mse: 43329.0781 - mae: 139.8509 - val_loss: 41990.1055 - val_mse: 41990.1055 - val_mae: 133.0332\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 39820.9062 - mse: 39820.9062 - mae: 129.2118 - val_loss: 38750.6992 - val_mse: 38750.6992 - val_mae: 125.2379\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 36923.3047 - mse: 36923.3047 - mae: 123.1425 - val_loss: 35944.1836 - val_mse: 35944.1836 - val_mae: 119.0652\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 34417.0977 - mse: 34417.0977 - mae: 117.0747 - val_loss: 33322.2656 - val_mse: 33322.2656 - val_mae: 112.0612\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 31740.6289 - mse: 31740.6289 - mae: 110.2459 - val_loss: 30779.4551 - val_mse: 30779.4551 - val_mae: 105.1467\n","163/163 [==============================] - 0s 993us/step\n","Epoch 10/10\n","16/16 loss: 31740.6289 mean_squared_error: 31740.6289 mean_absolute_error: 110.2459 val_loss: 30779.4551 val_mean_squared_error: 30779.4551 val_mean_absolute_error: 105.1467\n","Model: \"sequential_292\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_931 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_932 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_347 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_933 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 37713.5859 - mse: 37713.5859 - mae: 141.5474 - val_loss: 25019.6426 - val_mse: 25019.6426 - val_mae: 118.7726\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 20624.4805 - mse: 20624.4805 - mae: 103.9881 - val_loss: 15973.3594 - val_mse: 15973.3594 - val_mae: 92.1906\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16573.4258 - mse: 16573.4258 - mae: 90.6420 - val_loss: 14127.5811 - val_mse: 14127.5811 - val_mae: 82.0121\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15359.3555 - mse: 15359.3555 - mae: 86.0727 - val_loss: 13205.9082 - val_mse: 13205.9082 - val_mae: 81.2962\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15196.2891 - mse: 15196.2891 - mae: 84.9559 - val_loss: 12825.7393 - val_mse: 12825.7393 - val_mae: 77.7150\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14650.9160 - mse: 14650.9160 - mae: 83.2872 - val_loss: 12422.4551 - val_mse: 12422.4551 - val_mae: 78.9469\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14308.9385 - mse: 14308.9385 - mae: 81.6035 - val_loss: 12124.8623 - val_mse: 12124.8623 - val_mae: 76.6712\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13904.0879 - mse: 13904.0879 - mae: 79.7865 - val_loss: 11925.1768 - val_mse: 11925.1768 - val_mae: 72.5013\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13489.5928 - mse: 13489.5928 - mae: 77.7206 - val_loss: 11655.3633 - val_mse: 11655.3633 - val_mae: 70.6033\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13192.1611 - mse: 13192.1611 - mae: 76.3052 - val_loss: 11033.7432 - val_mse: 11033.7432 - val_mae: 72.8334\n","163/163 [==============================] - 0s 966us/step\n","Epoch 10/10\n","16/16 loss: 13192.1611 mean_squared_error: 13192.1611 mean_absolute_error: 76.3052 val_loss: 11033.7432 val_mean_squared_error: 11033.7432 val_mean_absolute_error: 72.8334\n","Model: \"sequential_293\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_934 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_935 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_348 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_936 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 37546.9570 - mse: 37546.9570 - mae: 141.5252 - val_loss: 24429.1816 - val_mse: 24429.1816 - val_mae: 118.7888\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21953.6172 - mse: 21953.6172 - mae: 110.5988 - val_loss: 17376.0488 - val_mse: 17376.0488 - val_mae: 97.8236\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17420.6914 - mse: 17420.6914 - mae: 93.5442 - val_loss: 15340.5391 - val_mse: 15340.5391 - val_mae: 84.4545\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16451.2188 - mse: 16451.2188 - mae: 88.6237 - val_loss: 13976.5342 - val_mse: 13976.5342 - val_mae: 80.5068\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15573.9980 - mse: 15573.9980 - mae: 85.7013 - val_loss: 13365.5928 - val_mse: 13365.5928 - val_mae: 79.2619\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15149.5439 - mse: 15149.5439 - mae: 84.3671 - val_loss: 13122.3154 - val_mse: 13122.3154 - val_mae: 77.8296\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14955.6182 - mse: 14955.6182 - mae: 83.3953 - val_loss: 13062.9590 - val_mse: 13062.9590 - val_mae: 76.0077\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14708.5410 - mse: 14708.5410 - mae: 82.6454 - val_loss: 12704.0127 - val_mse: 12704.0127 - val_mae: 77.3396\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14465.2666 - mse: 14465.2666 - mae: 81.9894 - val_loss: 12508.7061 - val_mse: 12508.7061 - val_mae: 76.7739\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14340.4707 - mse: 14340.4707 - mae: 80.8324 - val_loss: 12372.1992 - val_mse: 12372.1992 - val_mae: 77.3064\n","163/163 [==============================] - 0s 887us/step\n","Epoch 10/10\n","16/16 loss: 14340.4707 mean_squared_error: 14340.4707 mean_absolute_error: 80.8324 val_loss: 12372.1992 val_mean_squared_error: 12372.1992 val_mean_absolute_error: 77.3064\n","Model: \"sequential_294\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_937 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_938 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_349 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_939 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 34824.8828 - mse: 34824.8828 - mae: 136.5757 - val_loss: 22990.0215 - val_mse: 22990.0215 - val_mae: 118.2151\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19812.8496 - mse: 19812.8496 - mae: 104.4110 - val_loss: 16684.9121 - val_mse: 16684.9121 - val_mae: 94.3816\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16620.7676 - mse: 16620.7676 - mae: 91.2693 - val_loss: 14653.1270 - val_mse: 14653.1270 - val_mae: 86.8657\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15296.4619 - mse: 15296.4619 - mae: 86.9715 - val_loss: 13836.6025 - val_mse: 13836.6025 - val_mae: 82.1405\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14852.7676 - mse: 14852.7676 - mae: 84.7948 - val_loss: 13379.9756 - val_mse: 13379.9756 - val_mae: 81.2410\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14617.5117 - mse: 14617.5117 - mae: 83.8150 - val_loss: 13372.5283 - val_mse: 13372.5283 - val_mae: 85.3970\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14343.0713 - mse: 14343.0713 - mae: 83.0812 - val_loss: 13077.8604 - val_mse: 13077.8604 - val_mae: 80.9568\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14378.2734 - mse: 14378.2734 - mae: 83.0485 - val_loss: 13038.2275 - val_mse: 13038.2275 - val_mae: 79.2755\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14156.1943 - mse: 14156.1943 - mae: 82.4192 - val_loss: 13091.2939 - val_mse: 13091.2939 - val_mae: 83.6828\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14342.0488 - mse: 14342.0488 - mae: 83.2198 - val_loss: 12953.4814 - val_mse: 12953.4814 - val_mae: 80.7867\n","163/163 [==============================] - 0s 871us/step\n","Epoch 10/10\n","16/16 loss: 14342.0488 mean_squared_error: 14342.0488 mean_absolute_error: 83.2198 val_loss: 12953.4814 val_mean_squared_error: 12953.4814 val_mean_absolute_error: 80.7867\n","Model: \"sequential_295\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_940 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_941 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_350 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_942 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_351 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_943 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 31056.7539 - mse: 31056.7539 - mae: 125.8969 - val_loss: 15758.1875 - val_mse: 15758.1875 - val_mae: 87.8014\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17092.0566 - mse: 17092.0566 - mae: 89.7886 - val_loss: 13234.4297 - val_mse: 13234.4297 - val_mae: 78.5026\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15899.9697 - mse: 15899.9697 - mae: 85.2598 - val_loss: 12644.0020 - val_mse: 12644.0020 - val_mae: 75.3304\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15111.5918 - mse: 15111.5918 - mae: 83.2635 - val_loss: 12631.1934 - val_mse: 12631.1934 - val_mae: 70.9945\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14619.7646 - mse: 14619.7646 - mae: 81.0273 - val_loss: 11478.1338 - val_mse: 11478.1338 - val_mae: 72.0575\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14163.9492 - mse: 14163.9492 - mae: 78.7541 - val_loss: 11031.2188 - val_mse: 11031.2188 - val_mae: 68.3251\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13713.9658 - mse: 13713.9658 - mae: 77.3403 - val_loss: 11433.2012 - val_mse: 11433.2012 - val_mae: 67.1011\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13522.8057 - mse: 13522.8057 - mae: 76.5830 - val_loss: 10695.8818 - val_mse: 10695.8818 - val_mae: 67.4625\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13304.4990 - mse: 13304.4990 - mae: 75.3923 - val_loss: 10097.8008 - val_mse: 10097.8008 - val_mae: 65.6235\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12435.5713 - mse: 12435.5713 - mae: 73.2880 - val_loss: 10668.6104 - val_mse: 10668.6104 - val_mae: 64.0424\n","163/163 [==============================] - 0s 964us/step\n","Epoch 10/10\n","16/16 loss: 12435.5713 mean_squared_error: 12435.5713 mean_absolute_error: 73.2880 val_loss: 10668.6104 val_mean_squared_error: 10668.6104 val_mean_absolute_error: 64.0424\n","Model: \"sequential_296\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_944 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_945 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_352 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_946 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_353 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_947 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 64267.3867 - mse: 64267.3867 - mae: 178.5076 - val_loss: 62090.0195 - val_mse: 62090.0195 - val_mae: 173.3256\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 58723.0820 - mse: 58723.0820 - mae: 167.9785 - val_loss: 57111.2031 - val_mse: 57111.2031 - val_mae: 164.6047\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 54175.9688 - mse: 54175.9688 - mae: 160.4753 - val_loss: 52837.3086 - val_mse: 52837.3086 - val_mae: 157.8051\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 50320.4961 - mse: 50320.4961 - mae: 154.6187 - val_loss: 49169.2500 - val_mse: 49169.2500 - val_mae: 152.3881\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 46976.4805 - mse: 46976.4805 - mae: 149.8421 - val_loss: 46019.4453 - val_mse: 46019.4453 - val_mae: 148.1026\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 44110.7109 - mse: 44110.7109 - mae: 146.2792 - val_loss: 43356.2422 - val_mse: 43356.2422 - val_mae: 144.8066\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 41868.0586 - mse: 41868.0586 - mae: 143.6356 - val_loss: 41134.1562 - val_mse: 41134.1562 - val_mae: 142.4052\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 39802.6992 - mse: 39802.6992 - mae: 141.6958 - val_loss: 39312.6094 - val_mse: 39312.6094 - val_mae: 140.7286\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 38321.5586 - mse: 38321.5586 - mae: 140.7209 - val_loss: 37852.9961 - val_mse: 37852.9961 - val_mae: 139.7340\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 35172.3438 - mse: 35172.3438 - mae: 127.1332 - val_loss: 32831.0742 - val_mse: 32831.0742 - val_mae: 113.2758\n","163/163 [==============================] - 0s 954us/step\n","Epoch 10/10\n","16/16 loss: 35172.3438 mean_squared_error: 35172.3438 mean_absolute_error: 127.1332 val_loss: 32831.0742 val_mean_squared_error: 32831.0742 val_mean_absolute_error: 113.2758\n","Model: \"sequential_297\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_948 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_949 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_354 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_950 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_355 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_951 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 28722.0586 - mse: 28722.0586 - mae: 121.0055 - val_loss: 15922.1650 - val_mse: 15922.1650 - val_mae: 86.9403\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16693.3340 - mse: 16693.3340 - mae: 89.0630 - val_loss: 12979.8154 - val_mse: 12979.8154 - val_mae: 78.8614\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15091.4258 - mse: 15091.4258 - mae: 83.4216 - val_loss: 12205.6797 - val_mse: 12205.6797 - val_mae: 79.3064\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14412.4639 - mse: 14412.4639 - mae: 80.8492 - val_loss: 11687.6348 - val_mse: 11687.6348 - val_mae: 72.7070\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14007.2578 - mse: 14007.2578 - mae: 78.7852 - val_loss: 11877.9473 - val_mse: 11877.9473 - val_mae: 79.5680\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13628.6904 - mse: 13628.6904 - mae: 77.5846 - val_loss: 10940.2441 - val_mse: 10940.2441 - val_mae: 70.1562\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13082.1826 - mse: 13082.1826 - mae: 75.4662 - val_loss: 10526.9355 - val_mse: 10526.9355 - val_mae: 67.2943\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12655.1045 - mse: 12655.1045 - mae: 74.0201 - val_loss: 10195.8145 - val_mse: 10195.8145 - val_mae: 65.3215\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12512.8457 - mse: 12512.8457 - mae: 73.1797 - val_loss: 10150.4209 - val_mse: 10150.4209 - val_mae: 64.6934\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12374.6250 - mse: 12374.6250 - mae: 73.0238 - val_loss: 10065.1562 - val_mse: 10065.1562 - val_mae: 69.0123\n","163/163 [==============================] - 0s 972us/step\n","Epoch 10/10\n","16/16 loss: 12374.6250 mean_squared_error: 12374.6250 mean_absolute_error: 73.0238 val_loss: 10065.1562 val_mean_squared_error: 10065.1562 val_mean_absolute_error: 69.0123\n","Model: \"sequential_298\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_952 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_953 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_356 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_954 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_357 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_955 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 29105.3613 - mse: 29105.3613 - mae: 121.7854 - val_loss: 15942.7373 - val_mse: 15942.7373 - val_mae: 84.8278\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16578.7949 - mse: 16578.7949 - mae: 88.2932 - val_loss: 13272.1602 - val_mse: 13272.1602 - val_mae: 77.6707\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15561.8086 - mse: 15561.8086 - mae: 85.0986 - val_loss: 13958.2002 - val_mse: 13958.2002 - val_mae: 73.9524\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15436.3291 - mse: 15436.3291 - mae: 83.6765 - val_loss: 12457.8662 - val_mse: 12457.8662 - val_mae: 75.2839\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15055.4609 - mse: 15055.4609 - mae: 82.9255 - val_loss: 12129.5498 - val_mse: 12129.5498 - val_mae: 78.6323\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14762.1396 - mse: 14762.1396 - mae: 81.4327 - val_loss: 11871.7324 - val_mse: 11871.7324 - val_mae: 70.9728\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14315.0156 - mse: 14315.0156 - mae: 79.5117 - val_loss: 12601.2666 - val_mse: 12601.2666 - val_mae: 68.4480\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13563.4453 - mse: 13563.4453 - mae: 77.1337 - val_loss: 10972.1992 - val_mse: 10972.1992 - val_mae: 71.0969\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13754.1387 - mse: 13754.1387 - mae: 77.6199 - val_loss: 11250.2207 - val_mse: 11250.2207 - val_mae: 65.6279\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13371.7002 - mse: 13371.7002 - mae: 76.2122 - val_loss: 12142.4629 - val_mse: 12142.4629 - val_mae: 67.8531\n","163/163 [==============================] - 0s 909us/step\n","Epoch 10/10\n","16/16 loss: 13371.7002 mean_squared_error: 13371.7002 mean_absolute_error: 76.2122 val_loss: 12142.4629 val_mean_squared_error: 12142.4629 val_mean_absolute_error: 67.8531\n","Model: \"sequential_299\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_956 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_957 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_358 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_958 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_359 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_959 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 25171.9727 - mse: 25171.9727 - mae: 112.9632 - val_loss: 14615.5732 - val_mse: 14615.5732 - val_mae: 87.7047\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15605.6914 - mse: 15605.6914 - mae: 87.2500 - val_loss: 13261.4014 - val_mse: 13261.4014 - val_mae: 80.2647\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15364.4961 - mse: 15364.4961 - mae: 85.9582 - val_loss: 13255.7939 - val_mse: 13255.7939 - val_mae: 77.8798\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15305.5977 - mse: 15305.5977 - mae: 85.2572 - val_loss: 13156.4463 - val_mse: 13156.4463 - val_mae: 78.3264\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14993.6113 - mse: 14993.6113 - mae: 84.4690 - val_loss: 13160.0645 - val_mse: 13160.0645 - val_mae: 78.3649\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14952.1572 - mse: 14952.1572 - mae: 84.5253 - val_loss: 12977.7598 - val_mse: 12977.7598 - val_mae: 81.6210\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15216.4600 - mse: 15216.4600 - mae: 85.1218 - val_loss: 12985.7734 - val_mse: 12985.7734 - val_mae: 78.9134\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14951.0605 - mse: 14951.0605 - mae: 84.4299 - val_loss: 14613.4785 - val_mse: 14613.4785 - val_mae: 76.7761\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14932.6963 - mse: 14932.6963 - mae: 83.9552 - val_loss: 12924.4580 - val_mse: 12924.4580 - val_mae: 80.5160\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14909.1328 - mse: 14909.1328 - mae: 84.5738 - val_loss: 13585.0459 - val_mse: 13585.0459 - val_mae: 76.2875\n","163/163 [==============================] - 0s 980us/step\n","Epoch 10/10\n","16/16 loss: 14909.1328 mean_squared_error: 14909.1328 mean_absolute_error: 84.5738 val_loss: 13585.0459 val_mean_squared_error: 13585.0459 val_mean_absolute_error: 76.2875\n","Model: \"sequential_300\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_960 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_961 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 2s 2ms/step - loss: 45111.5195 - mse: 45111.5195 - mae: 149.7001 - val_loss: 28401.9668 - val_mse: 28401.9668 - val_mae: 127.7317\n","163/163 [==============================] - 0s 922us/step\n","Epoch 1/1\n","8/8 loss: 45111.5195 mean_squared_error: 45111.5195 mean_absolute_error: 149.7001 val_loss: 28401.9668 val_mean_squared_error: 28401.9668 val_mean_absolute_error: 127.7317\n","Model: \"sequential_301\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_962 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_963 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 55683.0273 - mse: 55683.0273 - mae: 163.5950 - val_loss: 46867.3633 - val_mse: 46867.3633 - val_mae: 148.9414\n","163/163 [==============================] - 0s 986us/step\n","Epoch 1/1\n","8/8 loss: 55683.0273 mean_squared_error: 55683.0273 mean_absolute_error: 163.5950 val_loss: 46867.3633 val_mean_squared_error: 46867.3633 val_mean_absolute_error: 148.9414\n","Model: \"sequential_302\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_964 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_965 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 2s 2ms/step - loss: 42704.8711 - mse: 42704.8711 - mae: 146.1705 - val_loss: 28920.1543 - val_mse: 28920.1543 - val_mae: 130.0769\n","163/163 [==============================] - 0s 895us/step\n","Epoch 1/1\n","8/8 loss: 42704.8711 mean_squared_error: 42704.8711 mean_absolute_error: 146.1705 val_loss: 28920.1543 val_mean_squared_error: 28920.1543 val_mean_absolute_error: 130.0769\n","Model: \"sequential_303\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_966 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_967 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 2s 2ms/step - loss: 43312.1602 - mse: 43312.1602 - mae: 147.3924 - val_loss: 27971.7344 - val_mse: 27971.7344 - val_mae: 128.0227\n","163/163 [==============================] - 0s 890us/step\n","Epoch 1/1\n","8/8 loss: 43312.1602 mean_squared_error: 43312.1602 mean_absolute_error: 147.3924 val_loss: 27971.7344 val_mean_squared_error: 27971.7344 val_mean_absolute_error: 128.0227\n","Model: \"sequential_304\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_968 (Dense)           (None, 64)                768       \n","                                                                 \n"," dense_969 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 2s 2ms/step - loss: 39640.1641 - mse: 39640.1641 - mae: 141.6775 - val_loss: 27516.3379 - val_mse: 27516.3379 - val_mae: 128.1877\n","163/163 [==============================] - 0s 900us/step\n","Epoch 1/1\n","8/8 loss: 39640.1641 mean_squared_error: 39640.1641 mean_absolute_error: 141.6775 val_loss: 27516.3379 val_mean_squared_error: 27516.3379 val_mean_absolute_error: 128.1877\n","Model: \"sequential_305\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_970 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_971 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_360 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_972 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 28378.1133 - mse: 28378.1133 - mae: 122.2208 - val_loss: 16513.8398 - val_mse: 16513.8398 - val_mae: 89.4944\n","163/163 [==============================] - 0s 917us/step\n","Epoch 1/1\n","8/8 loss: 28378.1133 mean_squared_error: 28378.1133 mean_absolute_error: 122.2208 val_loss: 16513.8398 val_mean_squared_error: 16513.8398 val_mean_absolute_error: 89.4944\n","Model: \"sequential_306\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_973 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_974 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_361 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_975 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 56971.4688 - mse: 56971.4688 - mae: 165.5636 - val_loss: 50251.2656 - val_mse: 50251.2656 - val_mae: 153.9252\n","163/163 [==============================] - 0s 952us/step\n","Epoch 1/1\n","8/8 loss: 56971.4688 mean_squared_error: 56971.4688 mean_absolute_error: 165.5636 val_loss: 50251.2656 val_mean_squared_error: 50251.2656 val_mean_absolute_error: 153.9252\n","Model: \"sequential_307\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_976 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_977 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_362 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_978 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 27347.6250 - mse: 27347.6250 - mae: 118.7979 - val_loss: 15545.3828 - val_mse: 15545.3828 - val_mae: 90.8719\n","163/163 [==============================] - 0s 934us/step\n","Epoch 1/1\n","8/8 loss: 27347.6250 mean_squared_error: 27347.6250 mean_absolute_error: 118.7979 val_loss: 15545.3828 val_mean_squared_error: 15545.3828 val_mean_absolute_error: 90.8719\n","Model: \"sequential_308\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_979 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_980 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_363 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_981 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 29610.1875 - mse: 29610.1875 - mae: 124.8861 - val_loss: 16913.8789 - val_mse: 16913.8789 - val_mae: 96.3731\n","163/163 [==============================] - 0s 871us/step\n","Epoch 1/1\n","8/8 loss: 29610.1875 mean_squared_error: 29610.1875 mean_absolute_error: 124.8861 val_loss: 16913.8789 val_mean_squared_error: 16913.8789 val_mean_absolute_error: 96.3731\n","Model: \"sequential_309\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_982 (Dense)           (None, 128)               1536      \n","                                                                 \n"," dense_983 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_364 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_984 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 25652.2070 - mse: 25652.2070 - mae: 117.6167 - val_loss: 16200.1367 - val_mse: 16200.1367 - val_mae: 98.3802\n","163/163 [==============================] - 0s 973us/step\n","Epoch 1/1\n","8/8 loss: 25652.2070 mean_squared_error: 25652.2070 mean_absolute_error: 117.6167 val_loss: 16200.1367 val_mean_squared_error: 16200.1367 val_mean_absolute_error: 98.3802\n","Model: \"sequential_310\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_985 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_986 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_365 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_987 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_366 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_988 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 23969.5293 - mse: 23969.5293 - mae: 107.5624 - val_loss: 13778.4668 - val_mse: 13778.4668 - val_mae: 78.2971\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 23969.5293 mean_squared_error: 23969.5293 mean_absolute_error: 107.5624 val_loss: 13778.4668 val_mean_squared_error: 13778.4668 val_mean_absolute_error: 78.2971\n","Model: \"sequential_311\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_989 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_990 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_367 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_991 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_368 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_992 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 57264.9219 - mse: 57264.9219 - mae: 165.8568 - val_loss: 50519.0156 - val_mse: 50519.0156 - val_mae: 154.3258\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 57264.9219 mean_squared_error: 57264.9219 mean_absolute_error: 165.8568 val_loss: 50519.0156 val_mean_squared_error: 50519.0156 val_mean_absolute_error: 154.3258\n","Model: \"sequential_312\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_993 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_994 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_369 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_995 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_370 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_996 (Dense)           (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 21973.2188 - mse: 21973.2188 - mae: 103.2240 - val_loss: 15244.6465 - val_mse: 15244.6465 - val_mae: 75.6198\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 21973.2188 mean_squared_error: 21973.2188 mean_absolute_error: 103.2240 val_loss: 15244.6465 val_mean_squared_error: 15244.6465 val_mean_absolute_error: 75.6198\n","Model: \"sequential_313\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_997 (Dense)           (None, 256)               3072      \n","                                                                 \n"," dense_998 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_371 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_999 (Dense)           (None, 64)                8256      \n","                                                                 \n"," dropout_372 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1000 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24187.5000 - mse: 24187.5000 - mae: 109.1060 - val_loss: 14339.2100 - val_mse: 14339.2100 - val_mae: 79.1085\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 24187.5000 mean_squared_error: 24187.5000 mean_absolute_error: 109.1060 val_loss: 14339.2100 val_mean_squared_error: 14339.2100 val_mean_absolute_error: 79.1085\n","Model: \"sequential_314\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1001 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1002 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_373 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1003 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_374 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1004 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 4s 2ms/step - loss: 20615.7539 - mse: 20615.7539 - mae: 101.6713 - val_loss: 13304.9922 - val_mse: 13304.9922 - val_mae: 83.9565\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 20615.7539 mean_squared_error: 20615.7539 mean_absolute_error: 101.6713 val_loss: 13304.9922 val_mean_squared_error: 13304.9922 val_mean_absolute_error: 83.9565\n","Model: \"sequential_315\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1005 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1006 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_375 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1007 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 35222.8242 - mse: 35222.8242 - mae: 136.3369 - val_loss: 21381.9766 - val_mse: 21381.9766 - val_mae: 105.7333\n","163/163 [==============================] - 0s 956us/step\n","Epoch 1/1\n","8/8 loss: 35222.8242 mean_squared_error: 35222.8242 mean_absolute_error: 136.3369 val_loss: 21381.9766 val_mean_squared_error: 21381.9766 val_mean_absolute_error: 105.7333\n","Model: \"sequential_316\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1008 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1009 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_376 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1010 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 61909.2383 - mse: 61909.2383 - mae: 173.9458 - val_loss: 57982.1992 - val_mse: 57982.1992 - val_mae: 166.0481\n","163/163 [==============================] - 0s 972us/step\n","Epoch 1/1\n","8/8 loss: 61909.2383 mean_squared_error: 61909.2383 mean_absolute_error: 173.9458 val_loss: 57982.1992 val_mean_squared_error: 57982.1992 val_mean_absolute_error: 166.0481\n","Model: \"sequential_317\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1011 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1012 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_377 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1013 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 34801.2773 - mse: 34801.2773 - mae: 134.9126 - val_loss: 20074.3828 - val_mse: 20074.3828 - val_mae: 99.9645\n","163/163 [==============================] - 0s 990us/step\n","Epoch 1/1\n","8/8 loss: 34801.2773 mean_squared_error: 34801.2773 mean_absolute_error: 134.9126 val_loss: 20074.3828 val_mean_squared_error: 20074.3828 val_mean_absolute_error: 99.9645\n","Model: \"sequential_318\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1014 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1015 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_378 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1016 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 34125.7695 - mse: 34125.7695 - mae: 134.6340 - val_loss: 20172.6992 - val_mse: 20172.6992 - val_mae: 107.4907\n","163/163 [==============================] - 0s 955us/step\n","Epoch 1/1\n","8/8 loss: 34125.7695 mean_squared_error: 34125.7695 mean_absolute_error: 134.6340 val_loss: 20172.6992 val_mean_squared_error: 20172.6992 val_mean_absolute_error: 107.4907\n","Model: \"sequential_319\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1017 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1018 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_379 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1019 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 30615.1523 - mse: 30615.1523 - mae: 128.9638 - val_loss: 19919.7715 - val_mse: 19919.7715 - val_mae: 102.7360\n","163/163 [==============================] - 0s 888us/step\n","Epoch 1/1\n","8/8 loss: 30615.1523 mean_squared_error: 30615.1523 mean_absolute_error: 128.9638 val_loss: 19919.7715 val_mean_squared_error: 19919.7715 val_mean_absolute_error: 102.7360\n","Model: \"sequential_320\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1020 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1021 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_380 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1022 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_381 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1023 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 28654.7871 - mse: 28654.7871 - mae: 118.3000 - val_loss: 13986.4355 - val_mse: 13986.4355 - val_mae: 81.8862\n","163/163 [==============================] - 0s 992us/step\n","Epoch 1/1\n","8/8 loss: 28654.7871 mean_squared_error: 28654.7871 mean_absolute_error: 118.3000 val_loss: 13986.4355 val_mean_squared_error: 13986.4355 val_mean_absolute_error: 81.8862\n","Model: \"sequential_321\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1024 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1025 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_382 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1026 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_383 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1027 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 62370.4453 - mse: 62370.4453 - mae: 174.9263 - val_loss: 58470.4922 - val_mse: 58470.4922 - val_mae: 166.8743\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","8/8 loss: 62370.4453 mean_squared_error: 62370.4453 mean_absolute_error: 174.9263 val_loss: 58470.4922 val_mean_squared_error: 58470.4922 val_mean_absolute_error: 166.8743\n","Model: \"sequential_322\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1028 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1029 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_384 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1030 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_385 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1031 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 28369.2129 - mse: 28369.2129 - mae: 117.1569 - val_loss: 14575.1855 - val_mse: 14575.1855 - val_mae: 84.5197\n","163/163 [==============================] - 0s 998us/step\n","Epoch 1/1\n","8/8 loss: 28369.2129 mean_squared_error: 28369.2129 mean_absolute_error: 117.1569 val_loss: 14575.1855 val_mean_squared_error: 14575.1855 val_mean_absolute_error: 84.5197\n","Model: \"sequential_323\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1032 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1033 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_386 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1034 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_387 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1035 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 30023.6641 - mse: 30023.6641 - mae: 121.9773 - val_loss: 15135.5166 - val_mse: 15135.5166 - val_mae: 81.4582\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","8/8 loss: 30023.6641 mean_squared_error: 30023.6641 mean_absolute_error: 121.9773 val_loss: 15135.5166 val_mean_squared_error: 15135.5166 val_mean_absolute_error: 81.4582\n","Model: \"sequential_324\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1036 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1037 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_388 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1038 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_389 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1039 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24763.6309 - mse: 24763.6309 - mae: 111.2928 - val_loss: 15256.2295 - val_mse: 15256.2295 - val_mae: 81.1231\n","163/163 [==============================] - 0s 938us/step\n","Epoch 1/1\n","8/8 loss: 24763.6309 mean_squared_error: 24763.6309 mean_absolute_error: 111.2928 val_loss: 15256.2295 val_mean_squared_error: 15256.2295 val_mean_absolute_error: 81.1231\n","Model: \"sequential_325\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1040 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1041 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 43907.2148 - mse: 43907.2148 - mae: 148.4793 - val_loss: 28215.3184 - val_mse: 28215.3184 - val_mae: 129.2012\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25229.4590 - mse: 25229.4590 - mae: 121.6415 - val_loss: 22671.0332 - val_mse: 22671.0332 - val_mae: 115.0086\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20316.3086 - mse: 20316.3086 - mae: 106.6230 - val_loss: 18702.7988 - val_mse: 18702.7988 - val_mae: 101.1727\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17368.8984 - mse: 17368.8984 - mae: 96.2730 - val_loss: 16625.4062 - val_mse: 16625.4062 - val_mae: 92.7888\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15774.2051 - mse: 15774.2051 - mae: 90.0489 - val_loss: 15345.5127 - val_mse: 15345.5127 - val_mae: 90.3271\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14821.1680 - mse: 14821.1680 - mae: 86.4878 - val_loss: 14615.4375 - val_mse: 14615.4375 - val_mae: 85.3148\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14203.9033 - mse: 14203.9033 - mae: 83.9179 - val_loss: 14055.2119 - val_mse: 14055.2119 - val_mae: 83.4349\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13781.2217 - mse: 13781.2217 - mae: 82.1836 - val_loss: 13657.8193 - val_mse: 13657.8193 - val_mae: 83.5493\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13466.0654 - mse: 13466.0654 - mae: 81.0607 - val_loss: 13427.5283 - val_mse: 13427.5283 - val_mae: 80.3551\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13258.7012 - mse: 13258.7012 - mae: 80.2075 - val_loss: 13196.8496 - val_mse: 13196.8496 - val_mae: 79.8978\n","163/163 [==============================] - 0s 924us/step\n","Epoch 10/10\n","8/8 loss: 13258.7012 mean_squared_error: 13258.7012 mean_absolute_error: 80.2075 val_loss: 13196.8496 val_mean_squared_error: 13196.8496 val_mean_absolute_error: 79.8978\n","Model: \"sequential_326\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1042 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1043 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 55752.4766 - mse: 55752.4766 - mae: 163.7452 - val_loss: 46949.2500 - val_mse: 46949.2500 - val_mae: 149.0346\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 41319.4922 - mse: 41319.4922 - mae: 142.6252 - val_loss: 38164.2109 - val_mse: 38164.2109 - val_mae: 139.1002\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 34471.3672 - mse: 34471.3672 - mae: 131.6699 - val_loss: 31594.7344 - val_mse: 31594.7344 - val_mae: 120.7618\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 28065.9707 - mse: 28065.9707 - mae: 112.8847 - val_loss: 26101.1250 - val_mse: 26101.1250 - val_mae: 106.8606\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 23524.5488 - mse: 23524.5488 - mae: 101.8967 - val_loss: 22329.4199 - val_mse: 22329.4199 - val_mae: 99.7626\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20272.7305 - mse: 20272.7305 - mae: 94.5502 - val_loss: 19438.7148 - val_mse: 19438.7148 - val_mae: 92.7943\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17698.7754 - mse: 17698.7754 - mae: 88.0333 - val_loss: 17111.3828 - val_mse: 17111.3828 - val_mae: 89.3429\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15701.5947 - mse: 15701.5947 - mae: 83.0599 - val_loss: 15344.8340 - val_mse: 15344.8340 - val_mae: 82.4462\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14248.6543 - mse: 14248.6543 - mae: 79.0416 - val_loss: 14082.6436 - val_mse: 14082.6436 - val_mae: 78.8209\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13203.6318 - mse: 13203.6318 - mae: 76.0138 - val_loss: 13158.9834 - val_mse: 13158.9834 - val_mae: 77.6620\n","163/163 [==============================] - 0s 923us/step\n","Epoch 10/10\n","8/8 loss: 13203.6318 mean_squared_error: 13203.6318 mean_absolute_error: 76.0138 val_loss: 13158.9834 val_mean_squared_error: 13158.9834 val_mean_absolute_error: 77.6620\n","Model: \"sequential_327\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1044 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1045 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 41566.8711 - mse: 41566.8711 - mae: 144.6749 - val_loss: 28622.6367 - val_mse: 28622.6367 - val_mae: 130.7625\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25667.7969 - mse: 25667.7969 - mae: 122.8016 - val_loss: 22606.8145 - val_mse: 22606.8145 - val_mae: 114.0759\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20003.8496 - mse: 20003.8496 - mae: 105.6959 - val_loss: 18136.8359 - val_mse: 18136.8359 - val_mae: 100.0907\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16721.6152 - mse: 16721.6152 - mae: 93.7914 - val_loss: 15857.9307 - val_mse: 15857.9307 - val_mae: 91.0702\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15104.6553 - mse: 15104.6553 - mae: 87.4730 - val_loss: 14707.3027 - val_mse: 14707.3027 - val_mae: 86.4513\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14251.1348 - mse: 14251.1348 - mae: 84.0374 - val_loss: 14030.0000 - val_mse: 14030.0000 - val_mae: 83.6149\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13728.0459 - mse: 13728.0459 - mae: 82.1823 - val_loss: 13684.9238 - val_mse: 13684.9238 - val_mae: 80.7468\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13391.1191 - mse: 13391.1191 - mae: 80.5112 - val_loss: 13344.7871 - val_mse: 13344.7871 - val_mae: 83.8260\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 13173.1875 - mse: 13173.1875 - mae: 80.1094 - val_loss: 13061.6738 - val_mse: 13061.6738 - val_mae: 80.7635\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 12982.0195 - mse: 12982.0195 - mae: 79.3413 - val_loss: 12904.0342 - val_mse: 12904.0342 - val_mae: 79.6615\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 12982.0195 mean_squared_error: 12982.0195 mean_absolute_error: 79.3413 val_loss: 12904.0342 val_mean_squared_error: 12904.0342 val_mean_absolute_error: 79.6615\n","Model: \"sequential_328\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1046 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1047 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 44086.2227 - mse: 44086.2227 - mae: 148.3406 - val_loss: 28322.7578 - val_mse: 28322.7578 - val_mae: 129.6297\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25457.8359 - mse: 25457.8359 - mae: 122.5601 - val_loss: 23055.7363 - val_mse: 23055.7363 - val_mae: 113.9717\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20591.5137 - mse: 20591.5137 - mae: 107.5949 - val_loss: 18970.0469 - val_mse: 18970.0469 - val_mae: 101.4561\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17542.9648 - mse: 17542.9648 - mae: 96.7904 - val_loss: 16698.1895 - val_mse: 16698.1895 - val_mae: 94.1255\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15845.1973 - mse: 15845.1973 - mae: 90.4794 - val_loss: 15419.8330 - val_mse: 15419.8330 - val_mae: 89.4034\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14858.1807 - mse: 14858.1807 - mae: 86.4821 - val_loss: 14593.1494 - val_mse: 14593.1494 - val_mae: 86.2250\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14208.1582 - mse: 14208.1582 - mae: 83.7644 - val_loss: 14021.1914 - val_mse: 14021.1914 - val_mae: 84.7632\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13758.0205 - mse: 13758.0205 - mae: 82.2511 - val_loss: 13665.1807 - val_mse: 13665.1807 - val_mae: 81.5627\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13441.1152 - mse: 13441.1152 - mae: 80.8289 - val_loss: 13333.6055 - val_mse: 13333.6055 - val_mae: 81.7813\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13214.5000 - mse: 13214.5000 - mae: 80.0958 - val_loss: 13128.5625 - val_mse: 13128.5625 - val_mae: 81.5978\n","163/163 [==============================] - 0s 917us/step\n","Epoch 10/10\n","8/8 loss: 13214.5000 mean_squared_error: 13214.5000 mean_absolute_error: 80.0958 val_loss: 13128.5625 val_mean_squared_error: 13128.5625 val_mean_absolute_error: 81.5978\n","Model: \"sequential_329\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1048 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1049 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 40099.6094 - mse: 40099.6094 - mae: 143.2538 - val_loss: 27331.3340 - val_mse: 27331.3340 - val_mae: 129.1512\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25282.2520 - mse: 25282.2520 - mae: 123.7380 - val_loss: 23746.4980 - val_mse: 23746.4980 - val_mae: 117.9789\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 21840.8457 - mse: 21840.8457 - mae: 113.2514 - val_loss: 20365.3418 - val_mse: 20365.3418 - val_mae: 109.6558\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18879.5820 - mse: 18879.5820 - mae: 103.0880 - val_loss: 17885.9355 - val_mse: 17885.9355 - val_mae: 98.9742\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16873.3008 - mse: 16873.3008 - mae: 95.0605 - val_loss: 16292.0322 - val_mse: 16292.0322 - val_mae: 93.5754\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15658.0381 - mse: 15658.0381 - mae: 89.7917 - val_loss: 15339.7822 - val_mse: 15339.7822 - val_mae: 90.6130\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14885.2891 - mse: 14885.2891 - mae: 86.6298 - val_loss: 14675.2891 - val_mse: 14675.2891 - val_mae: 86.4310\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14355.2529 - mse: 14355.2529 - mae: 84.2691 - val_loss: 14199.9141 - val_mse: 14199.9141 - val_mae: 84.6761\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13982.4902 - mse: 13982.4902 - mae: 82.9134 - val_loss: 13882.0859 - val_mse: 13882.0859 - val_mae: 82.9124\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13730.5850 - mse: 13730.5850 - mae: 81.8147 - val_loss: 13635.0225 - val_mse: 13635.0225 - val_mae: 83.4353\n","163/163 [==============================] - 0s 954us/step\n","Epoch 10/10\n","8/8 loss: 13730.5850 mean_squared_error: 13730.5850 mean_absolute_error: 81.8147 val_loss: 13635.0225 val_mean_squared_error: 13635.0225 val_mean_absolute_error: 83.4353\n","Model: \"sequential_330\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1050 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1051 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_390 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1052 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 30920.1094 - mse: 30920.1094 - mae: 127.7953 - val_loss: 18472.9902 - val_mse: 18472.9902 - val_mae: 93.2697\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18060.5625 - mse: 18060.5625 - mae: 93.1532 - val_loss: 14304.0117 - val_mse: 14304.0117 - val_mae: 79.8885\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15996.4561 - mse: 15996.4561 - mae: 86.3667 - val_loss: 13223.7734 - val_mse: 13223.7734 - val_mae: 78.0238\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16003.8574 - mse: 16003.8574 - mae: 85.8618 - val_loss: 12745.4922 - val_mse: 12745.4922 - val_mae: 77.8143\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15419.1533 - mse: 15419.1533 - mae: 84.2016 - val_loss: 12810.8711 - val_mse: 12810.8711 - val_mae: 74.2751\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15561.3486 - mse: 15561.3486 - mae: 83.7817 - val_loss: 12218.9775 - val_mse: 12218.9775 - val_mae: 74.3396\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15241.9580 - mse: 15241.9580 - mae: 83.3043 - val_loss: 12025.0430 - val_mse: 12025.0430 - val_mae: 72.7557\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14863.0576 - mse: 14863.0576 - mae: 81.8024 - val_loss: 11866.8779 - val_mse: 11866.8779 - val_mae: 71.4313\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14353.3438 - mse: 14353.3438 - mae: 80.2299 - val_loss: 11566.8721 - val_mse: 11566.8721 - val_mae: 72.1913\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14203.2373 - mse: 14203.2373 - mae: 79.2890 - val_loss: 11471.6738 - val_mse: 11471.6738 - val_mae: 69.4174\n","163/163 [==============================] - 0s 936us/step\n","Epoch 10/10\n","8/8 loss: 14203.2373 mean_squared_error: 14203.2373 mean_absolute_error: 79.2890 val_loss: 11471.6738 val_mean_squared_error: 11471.6738 val_mean_absolute_error: 69.4174\n","Model: \"sequential_331\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1053 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1054 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_391 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1055 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 57031.8789 - mse: 57031.8789 - mae: 165.5897 - val_loss: 50232.2070 - val_mse: 50232.2070 - val_mae: 153.8976\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 44509.0742 - mse: 44509.0742 - mae: 145.3389 - val_loss: 40067.1797 - val_mse: 40067.1797 - val_mae: 132.8269\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 35183.0430 - mse: 35183.0430 - mae: 121.2067 - val_loss: 31943.0723 - val_mse: 31943.0723 - val_mae: 112.1354\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 28406.0898 - mse: 28406.0898 - mae: 104.5367 - val_loss: 25531.8398 - val_mse: 25531.8398 - val_mae: 96.0767\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 23447.2852 - mse: 23447.2852 - mae: 94.0452 - val_loss: 21274.4043 - val_mse: 21274.4043 - val_mae: 86.5209\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20050.9043 - mse: 20050.9043 - mae: 88.2631 - val_loss: 18338.9941 - val_mse: 18338.9941 - val_mae: 82.0044\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17848.3984 - mse: 17848.3984 - mae: 84.5773 - val_loss: 16240.3350 - val_mse: 16240.3350 - val_mae: 76.9440\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16682.1738 - mse: 16682.1738 - mae: 83.4240 - val_loss: 14757.3662 - val_mse: 14757.3662 - val_mae: 73.8898\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15271.8301 - mse: 15271.8301 - mae: 80.8892 - val_loss: 13713.7812 - val_mse: 13713.7812 - val_mae: 72.0434\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15029.9121 - mse: 15029.9121 - mae: 81.4277 - val_loss: 12966.1592 - val_mse: 12966.1592 - val_mae: 70.0932\n","163/163 [==============================] - 0s 984us/step\n","Epoch 10/10\n","8/8 loss: 15029.9121 mean_squared_error: 15029.9121 mean_absolute_error: 81.4277 val_loss: 12966.1592 val_mean_squared_error: 12966.1592 val_mean_absolute_error: 70.0932\n","Model: \"sequential_332\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1056 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1057 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_392 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1058 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 27877.8926 - mse: 27877.8926 - mae: 120.2506 - val_loss: 15659.3008 - val_mse: 15659.3008 - val_mae: 89.1930\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16701.9844 - mse: 16701.9844 - mae: 89.8612 - val_loss: 13750.7031 - val_mse: 13750.7031 - val_mae: 77.9940\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15304.1289 - mse: 15304.1289 - mae: 84.3988 - val_loss: 12677.2178 - val_mse: 12677.2178 - val_mae: 75.3740\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14502.6445 - mse: 14502.6445 - mae: 81.6294 - val_loss: 12115.4961 - val_mse: 12115.4961 - val_mae: 71.8807\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13823.0000 - mse: 13823.0000 - mae: 77.9701 - val_loss: 11532.3340 - val_mse: 11532.3340 - val_mae: 75.2628\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13332.1416 - mse: 13332.1416 - mae: 76.0945 - val_loss: 10725.8750 - val_mse: 10725.8750 - val_mae: 68.7409\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13000.3594 - mse: 13000.3594 - mae: 75.5162 - val_loss: 10556.1455 - val_mse: 10556.1455 - val_mae: 71.5225\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12807.0723 - mse: 12807.0723 - mae: 75.1315 - val_loss: 10356.9951 - val_mse: 10356.9951 - val_mae: 67.5154\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12284.4941 - mse: 12284.4941 - mae: 74.1520 - val_loss: 10306.7227 - val_mse: 10306.7227 - val_mae: 67.0452\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12311.6387 - mse: 12311.6387 - mae: 74.2325 - val_loss: 10227.6582 - val_mse: 10227.6582 - val_mae: 65.9034\n","163/163 [==============================] - 0s 918us/step\n","Epoch 10/10\n","8/8 loss: 12311.6387 mean_squared_error: 12311.6387 mean_absolute_error: 74.2325 val_loss: 10227.6582 val_mean_squared_error: 10227.6582 val_mean_absolute_error: 65.9034\n","Model: \"sequential_333\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1059 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1060 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_393 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1061 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 28846.9551 - mse: 28846.9551 - mae: 123.3879 - val_loss: 16630.7559 - val_mse: 16630.7559 - val_mae: 90.7100\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17586.7012 - mse: 17586.7012 - mae: 91.7817 - val_loss: 13810.6494 - val_mse: 13810.6494 - val_mae: 80.7316\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16393.3320 - mse: 16393.3320 - mae: 87.2574 - val_loss: 13545.4580 - val_mse: 13545.4580 - val_mae: 76.5866\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15630.4521 - mse: 15630.4521 - mae: 85.4500 - val_loss: 12900.3887 - val_mse: 12900.3887 - val_mae: 75.6218\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15657.2529 - mse: 15657.2529 - mae: 84.8518 - val_loss: 12738.5479 - val_mse: 12738.5479 - val_mae: 74.4527\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15195.6279 - mse: 15195.6279 - mae: 82.9602 - val_loss: 12355.7588 - val_mse: 12355.7588 - val_mae: 73.6086\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14694.9150 - mse: 14694.9150 - mae: 81.5892 - val_loss: 12417.2178 - val_mse: 12417.2178 - val_mae: 71.2775\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14809.4629 - mse: 14809.4629 - mae: 81.5188 - val_loss: 11851.2461 - val_mse: 11851.2461 - val_mae: 78.2082\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14531.3535 - mse: 14531.3535 - mae: 80.5826 - val_loss: 11627.0596 - val_mse: 11627.0596 - val_mae: 70.4846\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14289.7734 - mse: 14289.7734 - mae: 79.5908 - val_loss: 11380.4600 - val_mse: 11380.4600 - val_mae: 71.3704\n","163/163 [==============================] - 0s 916us/step\n","Epoch 10/10\n","8/8 loss: 14289.7734 mean_squared_error: 14289.7734 mean_absolute_error: 79.5908 val_loss: 11380.4600 val_mean_squared_error: 11380.4600 val_mean_absolute_error: 71.3704\n","Model: \"sequential_334\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1062 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1063 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_394 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1064 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 26177.3262 - mse: 26177.3262 - mae: 117.9031 - val_loss: 16183.7285 - val_mse: 16183.7285 - val_mae: 91.2349\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15834.2725 - mse: 15834.2725 - mae: 88.3090 - val_loss: 13760.7354 - val_mse: 13760.7354 - val_mae: 81.2743\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14861.1396 - mse: 14861.1396 - mae: 84.8804 - val_loss: 13377.0264 - val_mse: 13377.0264 - val_mae: 78.8006\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14716.3467 - mse: 14716.3467 - mae: 84.0477 - val_loss: 13093.2842 - val_mse: 13093.2842 - val_mae: 78.8022\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14471.9551 - mse: 14471.9551 - mae: 83.1738 - val_loss: 12956.6689 - val_mse: 12956.6689 - val_mae: 80.9418\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14554.4902 - mse: 14554.4902 - mae: 83.4757 - val_loss: 12967.9922 - val_mse: 12967.9922 - val_mae: 81.6593\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14423.5498 - mse: 14423.5498 - mae: 83.5660 - val_loss: 12916.3516 - val_mse: 12916.3516 - val_mae: 80.2456\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14624.9980 - mse: 14624.9980 - mae: 83.3437 - val_loss: 12954.5283 - val_mse: 12954.5283 - val_mae: 80.9767\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14732.9912 - mse: 14732.9912 - mae: 83.7950 - val_loss: 13082.4199 - val_mse: 13082.4199 - val_mae: 77.5158\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14295.0215 - mse: 14295.0215 - mae: 83.1388 - val_loss: 13459.4619 - val_mse: 13459.4619 - val_mae: 87.9719\n","163/163 [==============================] - 0s 926us/step\n","Epoch 10/10\n","8/8 loss: 14295.0215 mean_squared_error: 14295.0215 mean_absolute_error: 83.1388 val_loss: 13459.4619 val_mean_squared_error: 13459.4619 val_mean_absolute_error: 87.9719\n","Model: \"sequential_335\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1065 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1066 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_395 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1067 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_396 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1068 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24057.8301 - mse: 24057.8301 - mae: 107.0401 - val_loss: 13476.8105 - val_mse: 13476.8105 - val_mae: 76.8531\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16477.3457 - mse: 16477.3457 - mae: 86.2018 - val_loss: 12416.0752 - val_mse: 12416.0752 - val_mae: 73.5674\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15091.4189 - mse: 15091.4189 - mae: 82.1178 - val_loss: 11942.1982 - val_mse: 11942.1982 - val_mae: 67.8396\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14055.6377 - mse: 14055.6377 - mae: 78.6917 - val_loss: 10164.8896 - val_mse: 10164.8896 - val_mae: 67.4109\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13981.3848 - mse: 13981.3848 - mae: 77.4767 - val_loss: 10413.4854 - val_mse: 10413.4854 - val_mae: 64.6764\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13032.0068 - mse: 13032.0068 - mae: 74.1691 - val_loss: 9685.9287 - val_mse: 9685.9287 - val_mae: 69.3485\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13051.5186 - mse: 13051.5186 - mae: 73.6893 - val_loss: 9290.1338 - val_mse: 9290.1338 - val_mae: 63.5684\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12393.1416 - mse: 12393.1416 - mae: 71.5924 - val_loss: 9213.0049 - val_mse: 9213.0049 - val_mae: 61.7605\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12531.3438 - mse: 12531.3438 - mae: 71.8434 - val_loss: 9952.4404 - val_mse: 9952.4404 - val_mae: 61.8125\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12591.0273 - mse: 12591.0273 - mae: 71.9132 - val_loss: 9226.9482 - val_mse: 9226.9482 - val_mae: 64.9851\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 12591.0273 mean_squared_error: 12591.0273 mean_absolute_error: 71.9132 val_loss: 9226.9482 val_mean_squared_error: 9226.9482 val_mean_absolute_error: 64.9851\n","Model: \"sequential_336\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1069 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1070 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_397 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1071 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_398 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1072 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 57214.8008 - mse: 57214.8008 - mae: 166.0308 - val_loss: 50510.6094 - val_mse: 50510.6094 - val_mae: 154.3139\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 44992.2656 - mse: 44992.2656 - mae: 147.3315 - val_loss: 41486.8125 - val_mse: 41486.8125 - val_mae: 142.7614\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 38690.3516 - mse: 38690.3516 - mae: 140.5638 - val_loss: 35552.9062 - val_mse: 35552.9062 - val_mae: 128.8790\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 31128.8750 - mse: 31128.8750 - mae: 114.9153 - val_loss: 28296.1465 - val_mse: 28296.1465 - val_mae: 107.7510\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 25728.1055 - mse: 25728.1055 - mae: 101.7972 - val_loss: 22825.7578 - val_mse: 22825.7578 - val_mae: 88.6440\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 21656.3965 - mse: 21656.3965 - mae: 92.4477 - val_loss: 19491.5742 - val_mse: 19491.5742 - val_mae: 82.1973\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19010.4961 - mse: 19010.4961 - mae: 87.9022 - val_loss: 17031.9141 - val_mse: 17031.9141 - val_mae: 79.1519\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17727.9141 - mse: 17727.9141 - mae: 86.8441 - val_loss: 15444.8457 - val_mse: 15444.8457 - val_mae: 75.8080\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16424.9199 - mse: 16424.9199 - mae: 84.7141 - val_loss: 14507.6602 - val_mse: 14507.6602 - val_mae: 72.3213\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15815.6553 - mse: 15815.6553 - mae: 84.8662 - val_loss: 13607.6182 - val_mse: 13607.6182 - val_mae: 68.9474\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 15815.6553 mean_squared_error: 15815.6553 mean_absolute_error: 84.8662 val_loss: 13607.6182 val_mean_squared_error: 13607.6182 val_mean_absolute_error: 68.9474\n","Model: \"sequential_337\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1073 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1074 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_399 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1075 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_400 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1076 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 22062.2285 - mse: 22062.2285 - mae: 103.2865 - val_loss: 13661.3506 - val_mse: 13661.3506 - val_mae: 76.7375\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15953.8887 - mse: 15953.8887 - mae: 84.6148 - val_loss: 13081.1543 - val_mse: 13081.1543 - val_mae: 70.0659\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14720.7500 - mse: 14720.7500 - mae: 80.4546 - val_loss: 10877.9893 - val_mse: 10877.9893 - val_mae: 69.6320\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13708.8877 - mse: 13708.8877 - mae: 77.4453 - val_loss: 11163.8740 - val_mse: 11163.8740 - val_mae: 77.0525\n","Epoch 5/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 13591.3936 - mse: 13591.3936 - mae: 76.7121 - val_loss: 10815.0576 - val_mse: 10815.0576 - val_mae: 65.1789\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12597.2461 - mse: 12597.2461 - mae: 74.1181 - val_loss: 10313.1152 - val_mse: 10313.1152 - val_mae: 71.0279\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13007.5400 - mse: 13007.5400 - mae: 75.1990 - val_loss: 10612.1279 - val_mse: 10612.1279 - val_mae: 64.7797\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12888.2207 - mse: 12888.2207 - mae: 74.9668 - val_loss: 9877.7061 - val_mse: 9877.7061 - val_mae: 64.2355\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12495.5117 - mse: 12495.5117 - mae: 74.4166 - val_loss: 9702.0791 - val_mse: 9702.0791 - val_mae: 64.6962\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12422.1201 - mse: 12422.1201 - mae: 74.1903 - val_loss: 9403.2793 - val_mse: 9403.2793 - val_mae: 64.1187\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 12422.1201 mean_squared_error: 12422.1201 mean_absolute_error: 74.1903 val_loss: 9403.2793 val_mean_squared_error: 9403.2793 val_mean_absolute_error: 64.1187\n","Model: \"sequential_338\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1077 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1078 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_401 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1079 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_402 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1080 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 22851.0215 - mse: 22851.0215 - mae: 105.2367 - val_loss: 13804.2490 - val_mse: 13804.2490 - val_mae: 77.4879\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16119.6191 - mse: 16119.6191 - mae: 86.1552 - val_loss: 12563.9180 - val_mse: 12563.9180 - val_mae: 75.4390\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15407.1006 - mse: 15407.1006 - mae: 83.3239 - val_loss: 11769.9473 - val_mse: 11769.9473 - val_mae: 79.8197\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14133.9404 - mse: 14133.9404 - mae: 78.9115 - val_loss: 10394.4287 - val_mse: 10394.4287 - val_mae: 68.7489\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13700.1143 - mse: 13700.1143 - mae: 76.7137 - val_loss: 9846.7793 - val_mse: 9846.7793 - val_mae: 66.3590\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 13586.3389 - mse: 13586.3389 - mae: 75.4703 - val_loss: 9448.1475 - val_mse: 9448.1475 - val_mae: 65.4176\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12821.4160 - mse: 12821.4160 - mae: 72.9574 - val_loss: 9337.1543 - val_mse: 9337.1543 - val_mae: 63.8663\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12819.6348 - mse: 12819.6348 - mae: 72.9519 - val_loss: 9200.1982 - val_mse: 9200.1982 - val_mae: 65.0671\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 12600.8828 - mse: 12600.8828 - mae: 71.7559 - val_loss: 9047.1475 - val_mse: 9047.1475 - val_mae: 62.9277\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 11955.9277 - mse: 11955.9277 - mae: 70.0450 - val_loss: 8798.7617 - val_mse: 8798.7617 - val_mae: 61.5130\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 11955.9277 mean_squared_error: 11955.9277 mean_absolute_error: 70.0450 val_loss: 8798.7617 val_mean_squared_error: 8798.7617 val_mean_absolute_error: 61.5130\n","Model: \"sequential_339\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1081 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1082 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_403 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1083 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_404 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1084 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 4s 2ms/step - loss: 20362.9824 - mse: 20362.9824 - mae: 100.5556 - val_loss: 13464.2695 - val_mse: 13464.2695 - val_mae: 80.2178\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15588.6768 - mse: 15588.6768 - mae: 86.2693 - val_loss: 12979.2451 - val_mse: 12979.2451 - val_mae: 80.1026\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15368.4824 - mse: 15368.4824 - mae: 85.8257 - val_loss: 13588.9199 - val_mse: 13588.9199 - val_mae: 76.6450\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15432.4932 - mse: 15432.4932 - mae: 85.8957 - val_loss: 12968.5479 - val_mse: 12968.5479 - val_mae: 79.1262\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15591.6465 - mse: 15591.6465 - mae: 85.8615 - val_loss: 13056.4004 - val_mse: 13056.4004 - val_mae: 77.9528\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15760.9141 - mse: 15760.9141 - mae: 85.7848 - val_loss: 13302.1758 - val_mse: 13302.1758 - val_mae: 76.9528\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15738.2168 - mse: 15738.2168 - mae: 86.7529 - val_loss: 12969.4131 - val_mse: 12969.4131 - val_mae: 80.6879\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15205.3760 - mse: 15205.3760 - mae: 85.2835 - val_loss: 13215.9629 - val_mse: 13215.9629 - val_mae: 77.1509\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15246.6475 - mse: 15246.6475 - mae: 85.5052 - val_loss: 12975.5771 - val_mse: 12975.5771 - val_mae: 82.0272\n","Epoch 9: early stopping\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 15246.6475 mean_squared_error: 15246.6475 mean_absolute_error: 85.5052 val_loss: 12975.5771 val_mean_squared_error: 12975.5771 val_mean_absolute_error: 82.0272\n","Model: \"sequential_340\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1085 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1086 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_405 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1087 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 34083.3164 - mse: 34083.3164 - mae: 134.0087 - val_loss: 19710.4219 - val_mse: 19710.4219 - val_mae: 103.1662\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20950.2734 - mse: 20950.2734 - mae: 101.1588 - val_loss: 15189.0430 - val_mse: 15189.0430 - val_mae: 84.4441\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19000.9316 - mse: 19000.9316 - mae: 94.2096 - val_loss: 14211.8096 - val_mse: 14211.8096 - val_mae: 78.7707\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18128.3164 - mse: 18128.3164 - mae: 91.1196 - val_loss: 13407.1377 - val_mse: 13407.1377 - val_mae: 77.8973\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17969.1660 - mse: 17969.1660 - mae: 91.0060 - val_loss: 13567.2930 - val_mse: 13567.2930 - val_mae: 75.7520\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17936.7871 - mse: 17936.7871 - mae: 90.0134 - val_loss: 12982.4385 - val_mse: 12982.4385 - val_mae: 76.3779\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17552.0391 - mse: 17552.0391 - mae: 89.6319 - val_loss: 13552.0566 - val_mse: 13552.0566 - val_mae: 74.5571\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17344.5410 - mse: 17344.5410 - mae: 88.9240 - val_loss: 12838.3955 - val_mse: 12838.3955 - val_mae: 73.2292\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16577.6934 - mse: 16577.6934 - mae: 86.4842 - val_loss: 12347.5684 - val_mse: 12347.5684 - val_mae: 75.0426\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17121.2070 - mse: 17121.2070 - mae: 87.3415 - val_loss: 12432.7881 - val_mse: 12432.7881 - val_mae: 70.9298\n","163/163 [==============================] - 0s 887us/step\n","Epoch 10/10\n","8/8 loss: 17121.2070 mean_squared_error: 17121.2070 mean_absolute_error: 87.3415 val_loss: 12432.7881 val_mean_squared_error: 12432.7881 val_mean_absolute_error: 70.9298\n","Model: \"sequential_341\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1088 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1089 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_406 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1090 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 62179.3125 - mse: 62179.3125 - mae: 174.5384 - val_loss: 58167.2773 - val_mse: 58167.2773 - val_mae: 166.3602\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 53694.0938 - mse: 53694.0938 - mae: 159.9514 - val_loss: 50898.3828 - val_mse: 50898.3828 - val_mae: 154.8778\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 47592.6992 - mse: 47592.6992 - mae: 150.9846 - val_loss: 45462.1680 - val_mse: 45462.1680 - val_mae: 147.3661\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 42256.4727 - mse: 42256.4727 - mae: 138.6685 - val_loss: 39641.1133 - val_mse: 39641.1133 - val_mae: 129.7805\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 37153.4531 - mse: 37153.4531 - mae: 125.0054 - val_loss: 35050.7031 - val_mse: 35050.7031 - val_mae: 118.9354\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 33271.9258 - mse: 33271.9258 - mae: 116.3132 - val_loss: 30928.4609 - val_mse: 30928.4609 - val_mae: 106.6335\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 29389.1348 - mse: 29389.1348 - mae: 107.1514 - val_loss: 27447.7812 - val_mse: 27447.7812 - val_mae: 98.4002\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 26440.2422 - mse: 26440.2422 - mae: 101.0017 - val_loss: 24766.5586 - val_mse: 24766.5586 - val_mae: 92.2131\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 24401.7793 - mse: 24401.7793 - mae: 97.3768 - val_loss: 22366.7285 - val_mse: 22366.7285 - val_mae: 87.0722\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 22400.2012 - mse: 22400.2012 - mae: 93.8849 - val_loss: 20530.7012 - val_mse: 20530.7012 - val_mae: 84.3235\n","163/163 [==============================] - 0s 986us/step\n","Epoch 10/10\n","8/8 loss: 22400.2012 mean_squared_error: 22400.2012 mean_absolute_error: 93.8849 val_loss: 20530.7012 val_mean_squared_error: 20530.7012 val_mean_absolute_error: 84.3235\n","Model: \"sequential_342\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1091 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1092 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_407 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1093 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 36900.6484 - mse: 36900.6484 - mae: 138.1747 - val_loss: 21766.0645 - val_mse: 21766.0645 - val_mae: 102.9446\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 23220.9551 - mse: 23220.9551 - mae: 106.8234 - val_loss: 16058.0713 - val_mse: 16058.0713 - val_mae: 86.9451\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20504.4121 - mse: 20504.4121 - mae: 97.3411 - val_loss: 15072.2100 - val_mse: 15072.2100 - val_mae: 78.3784\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18283.0488 - mse: 18283.0488 - mae: 91.5022 - val_loss: 13784.3838 - val_mse: 13784.3838 - val_mae: 75.4619\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17793.7188 - mse: 17793.7188 - mae: 88.0467 - val_loss: 12488.5752 - val_mse: 12488.5752 - val_mae: 72.4780\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16859.2188 - mse: 16859.2188 - mae: 85.5012 - val_loss: 12159.8594 - val_mse: 12159.8594 - val_mae: 71.0617\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15988.1738 - mse: 15988.1738 - mae: 82.3790 - val_loss: 11473.9941 - val_mse: 11473.9941 - val_mae: 72.0927\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15570.8604 - mse: 15570.8604 - mae: 81.5567 - val_loss: 11373.7285 - val_mse: 11373.7285 - val_mae: 68.0596\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15527.5439 - mse: 15527.5439 - mae: 81.8275 - val_loss: 12122.6904 - val_mse: 12122.6904 - val_mae: 68.0117\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14904.4678 - mse: 14904.4678 - mae: 80.2020 - val_loss: 11050.0781 - val_mse: 11050.0781 - val_mae: 68.2644\n","163/163 [==============================] - 0s 904us/step\n","Epoch 10/10\n","8/8 loss: 14904.4678 mean_squared_error: 14904.4678 mean_absolute_error: 80.2020 val_loss: 11050.0781 val_mean_squared_error: 11050.0781 val_mean_absolute_error: 68.2644\n","Model: \"sequential_343\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1094 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1095 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_408 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1096 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 35229.3945 - mse: 35229.3945 - mae: 136.8223 - val_loss: 22184.6504 - val_mse: 22184.6504 - val_mae: 112.8494\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 22322.8711 - mse: 22322.8711 - mae: 106.6993 - val_loss: 15924.5869 - val_mse: 15924.5869 - val_mae: 86.7231\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19175.4141 - mse: 19175.4141 - mae: 94.7205 - val_loss: 14181.8525 - val_mse: 14181.8525 - val_mae: 79.3376\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18648.1621 - mse: 18648.1621 - mae: 91.9349 - val_loss: 13721.2715 - val_mse: 13721.2715 - val_mae: 78.3465\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18042.6875 - mse: 18042.6875 - mae: 90.3457 - val_loss: 13718.1367 - val_mse: 13718.1367 - val_mae: 76.2969\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17920.7734 - mse: 17920.7734 - mae: 90.5812 - val_loss: 13808.8828 - val_mse: 13808.8828 - val_mae: 75.3575\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17398.7715 - mse: 17398.7715 - mae: 89.4930 - val_loss: 12875.4053 - val_mse: 12875.4053 - val_mae: 76.1640\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17308.2949 - mse: 17308.2949 - mae: 88.5583 - val_loss: 12747.4541 - val_mse: 12747.4541 - val_mae: 76.1085\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17108.2344 - mse: 17108.2344 - mae: 88.2486 - val_loss: 12595.4111 - val_mse: 12595.4111 - val_mae: 74.7244\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17113.2871 - mse: 17113.2871 - mae: 87.4438 - val_loss: 12434.4473 - val_mse: 12434.4473 - val_mae: 73.4743\n","163/163 [==============================] - 0s 984us/step\n","Epoch 10/10\n","8/8 loss: 17113.2871 mean_squared_error: 17113.2871 mean_absolute_error: 87.4438 val_loss: 12434.4473 val_mean_squared_error: 12434.4473 val_mean_absolute_error: 73.4743\n","Model: \"sequential_344\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1097 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1098 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_409 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1099 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 31329.2344 - mse: 31329.2344 - mae: 130.2196 - val_loss: 20224.3828 - val_mse: 20224.3828 - val_mae: 101.9619\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18457.9375 - mse: 18457.9375 - mae: 96.9064 - val_loss: 14937.3867 - val_mse: 14937.3867 - val_mae: 84.5093\n","Epoch 3/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 16301.9326 - mse: 16301.9326 - mae: 88.5586 - val_loss: 13712.0830 - val_mse: 13712.0830 - val_mae: 82.2937\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15916.2061 - mse: 15916.2061 - mae: 87.2270 - val_loss: 13303.2383 - val_mse: 13303.2383 - val_mae: 80.8189\n","Epoch 5/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 15974.0820 - mse: 15974.0820 - mae: 87.1250 - val_loss: 13260.1279 - val_mse: 13260.1279 - val_mae: 78.3032\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15522.4082 - mse: 15522.4082 - mae: 86.0789 - val_loss: 13145.3213 - val_mse: 13145.3213 - val_mae: 78.2139\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15577.5098 - mse: 15577.5098 - mae: 85.7295 - val_loss: 12975.0742 - val_mse: 12975.0742 - val_mae: 80.8631\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 15615.1895 - mse: 15615.1895 - mae: 86.2249 - val_loss: 13265.9980 - val_mse: 13265.9980 - val_mae: 77.4807\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15461.1748 - mse: 15461.1748 - mae: 85.8006 - val_loss: 13049.8955 - val_mse: 13049.8955 - val_mae: 83.6478\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 15452.5791 - mse: 15452.5791 - mae: 86.0985 - val_loss: 13106.5947 - val_mse: 13106.5947 - val_mae: 77.7152\n","163/163 [==============================] - 0s 978us/step\n","Epoch 10/10\n","8/8 loss: 15452.5791 mean_squared_error: 15452.5791 mean_absolute_error: 86.0985 val_loss: 13106.5947 val_mean_squared_error: 13106.5947 val_mean_absolute_error: 77.7152\n","Model: \"sequential_345\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1100 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1101 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_410 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1102 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_411 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1103 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 31364.3008 - mse: 31364.3008 - mae: 123.6278 - val_loss: 15091.8848 - val_mse: 15091.8848 - val_mae: 81.1936\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 20142.5137 - mse: 20142.5137 - mae: 94.9811 - val_loss: 14174.8047 - val_mse: 14174.8047 - val_mae: 77.7884\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19565.5195 - mse: 19565.5195 - mae: 94.4004 - val_loss: 12667.9385 - val_mse: 12667.9385 - val_mae: 78.6447\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 18686.4785 - mse: 18686.4785 - mae: 91.2085 - val_loss: 12938.8457 - val_mse: 12938.8457 - val_mae: 71.8767\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18356.3984 - mse: 18356.3984 - mae: 89.9968 - val_loss: 13096.4814 - val_mse: 13096.4814 - val_mae: 70.2514\n","Epoch 6/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 17717.8789 - mse: 17717.8789 - mae: 88.0793 - val_loss: 11604.6934 - val_mse: 11604.6934 - val_mae: 77.4536\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18098.2305 - mse: 18098.2305 - mae: 87.5406 - val_loss: 11744.1768 - val_mse: 11744.1768 - val_mae: 70.2912\n","Epoch 8/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 17226.7734 - mse: 17226.7734 - mae: 85.6768 - val_loss: 11219.9434 - val_mse: 11219.9434 - val_mae: 67.2123\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17395.8691 - mse: 17395.8691 - mae: 85.8864 - val_loss: 11163.0586 - val_mse: 11163.0586 - val_mae: 67.8606\n","Epoch 10/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 16507.0703 - mse: 16507.0703 - mae: 83.6981 - val_loss: 10595.6211 - val_mse: 10595.6211 - val_mae: 65.8721\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","8/8 loss: 16507.0703 mean_squared_error: 16507.0703 mean_absolute_error: 83.6981 val_loss: 10595.6211 val_mean_squared_error: 10595.6211 val_mean_absolute_error: 65.8721\n","Model: \"sequential_346\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1104 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1105 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_412 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1106 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_413 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1107 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 62753.2969 - mse: 62753.3008 - mae: 175.6889 - val_loss: 58720.4766 - val_mse: 58720.4766 - val_mae: 167.2993\n","Epoch 2/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 54310.8906 - mse: 54310.8906 - mae: 160.8463 - val_loss: 51394.8281 - val_mse: 51394.8281 - val_mae: 155.6169\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 47829.1523 - mse: 47829.1523 - mae: 151.3216 - val_loss: 45811.9570 - val_mse: 45811.9570 - val_mae: 147.8318\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 43282.6445 - mse: 43282.6445 - mae: 145.4334 - val_loss: 41724.8633 - val_mse: 41724.8633 - val_mae: 143.0073\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 40204.1367 - mse: 40204.1367 - mae: 142.5989 - val_loss: 38864.0391 - val_mse: 38864.0391 - val_mae: 140.3821\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 37786.6680 - mse: 37786.6680 - mae: 140.0920 - val_loss: 35106.5781 - val_mse: 35106.5781 - val_mae: 122.0531\n","Epoch 7/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 32857.1992 - mse: 32857.1992 - mae: 119.3999 - val_loss: 30367.0977 - val_mse: 30367.0977 - val_mae: 109.3030\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 29674.0605 - mse: 29674.0605 - mae: 111.2917 - val_loss: 26981.5898 - val_mse: 26981.5898 - val_mae: 99.5476\n","Epoch 9/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 26480.5898 - mse: 26480.5898 - mae: 103.2459 - val_loss: 24347.2324 - val_mse: 24347.2324 - val_mae: 93.4443\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 24588.2812 - mse: 24588.2812 - mae: 100.2828 - val_loss: 22085.4727 - val_mse: 22085.4727 - val_mae: 88.4026\n","163/163 [==============================] - 0s 995us/step\n","Epoch 10/10\n","8/8 loss: 24588.2812 mean_squared_error: 24588.2812 mean_absolute_error: 100.2828 val_loss: 22085.4727 val_mean_squared_error: 22085.4727 val_mean_absolute_error: 88.4026\n","Model: \"sequential_347\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1108 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1109 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_414 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1110 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_415 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1111 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 5s 3ms/step - loss: 30403.1816 - mse: 30403.1816 - mae: 122.4051 - val_loss: 15631.1934 - val_mse: 15631.1934 - val_mae: 81.8459\n","Epoch 2/10\n","1065/1065 [==============================] - 4s 3ms/step - loss: 20528.5508 - mse: 20528.5508 - mae: 95.7678 - val_loss: 13469.6592 - val_mse: 13469.6592 - val_mae: 74.6368\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18355.5176 - mse: 18355.5176 - mae: 89.5687 - val_loss: 12394.8994 - val_mse: 12394.8994 - val_mae: 75.1223\n","Epoch 4/10\n","1065/1065 [==============================] - 3s 3ms/step - loss: 17402.8730 - mse: 17402.8730 - mae: 86.1539 - val_loss: 12233.5674 - val_mse: 12233.5674 - val_mae: 68.8176\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17033.5195 - mse: 17033.5195 - mae: 85.1158 - val_loss: 11814.4502 - val_mse: 11814.4502 - val_mae: 70.5872\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16122.9717 - mse: 16122.9717 - mae: 83.5107 - val_loss: 11148.0879 - val_mse: 11148.0879 - val_mae: 68.7132\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15707.1299 - mse: 15707.1299 - mae: 83.1741 - val_loss: 10957.3096 - val_mse: 10957.3096 - val_mae: 66.5580\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15608.9189 - mse: 15608.9189 - mae: 81.7538 - val_loss: 11375.6650 - val_mse: 11375.6650 - val_mae: 66.9594\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 15668.4307 - mse: 15668.4307 - mae: 80.9065 - val_loss: 10518.1182 - val_mse: 10518.1182 - val_mae: 68.0767\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 14723.3086 - mse: 14723.3086 - mae: 79.6914 - val_loss: 10074.6182 - val_mse: 10074.6182 - val_mae: 66.2758\n","163/163 [==============================] - 0s 980us/step\n","Epoch 10/10\n","8/8 loss: 14723.3086 mean_squared_error: 14723.3086 mean_absolute_error: 79.6914 val_loss: 10074.6182 val_mean_squared_error: 10074.6182 val_mean_absolute_error: 66.2758\n","Model: \"sequential_348\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1112 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1113 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_416 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1114 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_417 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1115 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 32766.5117 - mse: 32766.5117 - mae: 126.4589 - val_loss: 15068.1670 - val_mse: 15068.1670 - val_mae: 84.8270\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20724.8164 - mse: 20724.8164 - mae: 96.8786 - val_loss: 13476.9893 - val_mse: 13476.9893 - val_mae: 76.3833\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 20044.1465 - mse: 20044.1465 - mae: 94.4086 - val_loss: 15575.9727 - val_mse: 15575.9727 - val_mae: 78.2551\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 19661.0098 - mse: 19661.0098 - mae: 92.7710 - val_loss: 12407.3076 - val_mse: 12407.3076 - val_mae: 72.3634\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18697.5449 - mse: 18697.5449 - mae: 89.6445 - val_loss: 12045.5146 - val_mse: 12045.5146 - val_mae: 70.2297\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18344.1895 - mse: 18344.1895 - mae: 88.9493 - val_loss: 12336.6172 - val_mse: 12336.6172 - val_mae: 71.0375\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17661.3027 - mse: 17661.3027 - mae: 87.0810 - val_loss: 11198.9209 - val_mse: 11198.9209 - val_mae: 68.6510\n","Epoch 8/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 18016.5996 - mse: 18016.5996 - mae: 86.6976 - val_loss: 10722.1914 - val_mse: 10722.1914 - val_mae: 68.0880\n","Epoch 9/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17329.0957 - mse: 17329.0957 - mae: 84.7761 - val_loss: 10275.9707 - val_mse: 10275.9707 - val_mae: 68.6790\n","Epoch 10/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17671.6387 - mse: 17671.6387 - mae: 85.8744 - val_loss: 10194.8584 - val_mse: 10194.8584 - val_mae: 66.8825\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","8/8 loss: 17671.6387 mean_squared_error: 17671.6387 mean_absolute_error: 85.8744 val_loss: 10194.8584 val_mean_squared_error: 10194.8584 val_mean_absolute_error: 66.8825\n","Model: \"sequential_349\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1116 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1117 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_418 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1118 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_419 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1119 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1065/1065 [==============================] - 3s 2ms/step - loss: 24485.6504 - mse: 24485.6504 - mae: 111.2959 - val_loss: 14067.3779 - val_mse: 14067.3779 - val_mae: 82.2648\n","Epoch 2/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17577.7500 - mse: 17577.7500 - mae: 90.8162 - val_loss: 13215.0566 - val_mse: 13215.0566 - val_mae: 79.3074\n","Epoch 3/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17135.3750 - mse: 17135.3750 - mae: 89.4925 - val_loss: 15350.1064 - val_mse: 15350.1064 - val_mae: 78.2107\n","Epoch 4/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17030.1426 - mse: 17030.1426 - mae: 89.4991 - val_loss: 13528.5234 - val_mse: 13528.5234 - val_mae: 76.6383\n","Epoch 5/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 16983.7129 - mse: 16983.7129 - mae: 89.3906 - val_loss: 13830.3916 - val_mse: 13830.3916 - val_mae: 76.9807\n","Epoch 6/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17373.6035 - mse: 17373.6035 - mae: 89.6870 - val_loss: 13242.0801 - val_mse: 13242.0801 - val_mae: 78.6855\n","Epoch 7/10\n","1065/1065 [==============================] - 2s 2ms/step - loss: 17209.1523 - mse: 17209.1523 - mae: 90.6179 - val_loss: 13385.5938 - val_mse: 13385.5938 - val_mae: 76.4462\n","Epoch 7: early stopping\n","163/163 [==============================] - 0s 922us/step\n","Epoch 10/10\n","8/8 loss: 17209.1523 mean_squared_error: 17209.1523 mean_absolute_error: 90.6179 val_loss: 13385.5938 val_mean_squared_error: 13385.5938 val_mean_absolute_error: 76.4462\n","Model: \"sequential_350\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1120 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1121 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 51661.1406 - mse: 51661.1406 - mae: 158.0809 - val_loss: 32399.9238 - val_mse: 32399.9238 - val_mae: 128.7177\n","163/163 [==============================] - 0s 955us/step\n","Epoch 1/1\n","12/12 loss: 51661.1406 mean_squared_error: 51661.1406 mean_absolute_error: 158.0809 val_loss: 32399.9238 val_mean_squared_error: 32399.9238 val_mean_absolute_error: 128.7177\n","Model: \"sequential_351\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1122 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1123 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 58618.3281 - mse: 58618.3281 - mae: 168.6578 - val_loss: 51448.1562 - val_mse: 51448.1562 - val_mae: 155.5150\n","163/163 [==============================] - 0s 873us/step\n","Epoch 1/1\n","12/12 loss: 58618.3281 mean_squared_error: 58618.3281 mean_absolute_error: 168.6578 val_loss: 51448.1562 val_mean_squared_error: 51448.1562 val_mean_absolute_error: 155.5150\n","Model: \"sequential_352\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1124 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1125 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 47708.9141 - mse: 47708.9141 - mae: 152.2715 - val_loss: 30333.0195 - val_mse: 30333.0195 - val_mae: 130.2510\n","163/163 [==============================] - 0s 985us/step\n","Epoch 1/1\n","12/12 loss: 47708.9141 mean_squared_error: 47708.9141 mean_absolute_error: 152.2715 val_loss: 30333.0195 val_mean_squared_error: 30333.0195 val_mean_absolute_error: 130.2510\n","Model: \"sequential_353\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1126 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1127 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 50691.2578 - mse: 50691.2578 - mae: 157.0335 - val_loss: 30955.8262 - val_mse: 30955.8262 - val_mae: 128.3058\n","163/163 [==============================] - 0s 853us/step\n","Epoch 1/1\n","12/12 loss: 50691.2578 mean_squared_error: 50691.2578 mean_absolute_error: 157.0335 val_loss: 30955.8262 val_mean_squared_error: 30955.8262 val_mean_absolute_error: 128.3058\n","Model: \"sequential_354\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1128 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1129 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 45880.3008 - mse: 45880.3047 - mae: 151.1868 - val_loss: 28992.1113 - val_mse: 28992.1113 - val_mae: 128.7124\n","163/163 [==============================] - 0s 956us/step\n","Epoch 1/1\n","12/12 loss: 45880.3008 mean_squared_error: 45880.3047 mean_absolute_error: 151.1868 val_loss: 28992.1113 val_mean_squared_error: 28992.1113 val_mean_absolute_error: 128.7124\n","Model: \"sequential_355\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1130 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1131 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_420 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1132 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 33078.8359 - mse: 33078.8359 - mae: 132.0614 - val_loss: 19254.4648 - val_mse: 19254.4648 - val_mae: 100.1318\n","163/163 [==============================] - 0s 977us/step\n","Epoch 1/1\n","12/12 loss: 33078.8359 mean_squared_error: 33078.8359 mean_absolute_error: 132.0614 val_loss: 19254.4648 val_mean_squared_error: 19254.4648 val_mean_absolute_error: 100.1318\n","Model: \"sequential_356\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1133 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1134 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_421 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1135 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 59611.5977 - mse: 59611.5977 - mae: 170.0364 - val_loss: 54284.4766 - val_mse: 54284.4766 - val_mae: 160.0456\n","163/163 [==============================] - 0s 930us/step\n","Epoch 1/1\n","12/12 loss: 59611.5977 mean_squared_error: 59611.5977 mean_absolute_error: 170.0364 val_loss: 54284.4766 val_mean_squared_error: 54284.4766 val_mean_absolute_error: 160.0456\n","Model: \"sequential_357\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1136 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1137 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_422 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1138 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 30680.8301 - mse: 30680.8301 - mae: 127.1276 - val_loss: 17785.4551 - val_mse: 17785.4551 - val_mae: 96.0989\n","163/163 [==============================] - 0s 956us/step\n","Epoch 1/1\n","12/12 loss: 30680.8301 mean_squared_error: 30680.8301 mean_absolute_error: 127.1276 val_loss: 17785.4551 val_mean_squared_error: 17785.4551 val_mean_absolute_error: 96.0989\n","Model: \"sequential_358\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1139 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1140 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_423 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1141 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 32787.3516 - mse: 32787.3516 - mae: 132.0758 - val_loss: 18943.9531 - val_mse: 18943.9531 - val_mae: 101.6733\n","163/163 [==============================] - 0s 948us/step\n","Epoch 1/1\n","12/12 loss: 32787.3516 mean_squared_error: 32787.3516 mean_absolute_error: 132.0758 val_loss: 18943.9531 val_mean_squared_error: 18943.9531 val_mean_absolute_error: 101.6733\n","Model: \"sequential_359\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1142 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1143 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_424 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1144 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 27577.4414 - mse: 27577.4434 - mae: 122.2117 - val_loss: 17227.3047 - val_mse: 17227.3047 - val_mae: 95.1710\n","163/163 [==============================] - 0s 962us/step\n","Epoch 1/1\n","12/12 loss: 27577.4414 mean_squared_error: 27577.4434 mean_absolute_error: 122.2117 val_loss: 17227.3047 val_mean_squared_error: 17227.3047 val_mean_absolute_error: 95.1710\n","Model: \"sequential_360\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1145 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1146 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_425 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1147 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_426 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1148 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 25295.6035 - mse: 25295.6035 - mae: 111.5417 - val_loss: 14269.4541 - val_mse: 14269.4541 - val_mae: 77.4675\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 25295.6035 mean_squared_error: 25295.6035 mean_absolute_error: 111.5417 val_loss: 14269.4541 val_mean_squared_error: 14269.4541 val_mean_absolute_error: 77.4675\n","Model: \"sequential_361\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1149 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1150 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_427 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1151 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_428 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1152 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 59314.9219 - mse: 59314.9219 - mae: 169.4037 - val_loss: 54153.6953 - val_mse: 54153.6953 - val_mae: 159.8483\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 59314.9219 mean_squared_error: 59314.9219 mean_absolute_error: 169.4037 val_loss: 54153.6953 val_mean_squared_error: 54153.6953 val_mean_absolute_error: 159.8483\n","Model: \"sequential_362\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1153 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1154 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_429 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1155 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_430 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1156 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 24492.4160 - mse: 24492.4160 - mae: 109.3013 - val_loss: 13486.0928 - val_mse: 13486.0928 - val_mae: 79.0885\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 24492.4160 mean_squared_error: 24492.4160 mean_absolute_error: 109.3013 val_loss: 13486.0928 val_mean_squared_error: 13486.0928 val_mean_absolute_error: 79.0885\n","Model: \"sequential_363\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1157 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1158 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_431 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1159 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_432 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1160 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 26403.8340 - mse: 26403.8340 - mae: 113.3307 - val_loss: 14826.7266 - val_mse: 14826.7266 - val_mae: 77.0340\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 26403.8340 mean_squared_error: 26403.8340 mean_absolute_error: 113.3307 val_loss: 14826.7266 val_mean_squared_error: 14826.7266 val_mean_absolute_error: 77.0340\n","Model: \"sequential_364\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1161 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1162 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_433 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1163 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_434 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1164 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 22088.2402 - mse: 22088.2402 - mae: 104.3114 - val_loss: 13455.8682 - val_mse: 13455.8682 - val_mae: 79.8343\n","163/163 [==============================] - 1s 2ms/step\n","Epoch 1/1\n","12/12 loss: 22088.2402 mean_squared_error: 22088.2402 mean_absolute_error: 104.3114 val_loss: 13455.8682 val_mean_squared_error: 13455.8682 val_mean_absolute_error: 79.8343\n","Model: \"sequential_365\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1165 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1166 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_435 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1167 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 37872.9531 - mse: 37872.9531 - mae: 141.4921 - val_loss: 23433.4004 - val_mse: 23433.4004 - val_mae: 113.8142\n","163/163 [==============================] - 0s 900us/step\n","Epoch 1/1\n","12/12 loss: 37872.9531 mean_squared_error: 37872.9531 mean_absolute_error: 141.4921 val_loss: 23433.4004 val_mean_squared_error: 23433.4004 val_mean_absolute_error: 113.8142\n","Model: \"sequential_366\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1168 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1169 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_436 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1170 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 4ms/step - loss: 63481.7695 - mse: 63481.7695 - mae: 176.9418 - val_loss: 60676.2656 - val_mse: 60676.2656 - val_mae: 170.7174\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 63481.7695 mean_squared_error: 63481.7695 mean_absolute_error: 176.9418 val_loss: 60676.2656 val_mean_squared_error: 60676.2656 val_mean_absolute_error: 170.7174\n","Model: \"sequential_367\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1171 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1172 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_437 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1173 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 2s 2ms/step - loss: 37262.1953 - mse: 37262.1992 - mae: 140.3930 - val_loss: 23019.2891 - val_mse: 23019.2891 - val_mae: 112.4145\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 37262.1953 mean_squared_error: 37262.1992 mean_absolute_error: 140.3930 val_loss: 23019.2891 val_mean_squared_error: 23019.2891 val_mean_absolute_error: 112.4145\n","Model: \"sequential_368\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1174 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1175 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_438 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1176 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 3ms/step - loss: 39178.1367 - mse: 39178.1367 - mae: 143.0238 - val_loss: 23726.7188 - val_mse: 23726.7188 - val_mae: 116.5312\n","163/163 [==============================] - 0s 986us/step\n","Epoch 1/1\n","12/12 loss: 39178.1367 mean_squared_error: 39178.1367 mean_absolute_error: 143.0238 val_loss: 23726.7188 val_mean_squared_error: 23726.7188 val_mean_absolute_error: 116.5312\n","Model: \"sequential_369\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1177 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1178 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_439 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1179 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 33085.1367 - mse: 33085.1367 - mae: 133.9467 - val_loss: 21422.5840 - val_mse: 21422.5840 - val_mae: 110.8169\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","12/12 loss: 33085.1367 mean_squared_error: 33085.1367 mean_absolute_error: 133.9467 val_loss: 21422.5840 val_mean_squared_error: 21422.5840 val_mean_absolute_error: 110.8169\n","Model: \"sequential_370\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1180 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1181 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_440 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1182 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_441 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1183 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 31901.0078 - mse: 31901.0078 - mae: 126.3717 - val_loss: 16782.1738 - val_mse: 16782.1738 - val_mae: 83.7466\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 31901.0078 mean_squared_error: 31901.0078 mean_absolute_error: 126.3717 val_loss: 16782.1738 val_mean_squared_error: 16782.1738 val_mean_absolute_error: 83.7466\n","Model: \"sequential_371\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1184 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1185 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_442 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1186 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_443 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1187 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 3ms/step - loss: 63468.4727 - mse: 63468.4727 - mae: 176.9448 - val_loss: 60701.3047 - val_mse: 60701.3047 - val_mae: 170.7663\n","163/163 [==============================] - 0s 893us/step\n","Epoch 1/1\n","12/12 loss: 63468.4727 mean_squared_error: 63468.4727 mean_absolute_error: 176.9448 val_loss: 60701.3047 val_mean_squared_error: 60701.3047 val_mean_absolute_error: 170.7663\n","Model: \"sequential_372\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1188 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1189 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_444 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1190 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_445 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1191 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 3ms/step - loss: 30253.0977 - mse: 30253.0977 - mae: 122.0436 - val_loss: 16316.7480 - val_mse: 16316.7480 - val_mae: 84.1791\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 1/1\n","12/12 loss: 30253.0977 mean_squared_error: 30253.0977 mean_absolute_error: 122.0436 val_loss: 16316.7480 val_mean_squared_error: 16316.7480 val_mean_absolute_error: 84.1791\n","Model: \"sequential_373\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1192 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1193 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_446 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1194 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_447 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1195 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 3s 2ms/step - loss: 32505.8965 - mse: 32505.8965 - mae: 127.5822 - val_loss: 16481.4160 - val_mse: 16481.4160 - val_mae: 86.6188\n","163/163 [==============================] - 0s 988us/step\n","Epoch 1/1\n","12/12 loss: 32505.8965 mean_squared_error: 32505.8965 mean_absolute_error: 127.5822 val_loss: 16481.4160 val_mean_squared_error: 16481.4160 val_mean_absolute_error: 86.6188\n","Model: \"sequential_374\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1196 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1197 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_448 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1198 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_449 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1199 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","710/710 [==============================] - 4s 3ms/step - loss: 27544.2969 - mse: 27544.2969 - mae: 118.0072 - val_loss: 15677.8750 - val_mse: 15677.8750 - val_mae: 84.4567\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","12/12 loss: 27544.2969 mean_squared_error: 27544.2969 mean_absolute_error: 118.0072 val_loss: 15677.8750 val_mean_squared_error: 15677.8750 val_mean_absolute_error: 84.4567\n","Model: \"sequential_375\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1200 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1201 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 49486.1523 - mse: 49486.1523 - mae: 155.3972 - val_loss: 30546.0781 - val_mse: 30546.0781 - val_mae: 128.0808\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 27377.3105 - mse: 27377.3105 - mae: 126.1015 - val_loss: 25312.4844 - val_mse: 25312.4844 - val_mae: 122.9408\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 22835.3203 - mse: 22835.3203 - mae: 114.8340 - val_loss: 21099.7207 - val_mse: 21099.7207 - val_mae: 107.4623\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19391.5293 - mse: 19391.5293 - mae: 103.2395 - val_loss: 18311.1094 - val_mse: 18311.1094 - val_mae: 100.8710\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17272.1270 - mse: 17272.1270 - mae: 95.9428 - val_loss: 16695.4023 - val_mse: 16695.4023 - val_mae: 95.4780\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 16002.2139 - mse: 16002.2139 - mae: 91.3285 - val_loss: 15696.6123 - val_mse: 15696.6123 - val_mae: 90.2957\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15180.8359 - mse: 15180.8359 - mae: 87.8964 - val_loss: 14972.4912 - val_mse: 14972.4912 - val_mae: 87.8901\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14584.3389 - mse: 14584.3389 - mae: 85.5600 - val_loss: 14445.1621 - val_mse: 14445.1621 - val_mae: 85.7276\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14139.7129 - mse: 14139.7129 - mae: 83.7461 - val_loss: 14036.0127 - val_mse: 14036.0127 - val_mae: 84.5273\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13819.1572 - mse: 13819.1572 - mae: 82.3637 - val_loss: 13724.0273 - val_mse: 13724.0273 - val_mae: 83.4318\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","12/12 loss: 13819.1572 mean_squared_error: 13819.1572 mean_absolute_error: 82.3637 val_loss: 13724.0273 val_mean_squared_error: 13724.0273 val_mean_absolute_error: 83.4318\n","Model: \"sequential_376\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1202 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1203 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 59345.1484 - mse: 59345.1445 - mae: 169.8940 - val_loss: 51885.6758 - val_mse: 51885.6758 - val_mae: 156.1762\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 46280.8711 - mse: 46280.8711 - mae: 148.6351 - val_loss: 42958.5508 - val_mse: 42958.5508 - val_mae: 143.9962\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 39574.6836 - mse: 39574.6836 - mae: 140.7229 - val_loss: 37890.7422 - val_mse: 37890.7383 - val_mae: 138.8276\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 35075.2188 - mse: 35075.2188 - mae: 133.1456 - val_loss: 33139.0703 - val_mse: 33139.0703 - val_mae: 125.1124\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 30151.4102 - mse: 30151.4082 - mae: 118.2630 - val_loss: 28561.2090 - val_mse: 28561.2090 - val_mae: 113.0400\n","Epoch 6/10\n","710/710 [==============================] - 2s 2ms/step - loss: 26193.8633 - mse: 26193.8652 - mae: 108.0370 - val_loss: 25154.5586 - val_mse: 25154.5586 - val_mae: 105.5007\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23184.7539 - mse: 23184.7539 - mae: 100.9335 - val_loss: 22439.8203 - val_mse: 22439.8203 - val_mae: 99.7254\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20716.5117 - mse: 20716.5117 - mae: 95.3294 - val_loss: 20153.2852 - val_mse: 20153.2852 - val_mae: 93.8931\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 18599.4824 - mse: 18599.4824 - mae: 90.0189 - val_loss: 18184.7207 - val_mse: 18184.7188 - val_mae: 89.9732\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16847.7285 - mse: 16847.7285 - mae: 85.6048 - val_loss: 16577.2969 - val_mse: 16577.2969 - val_mae: 86.5147\n","163/163 [==============================] - 0s 962us/step\n","Epoch 10/10\n","12/12 loss: 16847.7285 mean_squared_error: 16847.7285 mean_absolute_error: 85.6048 val_loss: 16577.2969 val_mean_squared_error: 16577.2969 val_mean_absolute_error: 86.5147\n","Model: \"sequential_377\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1204 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1205 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 48211.5781 - mse: 48211.5781 - mae: 153.4112 - val_loss: 30478.1758 - val_mse: 30478.1758 - val_mae: 129.7031\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 28172.7793 - mse: 28172.7793 - mae: 129.0418 - val_loss: 26608.5312 - val_mse: 26608.5312 - val_mae: 125.3474\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23695.6777 - mse: 23695.6777 - mae: 116.9856 - val_loss: 21614.3984 - val_mse: 21614.3984 - val_mae: 110.8655\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19692.8730 - mse: 19692.8730 - mae: 104.5413 - val_loss: 18347.1504 - val_mse: 18347.1504 - val_mae: 100.7972\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 17092.2520 - mse: 17092.2520 - mae: 95.4033 - val_loss: 16353.0918 - val_mse: 16353.0918 - val_mae: 93.9145\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15591.0156 - mse: 15591.0156 - mae: 89.4832 - val_loss: 15225.1270 - val_mse: 15225.1270 - val_mae: 89.5823\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14725.9443 - mse: 14725.9443 - mae: 86.1164 - val_loss: 14515.8184 - val_mse: 14515.8184 - val_mae: 86.2689\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14166.4268 - mse: 14166.4268 - mae: 83.8821 - val_loss: 14014.4600 - val_mse: 14014.4600 - val_mae: 84.2901\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13770.6855 - mse: 13770.6855 - mae: 82.2802 - val_loss: 13665.6328 - val_mse: 13665.6328 - val_mae: 82.4732\n","Epoch 10/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13471.8711 - mse: 13471.8711 - mae: 81.0288 - val_loss: 13390.4062 - val_mse: 13390.4062 - val_mae: 82.2831\n","163/163 [==============================] - 0s 952us/step\n","Epoch 10/10\n","12/12 loss: 13471.8711 mean_squared_error: 13471.8711 mean_absolute_error: 81.0288 val_loss: 13390.4062 val_mean_squared_error: 13390.4062 val_mean_absolute_error: 82.2831\n","Model: \"sequential_378\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1206 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1207 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 51727.7188 - mse: 51727.7188 - mae: 158.1357 - val_loss: 32527.0176 - val_mse: 32527.0176 - val_mae: 128.9096\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 28051.0996 - mse: 28051.0996 - mae: 126.3596 - val_loss: 25772.1094 - val_mse: 25772.1094 - val_mae: 123.0432\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23261.8184 - mse: 23261.8184 - mae: 115.4762 - val_loss: 21380.0293 - val_mse: 21380.0293 - val_mae: 111.4289\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19597.5352 - mse: 19597.5352 - mae: 103.7211 - val_loss: 18439.6289 - val_mse: 18439.6289 - val_mae: 100.5290\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17321.9609 - mse: 17321.9609 - mae: 95.9925 - val_loss: 16793.6035 - val_mse: 16793.6035 - val_mae: 92.9033\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15993.8945 - mse: 15993.8945 - mae: 90.9195 - val_loss: 15643.1787 - val_mse: 15643.1787 - val_mae: 91.4083\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15116.7812 - mse: 15116.7812 - mae: 87.6271 - val_loss: 14919.1426 - val_mse: 14919.1426 - val_mae: 89.1509\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14502.5664 - mse: 14502.5664 - mae: 85.3834 - val_loss: 14440.6641 - val_mse: 14440.6641 - val_mae: 84.2427\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14071.6289 - mse: 14071.6289 - mae: 83.4919 - val_loss: 13985.5801 - val_mse: 13985.5801 - val_mae: 83.2575\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13734.2715 - mse: 13734.2715 - mae: 82.1742 - val_loss: 13703.0977 - val_mse: 13703.0977 - val_mae: 81.5304\n","163/163 [==============================] - 0s 878us/step\n","Epoch 10/10\n","12/12 loss: 13734.2715 mean_squared_error: 13734.2715 mean_absolute_error: 82.1742 val_loss: 13703.0977 val_mean_squared_error: 13703.0977 val_mean_absolute_error: 81.5304\n","Model: \"sequential_379\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1208 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1209 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 45278.9727 - mse: 45278.9727 - mae: 149.8408 - val_loss: 28640.0117 - val_mse: 28640.0117 - val_mae: 129.3564\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 26848.7656 - mse: 26848.7656 - mae: 127.2274 - val_loss: 25655.6348 - val_mse: 25655.6348 - val_mae: 123.8832\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 24080.1250 - mse: 24080.1230 - mae: 120.1051 - val_loss: 22896.2891 - val_mse: 22896.2891 - val_mae: 117.7264\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 21459.2812 - mse: 21459.2812 - mae: 112.3608 - val_loss: 20411.7949 - val_mse: 20411.7949 - val_mae: 108.8613\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19192.9844 - mse: 19192.9844 - mae: 104.1944 - val_loss: 18445.9492 - val_mse: 18445.9492 - val_mae: 100.6103\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17493.8203 - mse: 17493.8203 - mae: 97.5059 - val_loss: 17007.2090 - val_mse: 17007.2090 - val_mae: 95.2589\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16331.8340 - mse: 16331.8340 - mae: 92.5056 - val_loss: 16010.1475 - val_mse: 16010.1475 - val_mae: 93.2416\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15515.1553 - mse: 15515.1553 - mae: 89.4394 - val_loss: 15352.1250 - val_mse: 15352.1250 - val_mae: 88.5838\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14936.4023 - mse: 14936.4023 - mae: 86.7085 - val_loss: 14803.8154 - val_mse: 14803.8154 - val_mae: 86.9767\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14497.6621 - mse: 14497.6621 - mae: 84.8809 - val_loss: 14386.0518 - val_mse: 14386.0518 - val_mae: 85.5430\n","163/163 [==============================] - 0s 877us/step\n","Epoch 10/10\n","12/12 loss: 14497.6621 mean_squared_error: 14497.6621 mean_absolute_error: 84.8809 val_loss: 14386.0518 val_mean_squared_error: 14386.0518 val_mean_absolute_error: 85.5430\n","Model: \"sequential_380\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1210 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1211 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_450 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1212 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 33108.2773 - mse: 33108.2773 - mae: 132.4456 - val_loss: 19525.3672 - val_mse: 19525.3672 - val_mae: 105.1676\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19220.1582 - mse: 19220.1582 - mae: 97.6900 - val_loss: 15326.2275 - val_mse: 15326.2275 - val_mae: 82.6101\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16906.3652 - mse: 16906.3652 - mae: 88.7739 - val_loss: 13704.4492 - val_mse: 13704.4492 - val_mae: 79.3156\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16132.6562 - mse: 16132.6562 - mae: 86.6241 - val_loss: 13334.4883 - val_mse: 13334.4883 - val_mae: 76.7433\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15807.4756 - mse: 15807.4756 - mae: 85.9225 - val_loss: 13057.3193 - val_mse: 13057.3193 - val_mae: 76.7146\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15503.1641 - mse: 15503.1641 - mae: 84.7296 - val_loss: 12844.4541 - val_mse: 12844.4541 - val_mae: 75.2439\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14903.3525 - mse: 14903.3525 - mae: 83.0682 - val_loss: 12368.1768 - val_mse: 12368.1768 - val_mae: 75.8665\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15155.0156 - mse: 15155.0156 - mae: 82.8550 - val_loss: 12167.8926 - val_mse: 12167.8926 - val_mae: 77.0224\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14963.6631 - mse: 14963.6650 - mae: 82.0947 - val_loss: 11948.7314 - val_mse: 11948.7314 - val_mae: 73.9802\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14852.1729 - mse: 14852.1729 - mae: 81.7603 - val_loss: 11805.4697 - val_mse: 11805.4697 - val_mae: 71.8483\n","163/163 [==============================] - 0s 951us/step\n","Epoch 10/10\n","12/12 loss: 14852.1729 mean_squared_error: 14852.1729 mean_absolute_error: 81.7603 val_loss: 11805.4697 val_mean_squared_error: 11805.4697 val_mean_absolute_error: 71.8483\n","Model: \"sequential_381\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1213 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1214 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_451 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1215 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 59432.9062 - mse: 59432.9062 - mae: 169.6897 - val_loss: 54140.5977 - val_mse: 54140.5977 - val_mae: 159.8194\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 49115.2539 - mse: 49115.2539 - mae: 152.8674 - val_loss: 45824.6836 - val_mse: 45824.6836 - val_mae: 147.8332\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 41779.4258 - mse: 41779.4258 - mae: 138.8013 - val_loss: 38441.1914 - val_mse: 38441.1914 - val_mae: 127.2807\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 34992.2188 - mse: 34992.2188 - mae: 119.8955 - val_loss: 32588.1484 - val_mse: 32588.1484 - val_mae: 113.4022\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 29762.0938 - mse: 29762.0938 - mae: 107.2036 - val_loss: 27487.8887 - val_mse: 27487.8887 - val_mae: 99.9033\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 25465.7676 - mse: 25465.7676 - mae: 97.9084 - val_loss: 23737.4238 - val_mse: 23737.4238 - val_mae: 90.1229\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 22534.8457 - mse: 22534.8457 - mae: 92.1560 - val_loss: 20971.8320 - val_mse: 20971.8320 - val_mae: 86.4064\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20128.5449 - mse: 20128.5449 - mae: 87.7275 - val_loss: 18689.4004 - val_mse: 18689.4004 - val_mae: 81.6409\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18451.6348 - mse: 18451.6348 - mae: 85.7917 - val_loss: 16938.3965 - val_mse: 16938.3965 - val_mae: 77.8821\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17468.0352 - mse: 17468.0352 - mae: 84.1956 - val_loss: 15705.4775 - val_mse: 15705.4775 - val_mae: 75.8468\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 17468.0352 mean_squared_error: 17468.0352 mean_absolute_error: 84.1956 val_loss: 15705.4775 val_mean_squared_error: 15705.4775 val_mean_absolute_error: 75.8468\n","Model: \"sequential_382\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1216 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1217 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_452 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1218 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 32135.8281 - mse: 32135.8281 - mae: 130.4202 - val_loss: 18398.9160 - val_mse: 18398.9160 - val_mae: 100.3789\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18346.7832 - mse: 18346.7832 - mae: 95.0353 - val_loss: 14122.4551 - val_mse: 14122.4551 - val_mae: 85.5440\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15782.5186 - mse: 15782.5186 - mae: 87.2608 - val_loss: 12855.1182 - val_mse: 12855.1182 - val_mae: 80.5185\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15295.0967 - mse: 15295.0967 - mae: 83.5900 - val_loss: 12537.5000 - val_mse: 12537.5000 - val_mae: 73.3749\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14553.4756 - mse: 14553.4756 - mae: 80.5517 - val_loss: 11822.2803 - val_mse: 11822.2803 - val_mae: 70.3893\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 13816.0059 - mse: 13816.0059 - mae: 77.7882 - val_loss: 11128.2451 - val_mse: 11128.2451 - val_mae: 68.0325\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12867.1631 - mse: 12867.1631 - mae: 75.4154 - val_loss: 10979.4697 - val_mse: 10979.4688 - val_mae: 66.8253\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12692.1631 - mse: 12692.1631 - mae: 74.7093 - val_loss: 10845.4863 - val_mse: 10845.4863 - val_mae: 66.4964\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12414.2002 - mse: 12414.2002 - mae: 73.9829 - val_loss: 10242.7910 - val_mse: 10242.7910 - val_mae: 66.7008\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 12411.4629 - mse: 12411.4629 - mae: 74.0331 - val_loss: 10208.2676 - val_mse: 10208.2676 - val_mae: 67.0975\n","163/163 [==============================] - 0s 987us/step\n","Epoch 10/10\n","12/12 loss: 12411.4629 mean_squared_error: 12411.4629 mean_absolute_error: 74.0331 val_loss: 10208.2676 val_mean_squared_error: 10208.2676 val_mean_absolute_error: 67.0975\n","Model: \"sequential_383\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1219 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1220 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_453 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1221 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 32168.6406 - mse: 32168.6406 - mae: 131.4891 - val_loss: 19324.3613 - val_mse: 19324.3613 - val_mae: 103.6191\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18775.2676 - mse: 18775.2676 - mae: 97.0844 - val_loss: 14836.6348 - val_mse: 14836.6348 - val_mae: 82.5843\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16573.6191 - mse: 16573.6191 - mae: 87.5398 - val_loss: 13727.9922 - val_mse: 13727.9922 - val_mae: 78.8159\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15978.4531 - mse: 15978.4531 - mae: 85.8268 - val_loss: 13079.7432 - val_mse: 13079.7432 - val_mae: 80.1777\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15901.2549 - mse: 15901.2549 - mae: 85.7320 - val_loss: 12899.7236 - val_mse: 12899.7236 - val_mae: 79.8130\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15601.3057 - mse: 15601.3037 - mae: 84.9247 - val_loss: 12978.8369 - val_mse: 12978.8369 - val_mae: 76.1910\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15499.8428 - mse: 15499.8428 - mae: 84.2469 - val_loss: 12659.2969 - val_mse: 12659.2969 - val_mae: 75.8384\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15096.4746 - mse: 15096.4746 - mae: 82.9695 - val_loss: 12725.6064 - val_mse: 12725.6064 - val_mae: 74.0113\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15105.8604 - mse: 15105.8604 - mae: 82.9886 - val_loss: 12405.1660 - val_mse: 12405.1660 - val_mae: 73.6969\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14721.3379 - mse: 14721.3379 - mae: 82.0028 - val_loss: 12299.5352 - val_mse: 12299.5352 - val_mae: 73.4675\n","163/163 [==============================] - 0s 963us/step\n","Epoch 10/10\n","12/12 loss: 14721.3379 mean_squared_error: 14721.3379 mean_absolute_error: 82.0028 val_loss: 12299.5352 val_mean_squared_error: 12299.5352 val_mean_absolute_error: 73.4675\n","Model: \"sequential_384\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1222 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1223 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_454 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1224 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 28616.5156 - mse: 28616.5156 - mae: 124.0428 - val_loss: 17487.8203 - val_mse: 17487.8203 - val_mae: 97.9151\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16640.0938 - mse: 16640.0938 - mae: 91.4633 - val_loss: 14065.5811 - val_mse: 14065.5811 - val_mae: 83.7722\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15027.7363 - mse: 15027.7363 - mae: 85.1946 - val_loss: 13418.6816 - val_mse: 13418.6816 - val_mae: 80.4777\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14518.4697 - mse: 14518.4697 - mae: 83.8836 - val_loss: 13079.3105 - val_mse: 13079.3105 - val_mae: 79.7342\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14616.3984 - mse: 14616.3994 - mae: 83.5293 - val_loss: 13011.7314 - val_mse: 13011.7314 - val_mae: 80.6880\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14723.6406 - mse: 14723.6406 - mae: 84.0937 - val_loss: 13016.7148 - val_mse: 13016.7148 - val_mae: 78.6094\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14618.6689 - mse: 14618.6689 - mae: 83.9605 - val_loss: 13089.6465 - val_mse: 13089.6465 - val_mae: 77.6944\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14549.1309 - mse: 14549.1309 - mae: 83.2680 - val_loss: 13016.7705 - val_mse: 13016.7705 - val_mae: 82.8506\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14520.0508 - mse: 14520.0508 - mae: 83.0747 - val_loss: 13016.6494 - val_mse: 13016.6494 - val_mae: 77.8479\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 14667.6680 - mse: 14667.6680 - mae: 83.3490 - val_loss: 12945.2412 - val_mse: 12945.2412 - val_mae: 81.5623\n","163/163 [==============================] - 0s 950us/step\n","Epoch 10/10\n","12/12 loss: 14667.6680 mean_squared_error: 14667.6680 mean_absolute_error: 83.3490 val_loss: 12945.2412 val_mean_squared_error: 12945.2412 val_mean_absolute_error: 81.5623\n","Model: \"sequential_385\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1225 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1226 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_455 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1227 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_456 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1228 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 3ms/step - loss: 26206.8594 - mse: 26206.8594 - mae: 113.5553 - val_loss: 15053.1807 - val_mse: 15053.1807 - val_mae: 78.7732\n","Epoch 2/10\n","710/710 [==============================] - 2s 3ms/step - loss: 17520.4688 - mse: 17520.4688 - mae: 89.9709 - val_loss: 13199.3936 - val_mse: 13199.3936 - val_mae: 77.4878\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 16740.6250 - mse: 16740.6250 - mae: 86.7861 - val_loss: 13428.7705 - val_mse: 13428.7705 - val_mae: 72.8185\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 16058.9639 - mse: 16058.9639 - mae: 85.2060 - val_loss: 12130.1201 - val_mse: 12130.1201 - val_mae: 71.1317\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15424.0225 - mse: 15424.0225 - mae: 82.3431 - val_loss: 11668.3379 - val_mse: 11668.3379 - val_mae: 73.0136\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 14871.6309 - mse: 14871.6309 - mae: 80.6358 - val_loss: 10885.2490 - val_mse: 10885.2490 - val_mae: 69.3348\n","Epoch 7/10\n","710/710 [==============================] - 2s 2ms/step - loss: 14709.6758 - mse: 14709.6758 - mae: 78.9142 - val_loss: 10440.3760 - val_mse: 10440.3760 - val_mae: 68.1537\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13930.4736 - mse: 13930.4736 - mae: 76.9250 - val_loss: 10251.7969 - val_mse: 10251.7969 - val_mae: 64.7763\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13902.4170 - mse: 13902.4170 - mae: 76.8599 - val_loss: 9896.8535 - val_mse: 9896.8535 - val_mae: 63.3857\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13241.0225 - mse: 13241.0225 - mae: 74.8692 - val_loss: 9760.2383 - val_mse: 9760.2383 - val_mae: 63.0837\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 13241.0225 mean_squared_error: 13241.0225 mean_absolute_error: 74.8692 val_loss: 9760.2383 val_mean_squared_error: 9760.2383 val_mean_absolute_error: 63.0837\n","Model: \"sequential_386\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1229 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1230 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_457 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1231 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_458 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1232 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 3ms/step - loss: 59544.7852 - mse: 59544.7812 - mae: 169.6833 - val_loss: 54345.8359 - val_mse: 54345.8359 - val_mae: 160.1503\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 49334.0352 - mse: 49334.0352 - mae: 153.3461 - val_loss: 46051.0391 - val_mse: 46051.0391 - val_mae: 148.1435\n","Epoch 3/10\n","710/710 [==============================] - 3s 4ms/step - loss: 42624.1875 - mse: 42624.1875 - mae: 144.5076 - val_loss: 40651.0273 - val_mse: 40651.0273 - val_mae: 141.9298\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 38618.0938 - mse: 38618.0938 - mae: 140.9048 - val_loss: 37370.7148 - val_mse: 37370.7148 - val_mae: 139.4896\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 32400.6328 - mse: 32400.6328 - mae: 117.5652 - val_loss: 30256.2031 - val_mse: 30256.2031 - val_mae: 111.6753\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 27266.4082 - mse: 27266.4082 - mae: 102.7470 - val_loss: 24961.2324 - val_mse: 24961.2324 - val_mae: 93.1027\n","Epoch 7/10\n","710/710 [==============================] - 2s 2ms/step - loss: 23627.1367 - mse: 23627.1367 - mae: 95.3888 - val_loss: 21822.6191 - val_mse: 21822.6191 - val_mae: 88.1894\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 21294.7871 - mse: 21294.7871 - mae: 90.9121 - val_loss: 19448.8633 - val_mse: 19448.8633 - val_mae: 83.8218\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 19269.3008 - mse: 19269.3008 - mae: 87.7600 - val_loss: 17444.9707 - val_mse: 17444.9707 - val_mae: 77.3897\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 18275.0039 - mse: 18275.0039 - mae: 87.0819 - val_loss: 16355.9668 - val_mse: 16355.9668 - val_mae: 77.0900\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 18275.0039 mean_squared_error: 18275.0039 mean_absolute_error: 87.0819 val_loss: 16355.9668 val_mean_squared_error: 16355.9668 val_mean_absolute_error: 77.0900\n","Model: \"sequential_387\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1233 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1234 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_459 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1235 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_460 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1236 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 3ms/step - loss: 23804.4727 - mse: 23804.4727 - mae: 108.4890 - val_loss: 13714.6299 - val_mse: 13714.6299 - val_mae: 77.0354\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 16317.6084 - mse: 16317.6084 - mae: 86.6054 - val_loss: 13878.5557 - val_mse: 13878.5557 - val_mae: 72.8862\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15457.2168 - mse: 15457.2168 - mae: 83.0572 - val_loss: 13793.5127 - val_mse: 13793.5127 - val_mae: 70.3279\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15161.4746 - mse: 15161.4746 - mae: 81.1688 - val_loss: 11314.4717 - val_mse: 11314.4717 - val_mae: 70.2282\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 14325.9004 - mse: 14325.9004 - mae: 78.5535 - val_loss: 10442.7676 - val_mse: 10442.7676 - val_mae: 71.1422\n","Epoch 6/10\n","710/710 [==============================] - 3s 4ms/step - loss: 13329.8340 - mse: 13329.8340 - mae: 76.4524 - val_loss: 10161.6182 - val_mse: 10161.6182 - val_mae: 66.9603\n","Epoch 7/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13454.7764 - mse: 13454.7764 - mae: 76.4407 - val_loss: 10512.0020 - val_mse: 10512.0020 - val_mae: 64.8519\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13145.8701 - mse: 13145.8701 - mae: 75.9180 - val_loss: 10530.1992 - val_mse: 10530.1992 - val_mae: 64.3671\n","Epoch 9/10\n","710/710 [==============================] - 3s 4ms/step - loss: 12907.8330 - mse: 12907.8330 - mae: 75.2441 - val_loss: 10207.8916 - val_mse: 10207.8916 - val_mae: 66.1184\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 12715.7549 - mse: 12715.7549 - mae: 74.5078 - val_loss: 9947.9766 - val_mse: 9947.9766 - val_mae: 64.0791\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 12715.7549 mean_squared_error: 12715.7549 mean_absolute_error: 74.5078 val_loss: 9947.9766 val_mean_squared_error: 9947.9766 val_mean_absolute_error: 64.0791\n","Model: \"sequential_388\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1237 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1238 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_461 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1239 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_462 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1240 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 3ms/step - loss: 25666.8691 - mse: 25666.8672 - mae: 111.3062 - val_loss: 13616.7051 - val_mse: 13616.7051 - val_mae: 82.8091\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 16970.0781 - mse: 16970.0781 - mae: 88.5629 - val_loss: 12740.4248 - val_mse: 12740.4248 - val_mae: 75.4091\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 16128.1826 - mse: 16128.1826 - mae: 85.2576 - val_loss: 12061.9453 - val_mse: 12061.9453 - val_mae: 72.1424\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15549.6084 - mse: 15549.6084 - mae: 82.7047 - val_loss: 11547.1875 - val_mse: 11547.1875 - val_mae: 70.6753\n","Epoch 5/10\n","710/710 [==============================] - 2s 2ms/step - loss: 14747.0820 - mse: 14747.0820 - mae: 80.3342 - val_loss: 10805.7432 - val_mse: 10805.7432 - val_mae: 70.9205\n","Epoch 6/10\n","710/710 [==============================] - 3s 4ms/step - loss: 14026.3213 - mse: 14026.3213 - mae: 77.8090 - val_loss: 11250.7832 - val_mse: 11250.7832 - val_mae: 67.4322\n","Epoch 7/10\n","710/710 [==============================] - 2s 3ms/step - loss: 14029.4414 - mse: 14029.4414 - mae: 77.4403 - val_loss: 10486.7227 - val_mse: 10486.7227 - val_mae: 64.3136\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13751.1250 - mse: 13751.1250 - mae: 76.2955 - val_loss: 10159.5850 - val_mse: 10159.5850 - val_mae: 64.2200\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 13506.5928 - mse: 13506.5928 - mae: 75.5443 - val_loss: 10162.8184 - val_mse: 10162.8184 - val_mae: 64.2243\n","Epoch 10/10\n","710/710 [==============================] - 2s 2ms/step - loss: 13485.5742 - mse: 13485.5742 - mae: 75.0496 - val_loss: 9514.3564 - val_mse: 9514.3564 - val_mae: 66.5705\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","12/12 loss: 13485.5742 mean_squared_error: 13485.5742 mean_absolute_error: 75.0496 val_loss: 9514.3564 val_mean_squared_error: 9514.3564 val_mean_absolute_error: 66.5705\n","Model: \"sequential_389\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1241 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1242 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_463 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1243 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_464 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1244 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 5s 3ms/step - loss: 22022.1406 - mse: 22022.1406 - mae: 104.6500 - val_loss: 13948.3467 - val_mse: 13948.3467 - val_mae: 79.8252\n","Epoch 2/10\n","710/710 [==============================] - 2s 2ms/step - loss: 15833.7725 - mse: 15833.7725 - mae: 86.8457 - val_loss: 13322.2900 - val_mse: 13322.2900 - val_mae: 76.1368\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15572.0391 - mse: 15572.0391 - mae: 85.8597 - val_loss: 13429.6064 - val_mse: 13429.6064 - val_mae: 78.1050\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15524.4541 - mse: 15524.4541 - mae: 85.9049 - val_loss: 13022.0273 - val_mse: 13022.0273 - val_mae: 77.7398\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15601.5156 - mse: 15601.5156 - mae: 86.4497 - val_loss: 13623.1504 - val_mse: 13623.1504 - val_mae: 77.1702\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15604.6865 - mse: 15604.6865 - mae: 85.9948 - val_loss: 13307.1318 - val_mse: 13307.1318 - val_mae: 77.0075\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15611.8145 - mse: 15611.8145 - mae: 85.9011 - val_loss: 13385.5762 - val_mse: 13385.5762 - val_mae: 78.6050\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15567.5918 - mse: 15567.5918 - mae: 85.9085 - val_loss: 13061.5625 - val_mse: 13061.5625 - val_mae: 78.5836\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15650.1699 - mse: 15650.1689 - mae: 85.6590 - val_loss: 13072.8604 - val_mse: 13072.8604 - val_mae: 80.3646\n","Epoch 9: early stopping\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 15650.1699 mean_squared_error: 15650.1689 mean_absolute_error: 85.6590 val_loss: 13072.8604 val_mean_squared_error: 13072.8604 val_mean_absolute_error: 80.3646\n","Model: \"sequential_390\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1245 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1246 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_465 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1247 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 37078.5742 - mse: 37078.5742 - mae: 139.9236 - val_loss: 22659.4121 - val_mse: 22659.4121 - val_mae: 116.1095\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 22344.5273 - mse: 22344.5273 - mae: 107.9165 - val_loss: 16515.6016 - val_mse: 16515.6016 - val_mae: 91.7641\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19151.0527 - mse: 19151.0527 - mae: 96.2015 - val_loss: 14550.7500 - val_mse: 14550.7500 - val_mae: 82.1578\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18071.5996 - mse: 18071.5996 - mae: 91.6679 - val_loss: 13698.2988 - val_mse: 13698.2988 - val_mae: 80.9436\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17654.7656 - mse: 17654.7656 - mae: 90.6880 - val_loss: 13787.7559 - val_mse: 13787.7559 - val_mae: 77.2774\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17360.3457 - mse: 17360.3438 - mae: 89.6042 - val_loss: 13690.8975 - val_mse: 13690.8975 - val_mae: 76.0327\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17351.9102 - mse: 17351.9102 - mae: 89.3221 - val_loss: 12943.2920 - val_mse: 12943.2920 - val_mae: 78.3326\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17033.9785 - mse: 17033.9785 - mae: 88.2916 - val_loss: 13154.3936 - val_mse: 13154.3936 - val_mae: 75.1102\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16861.6895 - mse: 16861.6875 - mae: 87.8084 - val_loss: 12737.9541 - val_mse: 12737.9541 - val_mae: 75.8004\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16991.3789 - mse: 16991.3789 - mae: 88.0643 - val_loss: 13088.0957 - val_mse: 13088.0957 - val_mae: 73.0452\n","163/163 [==============================] - 0s 969us/step\n","Epoch 10/10\n","12/12 loss: 16991.3789 mean_squared_error: 16991.3789 mean_absolute_error: 88.0643 val_loss: 13088.0957 val_mean_squared_error: 13088.0957 val_mean_absolute_error: 73.0452\n","Model: \"sequential_391\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1248 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1249 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_466 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1250 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 63302.0117 - mse: 63302.0117 - mae: 176.7751 - val_loss: 60396.1172 - val_mse: 60396.1172 - val_mae: 170.2165\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 56668.4844 - mse: 56668.4844 - mae: 164.4819 - val_loss: 54619.1172 - val_mse: 54619.1172 - val_mae: 160.5750\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 51530.0117 - mse: 51530.0117 - mae: 156.5461 - val_loss: 49859.9062 - val_mse: 49859.9062 - val_mae: 153.3672\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 47323.6094 - mse: 47323.6094 - mae: 150.4995 - val_loss: 45973.9453 - val_mse: 45973.9453 - val_mae: 148.0155\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 43315.6016 - mse: 43315.6016 - mae: 140.1712 - val_loss: 41496.8281 - val_mse: 41496.8281 - val_mae: 133.4245\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 39257.9727 - mse: 39257.9727 - mae: 129.0457 - val_loss: 37757.8945 - val_mse: 37757.8945 - val_mae: 124.2019\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 36106.3398 - mse: 36106.3398 - mae: 122.3051 - val_loss: 34627.9219 - val_mse: 34627.9219 - val_mae: 117.1181\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 33014.6445 - mse: 33014.6445 - mae: 115.7750 - val_loss: 31496.9766 - val_mse: 31496.9766 - val_mae: 107.8054\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 30325.2188 - mse: 30325.2188 - mae: 108.3837 - val_loss: 28833.0840 - val_mse: 28833.0840 - val_mae: 100.7158\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 27935.3496 - mse: 27935.3496 - mae: 103.2532 - val_loss: 26541.2578 - val_mse: 26541.2578 - val_mae: 95.6625\n","163/163 [==============================] - 0s 893us/step\n","Epoch 10/10\n","12/12 loss: 27935.3496 mean_squared_error: 27935.3496 mean_absolute_error: 103.2532 val_loss: 26541.2578 val_mean_squared_error: 26541.2578 val_mean_absolute_error: 95.6625\n","Model: \"sequential_392\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1251 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1252 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_467 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1253 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 38761.1758 - mse: 38761.1758 - mae: 142.3593 - val_loss: 24671.4160 - val_mse: 24671.4160 - val_mae: 114.0844\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 24067.3047 - mse: 24067.3047 - mae: 110.0453 - val_loss: 17323.8672 - val_mse: 17323.8672 - val_mae: 89.2443\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20758.2344 - mse: 20758.2344 - mae: 99.2118 - val_loss: 14807.2197 - val_mse: 14807.2197 - val_mae: 82.1925\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18788.8516 - mse: 18788.8516 - mae: 92.9492 - val_loss: 13610.1943 - val_mse: 13610.1943 - val_mae: 78.2563\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18368.4980 - mse: 18368.4980 - mae: 91.0201 - val_loss: 12946.9307 - val_mse: 12946.9316 - val_mae: 75.6465\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17374.0957 - mse: 17374.0957 - mae: 87.2643 - val_loss: 12320.3379 - val_mse: 12320.3379 - val_mae: 72.5156\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16070.8770 - mse: 16070.8770 - mae: 83.8758 - val_loss: 11713.8418 - val_mse: 11713.8418 - val_mae: 70.6141\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15920.5410 - mse: 15920.5410 - mae: 83.1378 - val_loss: 12404.0557 - val_mse: 12404.0557 - val_mae: 68.8814\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15866.7969 - mse: 15866.7969 - mae: 82.9272 - val_loss: 11414.1016 - val_mse: 11414.1016 - val_mae: 69.0195\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15275.6436 - mse: 15275.6436 - mae: 81.3377 - val_loss: 11010.7803 - val_mse: 11010.7803 - val_mae: 69.8358\n","163/163 [==============================] - 0s 909us/step\n","Epoch 10/10\n","12/12 loss: 15275.6436 mean_squared_error: 15275.6436 mean_absolute_error: 81.3377 val_loss: 11010.7803 val_mean_squared_error: 11010.7803 val_mean_absolute_error: 69.8358\n","Model: \"sequential_393\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1254 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1255 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_468 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1256 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 39643.8438 - mse: 39643.8438 - mae: 143.7362 - val_loss: 24368.3594 - val_mse: 24368.3594 - val_mae: 116.3686\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 23883.2480 - mse: 23883.2480 - mae: 112.7746 - val_loss: 18094.7500 - val_mse: 18094.7500 - val_mae: 92.5615\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20368.8184 - mse: 20368.8184 - mae: 99.4540 - val_loss: 15672.5186 - val_mse: 15672.5186 - val_mae: 83.7972\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19001.3340 - mse: 19001.3340 - mae: 94.3220 - val_loss: 14533.5068 - val_mse: 14533.5068 - val_mae: 80.2641\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19149.9824 - mse: 19149.9824 - mae: 93.7439 - val_loss: 14061.7578 - val_mse: 14061.7578 - val_mae: 78.3088\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18549.7227 - mse: 18549.7227 - mae: 92.6730 - val_loss: 13861.4053 - val_mse: 13861.4053 - val_mae: 76.6101\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18864.0215 - mse: 18864.0215 - mae: 92.2889 - val_loss: 13336.4043 - val_mse: 13336.4043 - val_mae: 77.8549\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18774.1426 - mse: 18774.1426 - mae: 92.4279 - val_loss: 13468.7119 - val_mse: 13468.7119 - val_mae: 76.1406\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 18094.0215 - mse: 18094.0215 - mae: 90.9446 - val_loss: 13216.0605 - val_mse: 13216.0605 - val_mae: 76.0852\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17892.4805 - mse: 17892.4805 - mae: 90.3143 - val_loss: 13182.5996 - val_mse: 13182.5996 - val_mae: 75.0244\n","163/163 [==============================] - 0s 930us/step\n","Epoch 10/10\n","12/12 loss: 17892.4805 mean_squared_error: 17892.4805 mean_absolute_error: 90.3143 val_loss: 13182.5996 val_mean_squared_error: 13182.5996 val_mean_absolute_error: 75.0244\n","Model: \"sequential_394\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1257 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1258 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_469 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1259 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 2s 2ms/step - loss: 34713.9453 - mse: 34713.9453 - mae: 136.3372 - val_loss: 21906.5723 - val_mse: 21906.5723 - val_mae: 111.8208\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20274.6270 - mse: 20274.6270 - mae: 103.3687 - val_loss: 15885.3164 - val_mse: 15885.3174 - val_mae: 92.2982\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17371.3477 - mse: 17371.3477 - mae: 92.2156 - val_loss: 14533.3398 - val_mse: 14533.3398 - val_mae: 82.7309\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16430.8711 - mse: 16430.8711 - mae: 89.1150 - val_loss: 13799.7666 - val_mse: 13799.7676 - val_mae: 80.3737\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16098.0967 - mse: 16098.0967 - mae: 87.9192 - val_loss: 13718.0283 - val_mse: 13718.0283 - val_mae: 78.5014\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15867.0186 - mse: 15867.0186 - mae: 86.9875 - val_loss: 13369.3936 - val_mse: 13369.3936 - val_mae: 78.3285\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15605.7812 - mse: 15605.7812 - mae: 86.0558 - val_loss: 14067.3691 - val_mse: 14067.3691 - val_mae: 76.6314\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15820.0879 - mse: 15820.0879 - mae: 86.6591 - val_loss: 13432.5977 - val_mse: 13432.5977 - val_mae: 77.1226\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15561.1641 - mse: 15561.1641 - mae: 86.0683 - val_loss: 13177.1270 - val_mse: 13177.1270 - val_mae: 77.7148\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15444.5547 - mse: 15444.5547 - mae: 86.0230 - val_loss: 12969.0166 - val_mse: 12969.0166 - val_mae: 79.9000\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 15444.5547 mean_squared_error: 15444.5547 mean_absolute_error: 86.0230 val_loss: 12969.0166 val_mean_squared_error: 12969.0166 val_mean_absolute_error: 79.9000\n","Model: \"sequential_395\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1260 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1261 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_470 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1262 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_471 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1263 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 32337.3613 - mse: 32337.3613 - mae: 127.5327 - val_loss: 16803.3438 - val_mse: 16803.3438 - val_mae: 86.0009\n","Epoch 2/10\n","710/710 [==============================] - 3s 4ms/step - loss: 20524.0449 - mse: 20524.0449 - mae: 97.3440 - val_loss: 15619.9453 - val_mse: 15619.9463 - val_mae: 77.9182\n","Epoch 3/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19168.6875 - mse: 19168.6875 - mae: 93.0986 - val_loss: 13900.3467 - val_mse: 13900.3447 - val_mae: 74.9587\n","Epoch 4/10\n","710/710 [==============================] - 1s 2ms/step - loss: 19157.6328 - mse: 19157.6328 - mae: 92.3954 - val_loss: 12988.5391 - val_mse: 12988.5391 - val_mae: 74.4128\n","Epoch 5/10\n","710/710 [==============================] - 2s 3ms/step - loss: 18232.8555 - mse: 18232.8555 - mae: 90.4713 - val_loss: 13072.3281 - val_mse: 13072.3281 - val_mae: 71.6679\n","Epoch 6/10\n","710/710 [==============================] - 2s 2ms/step - loss: 18154.1602 - mse: 18154.1602 - mae: 89.1959 - val_loss: 11851.2588 - val_mse: 11851.2588 - val_mae: 73.3234\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17379.2793 - mse: 17379.2793 - mae: 87.2264 - val_loss: 12081.6445 - val_mse: 12081.6445 - val_mae: 70.7691\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 16834.2500 - mse: 16834.2500 - mae: 85.5352 - val_loss: 11760.6113 - val_mse: 11760.6113 - val_mae: 68.1720\n","Epoch 9/10\n","710/710 [==============================] - 2s 3ms/step - loss: 17004.2988 - mse: 17004.2988 - mae: 84.9537 - val_loss: 11187.6221 - val_mse: 11187.6221 - val_mae: 67.6589\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16243.3574 - mse: 16243.3574 - mae: 82.8910 - val_loss: 10615.8242 - val_mse: 10615.8232 - val_mae: 66.5608\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 16243.3574 mean_squared_error: 16243.3574 mean_absolute_error: 82.8910 val_loss: 10615.8242 val_mean_squared_error: 10615.8232 val_mean_absolute_error: 66.5608\n","Model: \"sequential_396\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1264 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1265 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_472 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1266 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_473 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1267 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 3ms/step - loss: 64104.4688 - mse: 64104.4688 - mae: 178.2566 - val_loss: 61301.1523 - val_mse: 61301.1523 - val_mae: 171.8591\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 57543.8711 - mse: 57543.8711 - mae: 166.0550 - val_loss: 55413.3438 - val_mse: 55413.3438 - val_mae: 161.8454\n","Epoch 3/10\n","710/710 [==============================] - 2s 2ms/step - loss: 52209.0117 - mse: 52209.0117 - mae: 157.5502 - val_loss: 50533.5625 - val_mse: 50533.5625 - val_mae: 154.3475\n","Epoch 4/10\n","710/710 [==============================] - 2s 3ms/step - loss: 48136.3945 - mse: 48136.3945 - mae: 151.5211 - val_loss: 46585.9258 - val_mse: 46585.9258 - val_mae: 148.8449\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 44602.8125 - mse: 44602.8125 - mae: 147.1180 - val_loss: 43360.1914 - val_mse: 43360.1914 - val_mae: 144.8110\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 41834.3867 - mse: 41834.3906 - mae: 143.6124 - val_loss: 40763.9961 - val_mse: 40763.9961 - val_mae: 142.0400\n","Epoch 7/10\n","710/710 [==============================] - 3s 4ms/step - loss: 39620.2070 - mse: 39620.2070 - mae: 142.0247 - val_loss: 38757.9609 - val_mse: 38757.9609 - val_mae: 140.3053\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 38042.4141 - mse: 38042.4141 - mae: 140.7384 - val_loss: 37265.7539 - val_mse: 37265.7539 - val_mae: 139.4534\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 36707.9531 - mse: 36707.9531 - mae: 140.3669 - val_loss: 36168.4414 - val_mse: 36168.4414 - val_mae: 139.1976\n","Epoch 10/10\n","710/710 [==============================] - 2s 3ms/step - loss: 33609.1523 - mse: 33609.1523 - mae: 124.9150 - val_loss: 30375.7871 - val_mse: 30375.7871 - val_mae: 110.0432\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","12/12 loss: 33609.1523 mean_squared_error: 33609.1523 mean_absolute_error: 124.9150 val_loss: 30375.7871 val_mean_squared_error: 30375.7871 val_mean_absolute_error: 110.0432\n","Model: \"sequential_397\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1268 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1269 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_474 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1270 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_475 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1271 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 29251.2344 - mse: 29251.2344 - mae: 121.8682 - val_loss: 15726.5352 - val_mse: 15726.5352 - val_mae: 83.6125\n","Epoch 2/10\n","710/710 [==============================] - 3s 4ms/step - loss: 19328.9160 - mse: 19328.9160 - mae: 94.3768 - val_loss: 13393.7920 - val_mse: 13393.7920 - val_mae: 75.1820\n","Epoch 3/10\n","710/710 [==============================] - 2s 2ms/step - loss: 18053.5938 - mse: 18053.5938 - mae: 89.9320 - val_loss: 12256.1113 - val_mse: 12256.1113 - val_mae: 77.5807\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 17354.7578 - mse: 17354.7578 - mae: 87.0832 - val_loss: 13141.8506 - val_mse: 13141.8506 - val_mae: 69.5171\n","Epoch 5/10\n","710/710 [==============================] - 3s 4ms/step - loss: 16456.9512 - mse: 16456.9512 - mae: 84.6060 - val_loss: 12467.7793 - val_mse: 12467.7793 - val_mae: 67.2346\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15838.0664 - mse: 15838.0664 - mae: 82.9203 - val_loss: 10975.7227 - val_mse: 10975.7227 - val_mae: 68.6036\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15840.0693 - mse: 15840.0693 - mae: 82.1727 - val_loss: 11504.4990 - val_mse: 11504.4990 - val_mae: 66.7286\n","Epoch 8/10\n","710/710 [==============================] - 2s 3ms/step - loss: 15401.5342 - mse: 15401.5342 - mae: 81.7195 - val_loss: 11189.7461 - val_mse: 11189.7461 - val_mae: 66.1656\n","Epoch 9/10\n","710/710 [==============================] - 2s 2ms/step - loss: 15427.9209 - mse: 15427.9209 - mae: 81.1097 - val_loss: 10350.8213 - val_mse: 10350.8213 - val_mae: 65.1633\n","Epoch 10/10\n","710/710 [==============================] - 1s 2ms/step - loss: 15153.7861 - mse: 15153.7861 - mae: 80.5005 - val_loss: 11212.4902 - val_mse: 11212.4902 - val_mae: 71.7083\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 15153.7861 mean_squared_error: 15153.7861 mean_absolute_error: 80.5005 val_loss: 11212.4902 val_mean_squared_error: 11212.4902 val_mean_absolute_error: 71.7083\n","Model: \"sequential_398\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1272 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1273 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_476 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1274 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_477 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1275 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 4s 2ms/step - loss: 31191.3203 - mse: 31191.3203 - mae: 124.5251 - val_loss: 15502.0244 - val_mse: 15502.0244 - val_mae: 83.6628\n","Epoch 2/10\n","710/710 [==============================] - 1s 2ms/step - loss: 20453.3848 - mse: 20453.3848 - mae: 95.3739 - val_loss: 13908.3408 - val_mse: 13908.3408 - val_mae: 77.1649\n","Epoch 3/10\n","710/710 [==============================] - 2s 3ms/step - loss: 19429.0898 - mse: 19429.0898 - mae: 93.6015 - val_loss: 13662.5498 - val_mse: 13662.5498 - val_mae: 74.5508\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 18454.4727 - mse: 18454.4727 - mae: 90.8924 - val_loss: 12307.5605 - val_mse: 12307.5605 - val_mae: 73.4679\n","Epoch 5/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17971.6992 - mse: 17971.6992 - mae: 89.0573 - val_loss: 12078.9385 - val_mse: 12078.9385 - val_mae: 71.1975\n","Epoch 6/10\n","710/710 [==============================] - 2s 3ms/step - loss: 17482.4609 - mse: 17482.4609 - mae: 87.5628 - val_loss: 13245.0596 - val_mse: 13245.0596 - val_mae: 69.5452\n","Epoch 7/10\n","710/710 [==============================] - 2s 3ms/step - loss: 17249.1094 - mse: 17249.1094 - mae: 86.2179 - val_loss: 12630.9424 - val_mse: 12630.9424 - val_mae: 70.4284\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17327.8750 - mse: 17327.8750 - mae: 85.5934 - val_loss: 11199.6670 - val_mse: 11199.6660 - val_mae: 70.8543\n","Epoch 9/10\n","710/710 [==============================] - 1s 2ms/step - loss: 16766.9336 - mse: 16766.9336 - mae: 84.1442 - val_loss: 12466.8232 - val_mse: 12466.8232 - val_mae: 66.7602\n","Epoch 10/10\n","710/710 [==============================] - 2s 3ms/step - loss: 16021.4717 - mse: 16021.4717 - mae: 82.8481 - val_loss: 10488.7607 - val_mse: 10488.7607 - val_mae: 66.7306\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","12/12 loss: 16021.4717 mean_squared_error: 16021.4717 mean_absolute_error: 82.8481 val_loss: 10488.7607 val_mean_squared_error: 10488.7607 val_mean_absolute_error: 66.7306\n","Model: \"sequential_399\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1276 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1277 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_478 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1278 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_479 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1279 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","710/710 [==============================] - 3s 2ms/step - loss: 27444.0078 - mse: 27444.0078 - mae: 116.4728 - val_loss: 16057.9629 - val_mse: 16057.9619 - val_mae: 83.4623\n","Epoch 2/10\n","710/710 [==============================] - 3s 4ms/step - loss: 18076.2812 - mse: 18076.2812 - mae: 92.4189 - val_loss: 13282.7686 - val_mse: 13282.7686 - val_mae: 80.0130\n","Epoch 3/10\n","710/710 [==============================] - 2s 2ms/step - loss: 16867.6504 - mse: 16867.6504 - mae: 89.3377 - val_loss: 13072.0752 - val_mse: 13072.0752 - val_mae: 80.8131\n","Epoch 4/10\n","710/710 [==============================] - 2s 2ms/step - loss: 16993.9512 - mse: 16993.9512 - mae: 89.7050 - val_loss: 14019.7578 - val_mse: 14019.7578 - val_mae: 77.4921\n","Epoch 5/10\n","710/710 [==============================] - 3s 4ms/step - loss: 17104.0332 - mse: 17104.0332 - mae: 89.4971 - val_loss: 13560.2529 - val_mse: 13560.2529 - val_mae: 75.8525\n","Epoch 6/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17089.5781 - mse: 17089.5781 - mae: 88.9896 - val_loss: 13235.1533 - val_mse: 13235.1533 - val_mae: 86.0074\n","Epoch 7/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17547.5195 - mse: 17547.5195 - mae: 90.8033 - val_loss: 13124.6162 - val_mse: 13124.6162 - val_mae: 78.1479\n","Epoch 8/10\n","710/710 [==============================] - 1s 2ms/step - loss: 17122.0469 - mse: 17122.0469 - mae: 89.3480 - val_loss: 13405.0400 - val_mse: 13405.0400 - val_mae: 76.8926\n","Epoch 8: early stopping\n","163/163 [==============================] - 0s 931us/step\n","Epoch 10/10\n","12/12 loss: 17122.0469 mean_squared_error: 17122.0469 mean_absolute_error: 89.3480 val_loss: 13405.0400 val_mean_squared_error: 13405.0400 val_mean_absolute_error: 76.8926\n","Model: \"sequential_400\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1280 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1281 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 53185.7344 - mse: 53185.7344 - mae: 160.1097 - val_loss: 33223.7617 - val_mse: 33223.7617 - val_mae: 129.1116\n","163/163 [==============================] - 0s 874us/step\n","Epoch 1/1\n","16/16 loss: 53185.7344 mean_squared_error: 53185.7344 mean_absolute_error: 160.1097 val_loss: 33223.7617 val_mean_squared_error: 33223.7617 val_mean_absolute_error: 129.1116\n","Model: \"sequential_401\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1282 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1283 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 61175.4453 - mse: 61175.4453 - mae: 173.0673 - val_loss: 54615.4648 - val_mse: 54615.4648 - val_mae: 160.4550\n","163/163 [==============================] - 0s 913us/step\n","Epoch 1/1\n","16/16 loss: 61175.4453 mean_squared_error: 61175.4453 mean_absolute_error: 173.0673 val_loss: 54615.4648 val_mean_squared_error: 54615.4648 val_mean_absolute_error: 160.4550\n","Model: \"sequential_402\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1284 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1285 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 52697.0781 - mse: 52697.0781 - mae: 158.9125 - val_loss: 34369.9844 - val_mse: 34369.9844 - val_mae: 131.3474\n","163/163 [==============================] - 0s 921us/step\n","Epoch 1/1\n","16/16 loss: 52697.0781 mean_squared_error: 52697.0781 mean_absolute_error: 158.9125 val_loss: 34369.9844 val_mean_squared_error: 34369.9844 val_mean_absolute_error: 131.3474\n","Model: \"sequential_403\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1286 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1287 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 52880.1992 - mse: 52880.1992 - mae: 159.8891 - val_loss: 33836.3984 - val_mse: 33836.3984 - val_mae: 129.6980\n","163/163 [==============================] - 0s 968us/step\n","Epoch 1/1\n","16/16 loss: 52880.1992 mean_squared_error: 52880.1992 mean_absolute_error: 159.8891 val_loss: 33836.3984 val_mean_squared_error: 33836.3984 val_mean_absolute_error: 129.6980\n","Model: \"sequential_404\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1288 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1289 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 50535.0000 - mse: 50535.0000 - mae: 156.3948 - val_loss: 31069.7461 - val_mse: 31069.7461 - val_mae: 128.2871\n","163/163 [==============================] - 0s 909us/step\n","Epoch 1/1\n","16/16 loss: 50535.0000 mean_squared_error: 50535.0000 mean_absolute_error: 156.3948 val_loss: 31069.7461 val_mean_squared_error: 31069.7461 val_mean_absolute_error: 128.2871\n","Model: \"sequential_405\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1290 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1291 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_480 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1292 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 35005.0703 - mse: 35005.0703 - mae: 137.0113 - val_loss: 20994.3555 - val_mse: 20994.3555 - val_mae: 107.3466\n","163/163 [==============================] - 0s 965us/step\n","Epoch 1/1\n","16/16 loss: 35005.0703 mean_squared_error: 35005.0703 mean_absolute_error: 137.0113 val_loss: 20994.3555 val_mean_squared_error: 20994.3555 val_mean_absolute_error: 107.3466\n","Model: \"sequential_406\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1293 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1294 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_481 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1295 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 60779.6680 - mse: 60779.6680 - mae: 172.0352 - val_loss: 56488.9180 - val_mse: 56488.9180 - val_mae: 163.5787\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 60779.6680 mean_squared_error: 60779.6680 mean_absolute_error: 172.0352 val_loss: 56488.9180 val_mean_squared_error: 56488.9180 val_mean_absolute_error: 163.5787\n","Model: \"sequential_407\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1296 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1297 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_482 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1298 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 32956.6836 - mse: 32956.6836 - mae: 133.1564 - val_loss: 19731.7266 - val_mse: 19731.7266 - val_mae: 100.9079\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 32956.6836 mean_squared_error: 32956.6836 mean_absolute_error: 133.1564 val_loss: 19731.7266 val_mean_squared_error: 19731.7266 val_mean_absolute_error: 100.9079\n","Model: \"sequential_408\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1299 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1300 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_483 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1301 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 34314.5195 - mse: 34314.5195 - mae: 134.6310 - val_loss: 20405.3281 - val_mse: 20405.3281 - val_mae: 107.6350\n","163/163 [==============================] - 0s 957us/step\n","Epoch 1/1\n","16/16 loss: 34314.5195 mean_squared_error: 34314.5195 mean_absolute_error: 134.6310 val_loss: 20405.3281 val_mean_squared_error: 20405.3281 val_mean_absolute_error: 107.6350\n","Model: \"sequential_409\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1302 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1303 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_484 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1304 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 30042.0547 - mse: 30042.0547 - mae: 128.2529 - val_loss: 19085.7090 - val_mse: 19085.7090 - val_mae: 101.9365\n","163/163 [==============================] - 0s 959us/step\n","Epoch 1/1\n","16/16 loss: 30042.0547 mean_squared_error: 30042.0547 mean_absolute_error: 128.2529 val_loss: 19085.7090 val_mean_squared_error: 19085.7090 val_mean_absolute_error: 101.9365\n","Model: \"sequential_410\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1305 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1306 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_485 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1307 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_486 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1308 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 27073.5957 - mse: 27073.5957 - mae: 115.7355 - val_loss: 14363.6475 - val_mse: 14363.6475 - val_mae: 82.3899\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 27073.5957 mean_squared_error: 27073.5957 mean_absolute_error: 115.7355 val_loss: 14363.6475 val_mean_squared_error: 14363.6475 val_mean_absolute_error: 82.3899\n","Model: \"sequential_411\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1309 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1310 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_487 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1311 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_488 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1312 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 2ms/step - loss: 60544.5664 - mse: 60544.5664 - mae: 171.4504 - val_loss: 56374.5547 - val_mse: 56374.5547 - val_mae: 163.4019\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 60544.5664 mean_squared_error: 60544.5664 mean_absolute_error: 171.4504 val_loss: 56374.5547 val_mean_squared_error: 56374.5547 val_mean_absolute_error: 163.4019\n","Model: \"sequential_412\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1313 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1314 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_489 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1315 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_490 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1316 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 25847.2285 - mse: 25847.2285 - mae: 114.6298 - val_loss: 14042.3223 - val_mse: 14042.3223 - val_mae: 82.2659\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 25847.2285 mean_squared_error: 25847.2285 mean_absolute_error: 114.6298 val_loss: 14042.3223 val_mean_squared_error: 14042.3223 val_mean_absolute_error: 82.2659\n","Model: \"sequential_413\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1317 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1318 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_491 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1319 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_492 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1320 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 29023.5352 - mse: 29023.5352 - mae: 119.6310 - val_loss: 14536.1875 - val_mse: 14536.1875 - val_mae: 79.8691\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 29023.5352 mean_squared_error: 29023.5352 mean_absolute_error: 119.6310 val_loss: 14536.1875 val_mean_squared_error: 14536.1875 val_mean_absolute_error: 79.8691\n","Model: \"sequential_414\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1321 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1322 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_493 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1323 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_494 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1324 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 3s 3ms/step - loss: 24001.6172 - mse: 24001.6172 - mae: 108.8783 - val_loss: 14098.9219 - val_mse: 14098.9219 - val_mae: 79.9609\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 24001.6172 mean_squared_error: 24001.6172 mean_absolute_error: 108.8783 val_loss: 14098.9219 val_mean_squared_error: 14098.9219 val_mean_absolute_error: 79.9609\n","Model: \"sequential_415\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1325 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1326 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_495 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1327 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 39290.4258 - mse: 39290.4258 - mae: 143.0722 - val_loss: 24234.8906 - val_mse: 24234.8906 - val_mae: 116.2857\n","163/163 [==============================] - 0s 902us/step\n","Epoch 1/1\n","16/16 loss: 39290.4258 mean_squared_error: 39290.4258 mean_absolute_error: 143.0722 val_loss: 24234.8906 val_mean_squared_error: 24234.8906 val_mean_absolute_error: 116.2857\n","Model: \"sequential_416\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1328 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1329 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_496 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1330 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 64583.8008 - mse: 64583.8008 - mae: 179.1948 - val_loss: 62345.4961 - val_mse: 62345.4961 - val_mae: 173.8081\n","163/163 [==============================] - 0s 957us/step\n","Epoch 1/1\n","16/16 loss: 64583.8008 mean_squared_error: 64583.8008 mean_absolute_error: 179.1948 val_loss: 62345.4961 val_mean_squared_error: 62345.4961 val_mean_absolute_error: 173.8081\n","Model: \"sequential_417\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1331 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1332 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_497 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1333 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 37530.7656 - mse: 37530.7656 - mae: 140.7111 - val_loss: 24383.4941 - val_mse: 24383.4941 - val_mae: 117.7903\n","163/163 [==============================] - 0s 977us/step\n","Epoch 1/1\n","16/16 loss: 37530.7656 mean_squared_error: 37530.7656 mean_absolute_error: 140.7111 val_loss: 24383.4941 val_mean_squared_error: 24383.4941 val_mean_absolute_error: 117.7903\n","Model: \"sequential_418\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1334 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1335 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_498 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1336 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 41786.1523 - mse: 41786.1523 - mae: 146.8520 - val_loss: 25684.3086 - val_mse: 25684.3086 - val_mae: 119.2887\n","163/163 [==============================] - 0s 883us/step\n","Epoch 1/1\n","16/16 loss: 41786.1523 mean_squared_error: 41786.1523 mean_absolute_error: 146.8520 val_loss: 25684.3086 val_mean_squared_error: 25684.3086 val_mean_absolute_error: 119.2887\n","Model: \"sequential_419\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1337 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1338 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_499 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1339 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 35586.6094 - mse: 35586.6094 - mae: 138.4580 - val_loss: 23314.6406 - val_mse: 23314.6406 - val_mae: 116.1854\n","163/163 [==============================] - 0s 924us/step\n","Epoch 1/1\n","16/16 loss: 35586.6094 mean_squared_error: 35586.6094 mean_absolute_error: 138.4580 val_loss: 23314.6406 val_mean_squared_error: 23314.6406 val_mean_absolute_error: 116.1854\n","Model: \"sequential_420\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1340 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1341 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_500 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1342 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_501 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1343 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 34110.4336 - mse: 34110.4336 - mae: 131.1373 - val_loss: 16649.5469 - val_mse: 16649.5469 - val_mae: 90.0911\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 34110.4336 mean_squared_error: 34110.4336 mean_absolute_error: 131.1373 val_loss: 16649.5469 val_mean_squared_error: 16649.5469 val_mean_absolute_error: 90.0911\n","Model: \"sequential_421\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1344 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1345 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_502 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1346 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_503 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1347 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 64590.1016 - mse: 64590.1016 - mae: 179.1704 - val_loss: 62484.0156 - val_mse: 62484.0156 - val_mae: 174.0712\n","163/163 [==============================] - 0s 944us/step\n","Epoch 1/1\n","16/16 loss: 64590.1016 mean_squared_error: 64590.1016 mean_absolute_error: 179.1704 val_loss: 62484.0156 val_mean_squared_error: 62484.0156 val_mean_absolute_error: 174.0712\n","Model: \"sequential_422\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1348 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1349 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_504 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1350 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_505 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1351 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 36212.2578 - mse: 36212.2578 - mae: 134.9202 - val_loss: 17517.2285 - val_mse: 17517.2285 - val_mae: 96.0430\n","163/163 [==============================] - 0s 993us/step\n","Epoch 1/1\n","16/16 loss: 36212.2578 mean_squared_error: 36212.2578 mean_absolute_error: 134.9202 val_loss: 17517.2285 val_mean_squared_error: 17517.2285 val_mean_absolute_error: 96.0430\n","Model: \"sequential_423\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1352 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1353 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_506 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1354 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_507 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1355 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 36093.6562 - mse: 36093.6562 - mae: 135.4252 - val_loss: 17089.4785 - val_mse: 17089.4785 - val_mae: 90.9776\n","163/163 [==============================] - 0s 995us/step\n","Epoch 1/1\n","16/16 loss: 36093.6562 mean_squared_error: 36093.6562 mean_absolute_error: 135.4252 val_loss: 17089.4785 val_mean_squared_error: 17089.4785 val_mean_absolute_error: 90.9776\n","Model: \"sequential_424\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1356 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1357 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_508 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1358 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_509 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1359 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","533/533 [==============================] - 2s 2ms/step - loss: 28752.7871 - mse: 28752.7871 - mae: 122.0648 - val_loss: 15324.4854 - val_mse: 15324.4854 - val_mae: 89.2352\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 1/1\n","16/16 loss: 28752.7871 mean_squared_error: 28752.7871 mean_absolute_error: 122.0648 val_loss: 15324.4854 val_mean_squared_error: 15324.4854 val_mean_absolute_error: 89.2352\n","Model: \"sequential_425\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1360 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1361 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 54291.4922 - mse: 54291.4922 - mae: 162.3294 - val_loss: 34933.9062 - val_mse: 34933.9062 - val_mae: 130.9812\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29150.6699 - mse: 29150.6699 - mae: 127.8796 - val_loss: 27195.7441 - val_mse: 27195.7441 - val_mae: 128.3450\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25292.0176 - mse: 25292.0176 - mae: 122.3530 - val_loss: 23818.8594 - val_mse: 23818.8594 - val_mae: 117.6931\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22041.5254 - mse: 22041.5254 - mae: 112.2151 - val_loss: 20781.7949 - val_mse: 20781.7949 - val_mae: 110.3898\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19434.8809 - mse: 19434.8809 - mae: 103.8797 - val_loss: 18581.7207 - val_mse: 18581.7207 - val_mae: 103.0584\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17670.4570 - mse: 17670.4570 - mae: 97.3944 - val_loss: 17183.1680 - val_mse: 17183.1680 - val_mae: 97.7495\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16506.4414 - mse: 16506.4414 - mae: 93.2993 - val_loss: 16241.7773 - val_mse: 16241.7773 - val_mae: 94.6507\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15729.2041 - mse: 15729.2041 - mae: 90.2753 - val_loss: 15524.0010 - val_mse: 15524.0010 - val_mae: 90.2721\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15130.1934 - mse: 15130.1934 - mae: 87.7720 - val_loss: 14986.1826 - val_mse: 14986.1826 - val_mae: 88.0042\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14651.9180 - mse: 14651.9180 - mae: 85.5936 - val_loss: 14549.9121 - val_mse: 14549.9121 - val_mae: 86.9223\n","163/163 [==============================] - 0s 865us/step\n","Epoch 10/10\n","16/16 loss: 14651.9180 mean_squared_error: 14651.9180 mean_absolute_error: 85.5936 val_loss: 14549.9121 val_mean_squared_error: 14549.9121 val_mean_absolute_error: 86.9223\n","Model: \"sequential_426\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1362 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1363 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 61158.6602 - mse: 61158.6602 - mae: 173.1336 - val_loss: 54618.2031 - val_mse: 54618.2031 - val_mae: 160.4442\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 49372.8672 - mse: 49372.8672 - mae: 152.8141 - val_loss: 46238.3047 - val_mse: 46238.3047 - val_mae: 148.0747\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 42741.8789 - mse: 42741.8789 - mae: 144.1337 - val_loss: 40941.9805 - val_mse: 40941.9805 - val_mae: 141.7220\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 38492.9922 - mse: 38492.9922 - mae: 139.5599 - val_loss: 37459.9531 - val_mse: 37459.9531 - val_mae: 138.2280\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 35167.2266 - mse: 35167.2266 - mae: 133.5527 - val_loss: 33777.1758 - val_mse: 33777.1758 - val_mae: 128.0589\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 31236.1328 - mse: 31236.1328 - mae: 121.2500 - val_loss: 29975.7793 - val_mse: 29975.7793 - val_mae: 117.0610\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 27816.6602 - mse: 27816.6602 - mae: 111.7414 - val_loss: 26970.9199 - val_mse: 26970.9199 - val_mae: 109.1232\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25102.1836 - mse: 25102.1836 - mae: 105.0696 - val_loss: 24545.9609 - val_mse: 24545.9609 - val_mae: 104.3358\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22936.1621 - mse: 22936.1621 - mae: 100.4063 - val_loss: 22538.8008 - val_mse: 22538.8008 - val_mae: 99.1731\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21039.7051 - mse: 21039.7051 - mae: 95.8442 - val_loss: 20715.3594 - val_mse: 20715.3594 - val_mae: 95.9058\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 21039.7051 mean_squared_error: 21039.7051 mean_absolute_error: 95.8442 val_loss: 20715.3594 val_mean_squared_error: 20715.3594 val_mean_absolute_error: 95.9058\n","Model: \"sequential_427\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1364 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1365 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 52958.6992 - mse: 52958.6992 - mae: 160.0438 - val_loss: 35343.0156 - val_mse: 35343.0156 - val_mae: 131.9976\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29959.3379 - mse: 29959.3379 - mae: 129.6667 - val_loss: 28366.4004 - val_mse: 28366.4004 - val_mae: 131.1638\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 26683.6758 - mse: 26683.6758 - mae: 126.1390 - val_loss: 24909.9863 - val_mse: 24909.9863 - val_mae: 119.6924\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22626.5742 - mse: 22626.5742 - mae: 113.4739 - val_loss: 21073.9180 - val_mse: 21073.9180 - val_mae: 109.2657\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19545.3008 - mse: 19545.3008 - mae: 103.9306 - val_loss: 18521.1621 - val_mse: 18521.1621 - val_mae: 102.6928\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17437.9355 - mse: 17437.9355 - mae: 96.6816 - val_loss: 16788.4160 - val_mse: 16788.4160 - val_mae: 95.2681\n","Epoch 7/10\n","533/533 [==============================] - 2s 3ms/step - loss: 16033.7979 - mse: 16033.7979 - mae: 91.4366 - val_loss: 15854.5293 - val_mse: 15854.5293 - val_mae: 88.4476\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15163.4170 - mse: 15163.4170 - mae: 87.5901 - val_loss: 14944.7803 - val_mse: 14944.7803 - val_mae: 87.0743\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14528.3037 - mse: 14528.3037 - mae: 85.1288 - val_loss: 14398.5869 - val_mse: 14398.5869 - val_mae: 86.7779\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14099.5869 - mse: 14099.5869 - mae: 83.5621 - val_loss: 13999.4590 - val_mse: 13999.4590 - val_mae: 85.1804\n","163/163 [==============================] - 0s 918us/step\n","Epoch 10/10\n","16/16 loss: 14099.5869 mean_squared_error: 14099.5869 mean_absolute_error: 83.5621 val_loss: 13999.4590 val_mean_squared_error: 13999.4590 val_mean_absolute_error: 85.1804\n","Model: \"sequential_428\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1366 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1367 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 4ms/step - loss: 54021.1016 - mse: 54021.1016 - mae: 162.1802 - val_loss: 34846.4531 - val_mse: 34846.4531 - val_mae: 130.7343\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 29032.2383 - mse: 29032.2383 - mae: 127.5114 - val_loss: 27034.6523 - val_mse: 27034.6523 - val_mae: 126.8225\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25032.7910 - mse: 25032.7910 - mae: 121.3626 - val_loss: 23459.9453 - val_mse: 23459.9453 - val_mae: 116.3155\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21656.2852 - mse: 21656.2852 - mae: 111.0944 - val_loss: 20375.9102 - val_mse: 20375.9102 - val_mae: 107.1824\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19063.9531 - mse: 19063.9531 - mae: 102.2247 - val_loss: 18254.2734 - val_mse: 18254.2734 - val_mae: 100.9851\n","Epoch 6/10\n","533/533 [==============================] - 2s 3ms/step - loss: 17373.9258 - mse: 17373.9258 - mae: 96.3872 - val_loss: 16927.2422 - val_mse: 16927.2422 - val_mae: 96.5270\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16286.8408 - mse: 16286.8408 - mae: 92.4756 - val_loss: 16011.3955 - val_mse: 16011.3955 - val_mae: 91.8546\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15513.8770 - mse: 15513.8770 - mae: 89.2279 - val_loss: 15335.6396 - val_mse: 15335.6396 - val_mae: 89.7899\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14947.5117 - mse: 14947.5117 - mae: 87.0436 - val_loss: 14840.3154 - val_mse: 14840.3154 - val_mae: 87.2614\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14529.6260 - mse: 14529.6260 - mae: 85.2523 - val_loss: 14433.5605 - val_mse: 14433.5605 - val_mae: 85.8480\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","16/16 loss: 14529.6260 mean_squared_error: 14529.6260 mean_absolute_error: 85.2523 val_loss: 14433.5605 val_mean_squared_error: 14433.5605 val_mean_absolute_error: 85.8480\n","Model: \"sequential_429\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1368 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1369 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 833\n","Trainable params: 833\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 50576.2773 - mse: 50576.2773 - mae: 156.5593 - val_loss: 30885.6309 - val_mse: 30885.6309 - val_mae: 128.1611\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 28065.4258 - mse: 28065.4258 - mae: 128.3696 - val_loss: 26969.2422 - val_mse: 26969.2422 - val_mae: 128.3570\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25636.1289 - mse: 25636.1289 - mae: 124.4783 - val_loss: 24696.9570 - val_mse: 24696.9570 - val_mae: 122.7562\n","Epoch 4/10\n","533/533 [==============================] - 2s 3ms/step - loss: 23411.8262 - mse: 23411.8262 - mae: 118.4890 - val_loss: 22457.5312 - val_mse: 22457.5312 - val_mae: 115.8036\n","Epoch 5/10\n","533/533 [==============================] - 1s 3ms/step - loss: 21258.3438 - mse: 21258.3438 - mae: 111.2826 - val_loss: 20396.1895 - val_mse: 20396.1895 - val_mae: 109.8021\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19363.9141 - mse: 19363.9141 - mae: 104.9184 - val_loss: 18719.6934 - val_mse: 18719.6934 - val_mae: 102.4971\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17876.6758 - mse: 17876.6758 - mae: 98.8716 - val_loss: 17425.6172 - val_mse: 17425.6172 - val_mae: 98.0012\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16793.4648 - mse: 16793.4648 - mae: 94.6311 - val_loss: 16515.3672 - val_mse: 16515.3672 - val_mae: 94.0122\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15995.9941 - mse: 15995.9941 - mae: 91.3683 - val_loss: 15850.7314 - val_mse: 15850.7314 - val_mae: 90.6731\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15409.8721 - mse: 15409.8721 - mae: 88.7097 - val_loss: 15285.3516 - val_mse: 15285.3516 - val_mae: 89.1920\n","163/163 [==============================] - 0s 905us/step\n","Epoch 10/10\n","16/16 loss: 15409.8721 mean_squared_error: 15409.8721 mean_absolute_error: 88.7097 val_loss: 15285.3516 val_mean_squared_error: 15285.3516 val_mean_absolute_error: 89.1920\n","Model: \"sequential_430\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1370 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1371 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_510 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1372 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 3ms/step - loss: 36711.0312 - mse: 36711.0312 - mae: 139.0247 - val_loss: 22638.4961 - val_mse: 22638.4961 - val_mae: 110.0857\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 20920.5020 - mse: 20920.5020 - mae: 104.1586 - val_loss: 15798.3330 - val_mse: 15798.3330 - val_mae: 87.3888\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17566.2754 - mse: 17566.2754 - mae: 91.8802 - val_loss: 14198.8213 - val_mse: 14198.8213 - val_mae: 80.7000\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16797.4082 - mse: 16797.4082 - mae: 88.0602 - val_loss: 13598.6543 - val_mse: 13598.6543 - val_mae: 78.0221\n","Epoch 5/10\n","533/533 [==============================] - 2s 4ms/step - loss: 16328.5273 - mse: 16328.5273 - mae: 86.8151 - val_loss: 13230.4609 - val_mse: 13230.4609 - val_mae: 77.2095\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16222.2002 - mse: 16222.2002 - mae: 86.3814 - val_loss: 13114.7832 - val_mse: 13114.7832 - val_mae: 75.0985\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15757.9678 - mse: 15757.9678 - mae: 85.8766 - val_loss: 12878.5391 - val_mse: 12878.5391 - val_mae: 74.6352\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16313.3486 - mse: 16313.3486 - mae: 86.4819 - val_loss: 12476.2852 - val_mse: 12476.2852 - val_mae: 75.4117\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15691.9590 - mse: 15691.9590 - mae: 84.3674 - val_loss: 12222.9541 - val_mse: 12222.9541 - val_mae: 76.5852\n","Epoch 10/10\n","533/533 [==============================] - 2s 3ms/step - loss: 15558.6094 - mse: 15558.6094 - mae: 84.4247 - val_loss: 12725.3652 - val_mse: 12725.3652 - val_mae: 71.9187\n","163/163 [==============================] - 0s 2ms/step\n","Epoch 10/10\n","16/16 loss: 15558.6094 mean_squared_error: 15558.6094 mean_absolute_error: 84.4247 val_loss: 12725.3652 val_mean_squared_error: 12725.3652 val_mean_absolute_error: 71.9187\n","Model: \"sequential_431\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1373 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1374 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_511 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1375 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 60966.7500 - mse: 60966.7500 - mae: 172.2456 - val_loss: 56557.6719 - val_mse: 56557.6719 - val_mae: 163.6887\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 51954.9688 - mse: 51954.9688 - mae: 157.0513 - val_loss: 49094.9922 - val_mse: 49094.9922 - val_mae: 152.2683\n","Epoch 3/10\n","533/533 [==============================] - 1s 3ms/step - loss: 45576.4219 - mse: 45576.4219 - mae: 148.0659 - val_loss: 43686.6836 - val_mse: 43686.6836 - val_mae: 145.0321\n","Epoch 4/10\n","533/533 [==============================] - 2s 3ms/step - loss: 40053.4492 - mse: 40053.4492 - mae: 133.4040 - val_loss: 37556.7227 - val_mse: 37556.7227 - val_mae: 124.0180\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 35043.7656 - mse: 35043.7656 - mae: 120.1040 - val_loss: 33057.2617 - val_mse: 33057.2617 - val_mae: 114.3468\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 30570.9062 - mse: 30570.9062 - mae: 109.2649 - val_loss: 28800.0371 - val_mse: 28800.0371 - val_mae: 101.9148\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 27041.2344 - mse: 27041.2344 - mae: 100.8207 - val_loss: 25508.0352 - val_mse: 25508.0352 - val_mae: 94.0625\n","Epoch 8/10\n","533/533 [==============================] - 2s 4ms/step - loss: 24407.6328 - mse: 24407.6328 - mae: 95.9350 - val_loss: 22877.9180 - val_mse: 22877.9180 - val_mae: 89.4565\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21988.5527 - mse: 21988.5527 - mae: 90.8535 - val_loss: 20751.7246 - val_mse: 20751.7246 - val_mae: 86.2347\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 20340.6074 - mse: 20340.6074 - mae: 88.0527 - val_loss: 18989.9727 - val_mse: 18989.9727 - val_mae: 82.1275\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 20340.6074 mean_squared_error: 20340.6074 mean_absolute_error: 88.0527 val_loss: 18989.9727 val_mean_squared_error: 18989.9727 val_mean_absolute_error: 82.1275\n","Model: \"sequential_432\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1376 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1377 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_512 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1378 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 4s 4ms/step - loss: 33237.3750 - mse: 33237.3750 - mae: 133.3378 - val_loss: 19660.9453 - val_mse: 19660.9453 - val_mae: 103.6225\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18536.6367 - mse: 18536.6367 - mae: 96.1725 - val_loss: 14506.3428 - val_mse: 14506.3428 - val_mae: 85.9884\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16059.2910 - mse: 16059.2910 - mae: 88.2594 - val_loss: 13544.2686 - val_mse: 13544.2686 - val_mae: 78.1511\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15220.4365 - mse: 15220.4365 - mae: 85.0129 - val_loss: 12734.6982 - val_mse: 12734.6982 - val_mae: 76.5425\n","Epoch 5/10\n","533/533 [==============================] - 2s 4ms/step - loss: 14961.8145 - mse: 14961.8145 - mae: 82.7908 - val_loss: 12564.1162 - val_mse: 12564.1162 - val_mae: 73.2611\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14370.3125 - mse: 14370.3125 - mae: 80.4761 - val_loss: 11804.1006 - val_mse: 11804.1006 - val_mae: 73.0902\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13642.0059 - mse: 13642.0059 - mae: 77.8781 - val_loss: 11346.6201 - val_mse: 11346.6201 - val_mae: 70.7832\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12924.2598 - mse: 12924.2598 - mae: 75.4705 - val_loss: 11001.9717 - val_mse: 11001.9717 - val_mae: 69.9108\n","Epoch 9/10\n","533/533 [==============================] - 2s 3ms/step - loss: 12580.5254 - mse: 12580.5254 - mae: 73.8334 - val_loss: 10812.9092 - val_mse: 10812.9092 - val_mae: 68.4592\n","Epoch 10/10\n","533/533 [==============================] - 2s 3ms/step - loss: 12800.1797 - mse: 12800.1797 - mae: 73.9800 - val_loss: 10403.0547 - val_mse: 10403.0547 - val_mae: 66.3420\n","163/163 [==============================] - 0s 986us/step\n","Epoch 10/10\n","16/16 loss: 12800.1797 mean_squared_error: 12800.1797 mean_absolute_error: 73.9800 val_loss: 10403.0547 val_mean_squared_error: 10403.0547 val_mean_absolute_error: 66.3420\n","Model: \"sequential_433\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1379 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1380 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_513 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1381 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 33577.2461 - mse: 33577.2461 - mae: 132.3474 - val_loss: 20209.4199 - val_mse: 20209.4199 - val_mae: 106.1371\n","Epoch 2/10\n","533/533 [==============================] - 2s 3ms/step - loss: 18359.0137 - mse: 18359.0137 - mae: 96.8167 - val_loss: 14965.2705 - val_mse: 14965.2705 - val_mae: 86.2255\n","Epoch 3/10\n","533/533 [==============================] - 2s 3ms/step - loss: 16313.4424 - mse: 16313.4424 - mae: 87.2657 - val_loss: 13657.7158 - val_mse: 13657.7158 - val_mae: 83.0540\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15285.9229 - mse: 15285.9229 - mae: 84.7008 - val_loss: 13141.0723 - val_mse: 13141.0723 - val_mae: 79.5089\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15089.4375 - mse: 15089.4375 - mae: 83.7702 - val_loss: 13001.7900 - val_mse: 13001.7900 - val_mae: 77.4555\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14939.2012 - mse: 14939.2012 - mae: 83.2573 - val_loss: 12800.5889 - val_mse: 12800.5889 - val_mae: 75.9798\n","Epoch 7/10\n","533/533 [==============================] - 1s 3ms/step - loss: 14728.5713 - mse: 14728.5713 - mae: 82.2315 - val_loss: 12482.0488 - val_mse: 12482.0488 - val_mae: 76.9238\n","Epoch 8/10\n","533/533 [==============================] - 2s 3ms/step - loss: 14503.0117 - mse: 14503.0117 - mae: 81.6778 - val_loss: 12373.4824 - val_mse: 12373.4824 - val_mae: 78.7065\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14592.4707 - mse: 14592.4707 - mae: 81.5902 - val_loss: 12244.2158 - val_mse: 12244.2158 - val_mae: 78.9922\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14142.2129 - mse: 14142.2129 - mae: 80.4807 - val_loss: 12291.6777 - val_mse: 12291.6777 - val_mae: 72.8549\n","163/163 [==============================] - 0s 923us/step\n","Epoch 10/10\n","16/16 loss: 14142.2129 mean_squared_error: 14142.2129 mean_absolute_error: 80.4807 val_loss: 12291.6777 val_mean_squared_error: 12291.6777 val_mean_absolute_error: 72.8549\n","Model: \"sequential_434\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1382 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1383 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_514 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1384 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 9,857\n","Trainable params: 9,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 31613.1777 - mse: 31613.1777 - mae: 131.6542 - val_loss: 19945.3496 - val_mse: 19945.3496 - val_mae: 105.7732\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17712.3242 - mse: 17712.3242 - mae: 96.1319 - val_loss: 14979.8105 - val_mse: 14979.8105 - val_mae: 85.2592\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15398.7715 - mse: 15398.7715 - mae: 86.1189 - val_loss: 13656.3291 - val_mse: 13656.3291 - val_mae: 84.0749\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14932.7275 - mse: 14932.7275 - mae: 85.0604 - val_loss: 13788.8281 - val_mse: 13788.8281 - val_mae: 77.3304\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14470.6455 - mse: 14470.6455 - mae: 82.8396 - val_loss: 13244.3340 - val_mse: 13244.3340 - val_mae: 77.8025\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14615.6211 - mse: 14615.6211 - mae: 83.7459 - val_loss: 12980.9434 - val_mse: 12980.9434 - val_mae: 80.3682\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14315.5771 - mse: 14315.5771 - mae: 82.5771 - val_loss: 12969.4189 - val_mse: 12969.4189 - val_mae: 82.0395\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14181.1113 - mse: 14181.1113 - mae: 82.6840 - val_loss: 12977.2412 - val_mse: 12977.2412 - val_mae: 82.4434\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14651.1240 - mse: 14651.1240 - mae: 83.8140 - val_loss: 13125.1719 - val_mse: 13125.1719 - val_mae: 77.4619\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14404.3047 - mse: 14404.3047 - mae: 83.0726 - val_loss: 12950.6641 - val_mse: 12950.6641 - val_mae: 79.1513\n","163/163 [==============================] - 0s 911us/step\n","Epoch 10/10\n","16/16 loss: 14404.3047 mean_squared_error: 14404.3047 mean_absolute_error: 83.0726 val_loss: 12950.6641 val_mean_squared_error: 12950.6641 val_mean_absolute_error: 79.1513\n","Model: \"sequential_435\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1385 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1386 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_515 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1387 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_516 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1388 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 27255.0859 - mse: 27255.0859 - mae: 116.5657 - val_loss: 14712.3848 - val_mse: 14712.3848 - val_mae: 79.9817\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17249.2812 - mse: 17249.2812 - mae: 89.4238 - val_loss: 13181.7227 - val_mse: 13181.7227 - val_mae: 74.6026\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16487.2227 - mse: 16487.2227 - mae: 86.6942 - val_loss: 12974.8242 - val_mse: 12974.8242 - val_mae: 71.5144\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15400.0801 - mse: 15400.0801 - mae: 83.0722 - val_loss: 12276.5273 - val_mse: 12276.5273 - val_mae: 70.8314\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15073.2080 - mse: 15073.2080 - mae: 81.2967 - val_loss: 11569.1904 - val_mse: 11569.1904 - val_mae: 68.2266\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14488.4268 - mse: 14488.4268 - mae: 79.8333 - val_loss: 10638.9453 - val_mse: 10638.9453 - val_mae: 67.7993\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14377.6816 - mse: 14377.6816 - mae: 78.2395 - val_loss: 11019.1025 - val_mse: 11019.1025 - val_mae: 65.2232\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13744.1875 - mse: 13744.1875 - mae: 76.6722 - val_loss: 10248.6426 - val_mse: 10248.6426 - val_mae: 64.3954\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13488.2773 - mse: 13488.2773 - mae: 76.1773 - val_loss: 10913.0117 - val_mse: 10913.0117 - val_mae: 64.6266\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13442.5078 - mse: 13442.5078 - mae: 76.0244 - val_loss: 10560.5811 - val_mse: 10560.5811 - val_mae: 63.3074\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 13442.5078 mean_squared_error: 13442.5078 mean_absolute_error: 76.0244 val_loss: 10560.5811 val_mean_squared_error: 10560.5811 val_mean_absolute_error: 63.3074\n","Model: \"sequential_436\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1389 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1390 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_517 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1391 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_518 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1392 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 2ms/step - loss: 61224.4336 - mse: 61224.4336 - mae: 172.5909 - val_loss: 57024.5703 - val_mse: 57024.5703 - val_mae: 164.4630\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 52361.0234 - mse: 52361.0234 - mae: 157.6755 - val_loss: 49495.0273 - val_mse: 49495.0273 - val_mae: 152.8529\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 46177.3477 - mse: 46177.3477 - mae: 148.8802 - val_loss: 44105.9336 - val_mse: 44105.9336 - val_mae: 145.6785\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 41603.3906 - mse: 41603.3906 - mae: 143.4044 - val_loss: 40271.5312 - val_mse: 40271.5312 - val_mae: 141.5697\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 38240.1836 - mse: 38240.1836 - mae: 138.4528 - val_loss: 35126.9492 - val_mse: 35126.9492 - val_mae: 121.0335\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 32565.3164 - mse: 32565.3164 - mae: 115.7220 - val_loss: 30357.3379 - val_mse: 30357.3379 - val_mae: 106.6949\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 28350.8867 - mse: 28350.8867 - mae: 104.6208 - val_loss: 26607.0234 - val_mse: 26607.0234 - val_mae: 97.6674\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25175.4805 - mse: 25175.4805 - mae: 97.5769 - val_loss: 23890.3379 - val_mse: 23890.3379 - val_mae: 93.5613\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 22895.8379 - mse: 22895.8379 - mae: 93.9190 - val_loss: 21264.8906 - val_mse: 21264.8906 - val_mae: 85.5339\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21033.4492 - mse: 21033.4492 - mae: 90.4483 - val_loss: 19271.6641 - val_mse: 19271.6641 - val_mae: 80.5390\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 21033.4492 mean_squared_error: 21033.4492 mean_absolute_error: 90.4483 val_loss: 19271.6641 val_mean_squared_error: 19271.6641 val_mean_absolute_error: 80.5390\n","Model: \"sequential_437\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1393 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1394 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_519 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1395 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_520 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1396 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 24684.2090 - mse: 24684.2090 - mae: 111.0739 - val_loss: 13522.4160 - val_mse: 13522.4160 - val_mae: 83.7410\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15875.3350 - mse: 15875.3350 - mae: 85.8024 - val_loss: 12408.6377 - val_mse: 12408.6377 - val_mae: 77.5577\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15064.3701 - mse: 15064.3701 - mae: 82.0870 - val_loss: 11579.1533 - val_mse: 11579.1533 - val_mae: 73.7672\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13761.3467 - mse: 13761.3467 - mae: 77.9677 - val_loss: 10720.0908 - val_mse: 10720.0908 - val_mae: 70.6096\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13555.1543 - mse: 13555.1543 - mae: 77.2475 - val_loss: 10326.2920 - val_mse: 10326.2920 - val_mae: 69.9360\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13253.9336 - mse: 13253.9336 - mae: 76.1013 - val_loss: 10263.8193 - val_mse: 10263.8193 - val_mae: 69.3815\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13020.5889 - mse: 13020.5889 - mae: 76.2403 - val_loss: 10156.6328 - val_mse: 10156.6328 - val_mae: 65.5553\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13029.9189 - mse: 13029.9189 - mae: 76.0627 - val_loss: 10423.2090 - val_mse: 10423.2090 - val_mae: 64.4697\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12642.0293 - mse: 12642.0293 - mae: 74.2319 - val_loss: 9989.6260 - val_mse: 9989.6260 - val_mae: 68.5809\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 12819.4775 - mse: 12819.4775 - mae: 74.4011 - val_loss: 10348.2920 - val_mse: 10348.2920 - val_mae: 63.8641\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 12819.4775 mean_squared_error: 12819.4775 mean_absolute_error: 74.4011 val_loss: 10348.2920 val_mean_squared_error: 10348.2920 val_mean_absolute_error: 63.8641\n","Model: \"sequential_438\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1397 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1398 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_521 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1399 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_522 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1400 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 3ms/step - loss: 27540.8984 - mse: 27540.8984 - mae: 117.6276 - val_loss: 14326.2598 - val_mse: 14326.2598 - val_mae: 82.9755\n","Epoch 2/10\n","533/533 [==============================] - 2s 4ms/step - loss: 17555.2109 - mse: 17555.2109 - mae: 89.7646 - val_loss: 12972.1758 - val_mse: 12972.1758 - val_mae: 81.5635\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16650.9141 - mse: 16650.9141 - mae: 87.2438 - val_loss: 13380.5000 - val_mse: 13380.5000 - val_mae: 72.6273\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16034.2158 - mse: 16034.2158 - mae: 85.1743 - val_loss: 11758.5869 - val_mse: 11758.5869 - val_mae: 76.3727\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15282.1367 - mse: 15282.1367 - mae: 81.6796 - val_loss: 11271.6436 - val_mse: 11271.6436 - val_mae: 70.2135\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14349.3682 - mse: 14349.3682 - mae: 79.1971 - val_loss: 10911.7041 - val_mse: 10911.7041 - val_mae: 76.3264\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 14169.6680 - mse: 14169.6680 - mae: 78.3971 - val_loss: 10431.6162 - val_mse: 10431.6162 - val_mae: 65.6901\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13998.4150 - mse: 13998.4150 - mae: 77.2643 - val_loss: 10898.2949 - val_mse: 10898.2949 - val_mae: 63.9698\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13452.0371 - mse: 13452.0371 - mae: 75.8780 - val_loss: 9632.4014 - val_mse: 9632.4014 - val_mae: 66.1618\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 13564.3633 - mse: 13564.3633 - mae: 74.9416 - val_loss: 11786.3027 - val_mse: 11786.3027 - val_mae: 66.1762\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 13564.3633 mean_squared_error: 13564.3633 mean_absolute_error: 74.9416 val_loss: 11786.3027 val_mean_squared_error: 11786.3027 val_mean_absolute_error: 66.1762\n","Model: \"sequential_439\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1401 (Dense)          (None, 256)               3072      \n","                                                                 \n"," dense_1402 (Dense)          (None, 128)               32896     \n","                                                                 \n"," dropout_523 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_1403 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_524 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1404 (Dense)          (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 44,289\n","Trainable params: 44,289\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 23323.1562 - mse: 23323.1562 - mae: 107.7152 - val_loss: 13961.6953 - val_mse: 13961.6953 - val_mae: 80.6351\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16029.3408 - mse: 16029.3408 - mae: 87.3095 - val_loss: 13235.1904 - val_mse: 13235.1904 - val_mae: 77.8466\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15159.1562 - mse: 15159.1562 - mae: 85.4686 - val_loss: 13668.1670 - val_mse: 13668.1670 - val_mae: 76.5735\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15291.0146 - mse: 15291.0146 - mae: 85.0477 - val_loss: 12913.1875 - val_mse: 12913.1875 - val_mae: 79.9664\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15475.7285 - mse: 15475.7285 - mae: 85.8042 - val_loss: 13102.1045 - val_mse: 13102.1045 - val_mae: 79.0117\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15800.4014 - mse: 15800.4014 - mae: 86.4839 - val_loss: 12955.4775 - val_mse: 12955.4775 - val_mae: 81.2562\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15522.3359 - mse: 15522.3359 - mae: 86.0477 - val_loss: 13003.5234 - val_mse: 13003.5234 - val_mae: 82.0738\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15172.9453 - mse: 15172.9453 - mae: 85.0337 - val_loss: 13451.9668 - val_mse: 13451.9668 - val_mae: 76.4858\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15472.8633 - mse: 15472.8633 - mae: 85.8874 - val_loss: 12960.5352 - val_mse: 12960.5352 - val_mae: 80.0783\n","Epoch 9: early stopping\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 15472.8633 mean_squared_error: 15472.8633 mean_absolute_error: 85.8874 val_loss: 12960.5352 val_mean_squared_error: 12960.5352 val_mean_absolute_error: 80.0783\n","Model: \"sequential_440\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1405 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1406 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_525 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1407 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 40517.4375 - mse: 40517.4375 - mae: 145.4707 - val_loss: 24897.3301 - val_mse: 24897.3301 - val_mae: 120.0770\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 23732.2207 - mse: 23732.2207 - mae: 113.5362 - val_loss: 17753.8652 - val_mse: 17753.8652 - val_mae: 94.9167\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19203.1797 - mse: 19203.1797 - mae: 97.1223 - val_loss: 15184.2100 - val_mse: 15184.2100 - val_mae: 84.9236\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18003.4863 - mse: 18003.4863 - mae: 92.0565 - val_loss: 14363.0654 - val_mse: 14363.0654 - val_mae: 79.7620\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16909.1387 - mse: 16909.1387 - mae: 88.9927 - val_loss: 13481.3076 - val_mse: 13481.3076 - val_mae: 80.1172\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17103.4648 - mse: 17103.4648 - mae: 88.2742 - val_loss: 13751.4150 - val_mse: 13751.4150 - val_mae: 77.0240\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16745.3438 - mse: 16745.3438 - mae: 88.3246 - val_loss: 13355.9053 - val_mse: 13355.9053 - val_mae: 76.8424\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16676.5820 - mse: 16676.5820 - mae: 87.8734 - val_loss: 13527.3018 - val_mse: 13527.3018 - val_mae: 75.4045\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17099.3184 - mse: 17099.3184 - mae: 87.8777 - val_loss: 13920.8848 - val_mse: 13920.8848 - val_mae: 74.3326\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16877.3457 - mse: 16877.3457 - mae: 87.8538 - val_loss: 12915.2676 - val_mse: 12915.2676 - val_mae: 75.5161\n","163/163 [==============================] - 0s 990us/step\n","Epoch 10/10\n","16/16 loss: 16877.3457 mean_squared_error: 16877.3457 mean_absolute_error: 87.8538 val_loss: 12915.2676 val_mean_squared_error: 12915.2676 val_mean_absolute_error: 75.5161\n","Model: \"sequential_441\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1408 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1409 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_526 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1410 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 64305.6836 - mse: 64305.6836 - mae: 178.6012 - val_loss: 62045.2773 - val_mse: 62045.2773 - val_mae: 173.2405\n","Epoch 2/10\n","533/533 [==============================] - 1s 3ms/step - loss: 58780.5156 - mse: 58780.5156 - mae: 168.0672 - val_loss: 57201.0781 - val_mse: 57201.0781 - val_mae: 164.7479\n","Epoch 3/10\n","533/533 [==============================] - 2s 3ms/step - loss: 54413.2734 - mse: 54413.2734 - mae: 160.8674 - val_loss: 53096.8672 - val_mse: 53096.8672 - val_mae: 158.1997\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 50829.5391 - mse: 50829.5391 - mae: 155.2393 - val_loss: 49568.1641 - val_mse: 49568.1641 - val_mae: 152.9513\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 47491.0078 - mse: 47491.0078 - mae: 150.5100 - val_loss: 46504.5625 - val_mse: 46504.5625 - val_mae: 148.7276\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 44770.5820 - mse: 44770.5820 - mae: 146.2144 - val_loss: 43320.8477 - val_mse: 43320.8477 - val_mae: 138.0775\n","Epoch 7/10\n","533/533 [==============================] - 2s 3ms/step - loss: 41227.5430 - mse: 41227.5430 - mae: 133.5322 - val_loss: 39985.7539 - val_mse: 39985.7539 - val_mae: 129.0118\n","Epoch 8/10\n","533/533 [==============================] - 1s 3ms/step - loss: 38159.1758 - mse: 38159.1758 - mae: 126.8002 - val_loss: 37135.5234 - val_mse: 37135.5234 - val_mae: 123.1239\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 35899.2969 - mse: 35899.2969 - mae: 121.9793 - val_loss: 34673.4062 - val_mse: 34673.4062 - val_mae: 116.9113\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 33777.9766 - mse: 33777.9766 - mae: 117.9803 - val_loss: 32488.8945 - val_mse: 32488.8945 - val_mae: 112.6807\n","163/163 [==============================] - 0s 993us/step\n","Epoch 10/10\n","16/16 loss: 33777.9766 mean_squared_error: 33777.9766 mean_absolute_error: 117.9803 val_loss: 32488.8945 val_mean_squared_error: 32488.8945 val_mean_absolute_error: 112.6807\n","Model: \"sequential_442\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1411 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1412 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_527 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1413 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 3ms/step - loss: 40214.9609 - mse: 40214.9609 - mae: 145.4367 - val_loss: 26545.8418 - val_mse: 26545.8418 - val_mae: 121.6914\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 24079.5684 - mse: 24079.5684 - mae: 112.3861 - val_loss: 17873.3516 - val_mse: 17873.3516 - val_mae: 92.0655\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19496.7832 - mse: 19496.7832 - mae: 96.8410 - val_loss: 14831.8721 - val_mse: 14831.8721 - val_mae: 85.7567\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17755.5762 - mse: 17755.5762 - mae: 91.6231 - val_loss: 14034.2812 - val_mse: 14034.2812 - val_mae: 78.4533\n","Epoch 5/10\n","533/533 [==============================] - 2s 4ms/step - loss: 17284.1699 - mse: 17284.1699 - mae: 89.2786 - val_loss: 12984.7100 - val_mse: 12984.7100 - val_mae: 77.7585\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16720.0625 - mse: 16720.0625 - mae: 87.3605 - val_loss: 12551.9404 - val_mse: 12551.9404 - val_mae: 74.1748\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15973.8291 - mse: 15973.8291 - mae: 84.1197 - val_loss: 12555.7686 - val_mse: 12555.7686 - val_mae: 71.8413\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15526.3818 - mse: 15526.3818 - mae: 82.4298 - val_loss: 11918.3711 - val_mse: 11918.3711 - val_mae: 70.0178\n","Epoch 9/10\n","533/533 [==============================] - 1s 3ms/step - loss: 15685.6494 - mse: 15685.6494 - mae: 82.7949 - val_loss: 11965.1338 - val_mse: 11965.1338 - val_mae: 68.1244\n","Epoch 10/10\n","533/533 [==============================] - 2s 3ms/step - loss: 15360.9033 - mse: 15360.9033 - mae: 80.9659 - val_loss: 11476.6660 - val_mse: 11476.6660 - val_mae: 67.6589\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 15360.9033 mean_squared_error: 15360.9033 mean_absolute_error: 80.9659 val_loss: 11476.6660 val_mean_squared_error: 11476.6660 val_mean_absolute_error: 67.6589\n","Model: \"sequential_443\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1414 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1415 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_528 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1416 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 41501.5117 - mse: 41501.5117 - mae: 147.9916 - val_loss: 25684.5879 - val_mse: 25684.5879 - val_mae: 121.3767\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 25205.2012 - mse: 25205.2012 - mae: 118.3182 - val_loss: 18953.8691 - val_mse: 18953.8691 - val_mae: 100.8782\n","Epoch 3/10\n","533/533 [==============================] - 2s 4ms/step - loss: 21206.5527 - mse: 21206.5527 - mae: 103.0804 - val_loss: 15975.5000 - val_mse: 15975.5000 - val_mae: 87.5030\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19675.8633 - mse: 19675.8633 - mae: 96.3702 - val_loss: 15047.0352 - val_mse: 15047.0352 - val_mae: 81.6802\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18614.2559 - mse: 18614.2559 - mae: 93.2412 - val_loss: 14432.8828 - val_mse: 14432.8828 - val_mae: 78.7235\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18074.5996 - mse: 18074.5996 - mae: 91.6525 - val_loss: 13563.5674 - val_mse: 13563.5674 - val_mae: 78.3660\n","Epoch 7/10\n","533/533 [==============================] - 1s 3ms/step - loss: 17978.8574 - mse: 17978.8574 - mae: 91.4216 - val_loss: 13445.4111 - val_mse: 13445.4111 - val_mae: 77.2681\n","Epoch 8/10\n","533/533 [==============================] - 2s 3ms/step - loss: 17810.1855 - mse: 17810.1855 - mae: 90.0941 - val_loss: 13439.9365 - val_mse: 13439.9365 - val_mae: 75.9040\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17890.3574 - mse: 17890.3574 - mae: 90.3715 - val_loss: 13233.6523 - val_mse: 13233.6523 - val_mae: 76.1936\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18020.9590 - mse: 18020.9590 - mae: 91.2129 - val_loss: 13797.5400 - val_mse: 13797.5400 - val_mae: 74.9244\n","163/163 [==============================] - 0s 912us/step\n","Epoch 10/10\n","16/16 loss: 18020.9590 mean_squared_error: 18020.9590 mean_absolute_error: 91.2129 val_loss: 13797.5400 val_mean_squared_error: 13797.5400 val_mean_absolute_error: 74.9244\n","Model: \"sequential_444\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1417 (Dense)          (None, 64)                768       \n","                                                                 \n"," dense_1418 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_529 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1419 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 2,881\n","Trainable params: 2,881\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 4ms/step - loss: 35958.3867 - mse: 35958.3867 - mae: 138.4595 - val_loss: 23610.3867 - val_mse: 23610.3867 - val_mae: 117.2030\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21939.7227 - mse: 21939.7227 - mae: 109.7618 - val_loss: 17353.5410 - val_mse: 17353.5410 - val_mae: 95.2751\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18054.9785 - mse: 18054.9785 - mae: 95.2315 - val_loss: 15057.8105 - val_mse: 15057.8105 - val_mae: 86.9393\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16980.1855 - mse: 16980.1855 - mae: 90.9357 - val_loss: 14035.0557 - val_mse: 14035.0557 - val_mae: 83.8624\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16395.8496 - mse: 16395.8496 - mae: 88.1348 - val_loss: 13539.1680 - val_mse: 13539.1680 - val_mae: 82.5714\n","Epoch 6/10\n","533/533 [==============================] - 1s 3ms/step - loss: 16012.1250 - mse: 16012.1250 - mae: 87.6302 - val_loss: 13331.7773 - val_mse: 13331.7773 - val_mae: 80.4899\n","Epoch 7/10\n","533/533 [==============================] - 2s 3ms/step - loss: 15859.4404 - mse: 15859.4404 - mae: 86.7622 - val_loss: 13507.0586 - val_mse: 13507.0586 - val_mae: 77.5208\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15684.3174 - mse: 15684.3174 - mae: 86.5774 - val_loss: 13060.0840 - val_mse: 13060.0840 - val_mae: 81.3145\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15860.6152 - mse: 15860.6152 - mae: 86.9821 - val_loss: 13517.3262 - val_mse: 13517.3262 - val_mae: 76.9040\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15863.8145 - mse: 15863.8145 - mae: 86.6568 - val_loss: 13560.5898 - val_mse: 13560.5898 - val_mae: 76.5574\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 15863.8145 mean_squared_error: 15863.8145 mean_absolute_error: 86.6568 val_loss: 13560.5898 val_mean_squared_error: 13560.5898 val_mean_absolute_error: 76.5574\n","Model: \"sequential_445\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1420 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1421 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_530 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1422 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_531 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1423 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 2ms/step - loss: 35026.0938 - mse: 35026.0938 - mae: 132.5993 - val_loss: 17213.1074 - val_mse: 17213.1074 - val_mae: 89.7078\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 21385.4746 - mse: 21385.4746 - mae: 98.9194 - val_loss: 13837.3350 - val_mse: 13837.3350 - val_mae: 78.9948\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19535.8906 - mse: 19535.8906 - mae: 93.3156 - val_loss: 14033.9922 - val_mse: 14033.9922 - val_mae: 75.9822\n","Epoch 4/10\n","533/533 [==============================] - 2s 4ms/step - loss: 18986.0156 - mse: 18986.0156 - mae: 92.8561 - val_loss: 13016.4697 - val_mse: 13016.4697 - val_mae: 76.1397\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18519.6465 - mse: 18519.6465 - mae: 91.3699 - val_loss: 15614.5723 - val_mse: 15614.5723 - val_mae: 76.0208\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18220.4883 - mse: 18220.4883 - mae: 89.7198 - val_loss: 12147.9463 - val_mse: 12147.9463 - val_mae: 75.9589\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17578.7129 - mse: 17578.7129 - mae: 87.6847 - val_loss: 11954.3496 - val_mse: 11954.3496 - val_mae: 69.5271\n","Epoch 8/10\n","533/533 [==============================] - 2s 4ms/step - loss: 17119.2656 - mse: 17119.2656 - mae: 86.4522 - val_loss: 11992.9219 - val_mse: 11992.9219 - val_mae: 69.1366\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16868.0371 - mse: 16868.0371 - mae: 84.8098 - val_loss: 11769.5234 - val_mse: 11769.5234 - val_mae: 68.0349\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16380.7793 - mse: 16380.7793 - mae: 83.8620 - val_loss: 10575.4336 - val_mse: 10575.4336 - val_mae: 68.8839\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 16380.7793 mean_squared_error: 16380.7793 mean_absolute_error: 83.8620 val_loss: 10575.4336 val_mean_squared_error: 10575.4336 val_mean_absolute_error: 68.8839\n","Model: \"sequential_446\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1424 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1425 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_532 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1426 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_533 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1427 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 4ms/step - loss: 64331.1445 - mse: 64331.1445 - mae: 178.6549 - val_loss: 62121.0742 - val_mse: 62121.0742 - val_mae: 173.3842\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 58900.7812 - mse: 58900.7812 - mae: 168.3280 - val_loss: 57280.7656 - val_mse: 57280.7656 - val_mae: 164.8841\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 54398.8945 - mse: 54398.8945 - mae: 160.8618 - val_loss: 53124.8398 - val_mse: 53124.8398 - val_mae: 158.2480\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 50828.3789 - mse: 50828.3789 - mae: 155.4449 - val_loss: 49607.2891 - val_mse: 49607.2891 - val_mae: 153.0129\n","Epoch 5/10\n","533/533 [==============================] - 2s 4ms/step - loss: 47599.5781 - mse: 47599.5781 - mae: 150.7714 - val_loss: 46565.7656 - val_mse: 46565.7656 - val_mae: 148.8181\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 44762.5000 - mse: 44762.5000 - mae: 147.2361 - val_loss: 43954.6445 - val_mse: 43954.6445 - val_mae: 145.4999\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 42607.6680 - mse: 42607.6680 - mae: 144.7332 - val_loss: 41776.3711 - val_mse: 41776.3711 - val_mae: 143.0616\n","Epoch 8/10\n","533/533 [==============================] - 1s 3ms/step - loss: 40738.6445 - mse: 40738.6445 - mae: 143.0005 - val_loss: 39974.8945 - val_mse: 39974.8945 - val_mae: 141.2949\n","Epoch 9/10\n","533/533 [==============================] - 2s 4ms/step - loss: 39279.6562 - mse: 39279.6562 - mae: 141.7501 - val_loss: 38496.6484 - val_mse: 38496.6484 - val_mae: 140.1223\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 37740.6602 - mse: 37740.6602 - mae: 140.1628 - val_loss: 37060.0820 - val_mse: 37060.0820 - val_mae: 138.1501\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 37740.6602 mean_squared_error: 37740.6602 mean_absolute_error: 140.1628 val_loss: 37060.0820 val_mean_squared_error: 37060.0820 val_mean_absolute_error: 138.1501\n","Model: \"sequential_447\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1428 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1429 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_534 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1430 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_535 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1431 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 3s 3ms/step - loss: 33986.4688 - mse: 33986.4688 - mae: 131.2378 - val_loss: 17525.7539 - val_mse: 17525.7539 - val_mae: 92.1976\n","Epoch 2/10\n","533/533 [==============================] - 2s 3ms/step - loss: 21255.9062 - mse: 21255.9062 - mae: 99.4164 - val_loss: 15045.4922 - val_mse: 15045.4922 - val_mae: 77.8711\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19709.2500 - mse: 19709.2500 - mae: 94.6772 - val_loss: 13668.5410 - val_mse: 13668.5410 - val_mae: 75.6761\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18954.0938 - mse: 18954.0938 - mae: 91.0248 - val_loss: 12428.5371 - val_mse: 12428.5371 - val_mae: 74.5111\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18139.4824 - mse: 18139.4824 - mae: 88.4671 - val_loss: 12398.2588 - val_mse: 12398.2588 - val_mae: 69.6020\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17212.1719 - mse: 17212.1719 - mae: 86.2153 - val_loss: 12168.6816 - val_mse: 12168.6816 - val_mae: 68.0679\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17168.4023 - mse: 17168.4023 - mae: 85.0306 - val_loss: 11728.2754 - val_mse: 11728.2754 - val_mae: 65.9473\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16490.4688 - mse: 16490.4688 - mae: 83.8525 - val_loss: 12023.6748 - val_mse: 12023.6748 - val_mae: 67.7638\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15892.1377 - mse: 15892.1377 - mae: 82.4767 - val_loss: 10983.8750 - val_mse: 10983.8750 - val_mae: 66.6825\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 15782.3779 - mse: 15782.3779 - mae: 82.3064 - val_loss: 10398.4463 - val_mse: 10398.4463 - val_mae: 65.8777\n","163/163 [==============================] - 0s 1ms/step\n","Epoch 10/10\n","16/16 loss: 15782.3779 mean_squared_error: 15782.3779 mean_absolute_error: 82.3064 val_loss: 10398.4463 val_mean_squared_error: 10398.4463 val_mean_absolute_error: 65.8777\n","Model: \"sequential_448\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1432 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1433 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_536 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1434 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_537 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1435 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 34985.5742 - mse: 34985.5742 - mae: 132.9663 - val_loss: 17142.4805 - val_mse: 17142.4805 - val_mae: 88.5873\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 20984.3613 - mse: 20984.3613 - mae: 97.8255 - val_loss: 13873.1904 - val_mse: 13873.1904 - val_mae: 77.9230\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19509.6250 - mse: 19509.6250 - mae: 94.2959 - val_loss: 13872.0127 - val_mse: 13872.0127 - val_mae: 76.1093\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 19169.4551 - mse: 19169.4551 - mae: 92.6552 - val_loss: 13077.3848 - val_mse: 13077.3848 - val_mae: 76.6004\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18828.6426 - mse: 18828.6426 - mae: 91.2318 - val_loss: 12449.1152 - val_mse: 12449.1152 - val_mae: 74.4646\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18412.4688 - mse: 18412.4688 - mae: 90.3949 - val_loss: 13629.9189 - val_mse: 13629.9189 - val_mae: 72.1896\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18252.2695 - mse: 18252.2695 - mae: 89.0724 - val_loss: 12990.3408 - val_mse: 12990.3408 - val_mae: 70.5193\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17977.1133 - mse: 17977.1133 - mae: 87.9971 - val_loss: 11989.4473 - val_mse: 11989.4473 - val_mae: 69.4103\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17487.1094 - mse: 17487.1094 - mae: 86.9381 - val_loss: 11374.5078 - val_mse: 11374.5078 - val_mae: 67.3984\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 16801.6504 - mse: 16801.6504 - mae: 84.6037 - val_loss: 11071.8486 - val_mse: 11071.8486 - val_mae: 67.1289\n","163/163 [==============================] - 0s 918us/step\n","Epoch 10/10\n","16/16 loss: 16801.6504 mean_squared_error: 16801.6504 mean_absolute_error: 84.6037 val_loss: 11071.8486 val_mean_squared_error: 11071.8486 val_mean_absolute_error: 67.1289\n","Model: \"sequential_449\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1436 (Dense)          (None, 128)               1536      \n","                                                                 \n"," dense_1437 (Dense)          (None, 64)                8256      \n","                                                                 \n"," dropout_538 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_1438 (Dense)          (None, 32)                2080      \n","                                                                 \n"," dropout_539 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_1439 (Dense)          (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 11,905\n","Trainable params: 11,905\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","533/533 [==============================] - 2s 2ms/step - loss: 28580.0898 - mse: 28580.0898 - mae: 121.0181 - val_loss: 16172.1064 - val_mse: 16172.1064 - val_mae: 86.8128\n","Epoch 2/10\n","533/533 [==============================] - 1s 2ms/step - loss: 18666.1797 - mse: 18666.1797 - mae: 94.3289 - val_loss: 13884.5088 - val_mse: 13884.5088 - val_mae: 78.7485\n","Epoch 3/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17678.5137 - mse: 17678.5137 - mae: 91.3598 - val_loss: 13098.3818 - val_mse: 13098.3818 - val_mae: 82.1476\n","Epoch 4/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17343.2305 - mse: 17343.2305 - mae: 90.2181 - val_loss: 14290.8574 - val_mse: 14290.8574 - val_mae: 76.3052\n","Epoch 5/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17246.2402 - mse: 17246.2402 - mae: 89.7439 - val_loss: 14356.9941 - val_mse: 14356.9941 - val_mae: 76.5124\n","Epoch 6/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17400.5977 - mse: 17400.5977 - mae: 90.0735 - val_loss: 13714.3408 - val_mse: 13714.3408 - val_mae: 77.8255\n","Epoch 7/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17489.5840 - mse: 17489.5840 - mae: 90.7559 - val_loss: 13709.6689 - val_mse: 13709.6689 - val_mae: 76.3970\n","Epoch 8/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17129.9922 - mse: 17129.9922 - mae: 89.1673 - val_loss: 13062.4600 - val_mse: 13062.4600 - val_mae: 81.5106\n","Epoch 9/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17010.4453 - mse: 17010.4453 - mae: 89.2714 - val_loss: 12990.4229 - val_mse: 12990.4229 - val_mae: 79.6123\n","Epoch 10/10\n","533/533 [==============================] - 1s 2ms/step - loss: 17201.6387 - mse: 17201.6387 - mae: 89.2113 - val_loss: 12978.9844 - val_mse: 12978.9844 - val_mae: 81.6602\n","163/163 [==============================] - 0s 973us/step\n","Epoch 10/10\n","16/16 loss: 17201.6387 mean_squared_error: 17201.6387 mean_absolute_error: 89.2113 val_loss: 12978.9844 val_mean_squared_error: 12978.9844 val_mean_absolute_error: 81.6602\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 6412.595127330708\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8278.273307996584\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8601.08398836758\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8612.587501567155\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 8632.485264501045\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8685.6250022771\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8725.687037768017\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8733.076581419951\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8737.048112163955\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8813.43621261073\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8881.624022892345\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 8947.641467258678\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8981.393027562412\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 8984.933440567404\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 9031.02899126\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 9041.678836755287\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 9109.162104658182\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9126.781786311065\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 9132.13637185357\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9145.062135297318\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 9149.862107350857\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9180.70526751863\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 9209.300924775995\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9218.57221625114\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9223.06417949025\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 9266.090204057133\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 9333.041853056797\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 9391.474548074515\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9500.93080732121\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9508.336424874366\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9541.455892494321\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9573.432057663302\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9606.55982444112\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9614.983781883298\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9671.705279689939\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9796.158383456946\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 9815.828786277694\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9820.247249213999\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 9851.599988111258\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 9894.110055378833\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 9900.169193174917\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9923.368127658074\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 9927.652255205436\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 9937.390838680098\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 9952.366349185195\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 9956.082530464953\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10017.411608541048\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10025.175933520492\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 10084.34698164687\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10127.976014752843\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 10130.495441231147\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10149.768806549873\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 10170.584822476694\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10182.030304539256\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10183.4221744766\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10201.736739096019\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10202.776065353106\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 10217.331982120482\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 10229.930104807972\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 10252.992093185663\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 10268.94931213156\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 10298.312243874781\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 10378.197610650925\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 10380.436015379926\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10568.38738336857\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10569.949976605089\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10586.758673146933\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 10681.604416274058\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10682.34002523427\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 10714.95553798208\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10751.314592703711\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 10766.109695702511\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 10789.800004082075\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 10804.87149224676\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10811.786209259431\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 10886.606907314135\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 10907.239011060763\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 10914.918957585463\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 10937.590970019997\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 10950.552403450054\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 10953.885736323422\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11013.2490989792\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 11113.436432390652\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11183.2328413727\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 11205.120101948216\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11205.437844447613\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11295.897964817419\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11299.742348542266\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11341.196014122805\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11367.618788906993\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11406.481211479313\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11426.532706620666\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11435.823547340995\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11439.719268983887\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 11530.149548327436\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11577.933986482862\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11621.592704573155\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11645.874325544592\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11788.911194290653\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 11793.091834367757\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11842.145484359224\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11932.763989957097\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 11953.568472021658\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11960.215473068312\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 11998.774269387053\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 12100.470753733662\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 12127.850346236426\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 12171.444472122254\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 12238.631657205418\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 12257.130249566495\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 12264.861753860901\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 12266.190195211899\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 12268.251037420849\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 12306.976690945894\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 12384.894064097014\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 12402.77001897656\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 12418.779548795563\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 12430.746345408616\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 12469.496422320728\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 12494.044167782338\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 12497.39233753683\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 12503.468548862873\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12516.644044038432\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 12525.020637857357\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 12527.785359456953\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 12530.428802323628\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 12537.846103191256\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 12542.020539437714\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 12546.30959290487\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12549.933994806623\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12560.083473538454\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12561.383528532248\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12562.268795591817\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12568.116952170654\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12571.832868047408\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12573.037408686781\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 12573.142589899899\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12577.45683824156\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 12578.613325456787\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12582.421102231587\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 12584.939487895384\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 12595.138924908888\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12599.820938121631\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12613.516206738946\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 12622.212886182844\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 12622.242363172372\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12625.02050043047\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12625.043066980887\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 12626.165050051166\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 12634.188833956192\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 12638.30382053499\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12649.030092407229\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12651.274346278218\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12657.705792252322\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 12665.450403692888\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12667.955527269945\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12696.535065297254\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12700.94687963216\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 12715.14987310393\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 12748.555627507609\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 12769.1398431526\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 12770.723554930144\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12771.775980833794\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 12772.245203304297\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 12801.148232987713\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12807.081699678121\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12815.959289092947\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12817.180597872577\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12820.414731939652\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12832.65684393767\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 12847.190500856042\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 12895.03806934214\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 12900.696510916481\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 12921.452853491697\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12932.604139968582\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12942.016636497063\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12943.90606475627\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 12947.1998454836\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 12950.519295306834\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 12959.600304654554\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12970.803001450604\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 12974.01386606737\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 12976.440554646582\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 12981.846039889628\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 12986.179820880418\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 13007.6849164556\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13015.184626335948\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 13015.435771004268\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13031.087232542995\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 13035.864709857184\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13039.158525308561\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 13049.513148014767\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 13057.957299781254\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 13089.188222140378\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 13104.749944814266\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13105.686402836212\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 13106.14028298301\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13106.616947247701\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13107.212079994944\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13107.582638776066\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13111.855868855426\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 13116.82524610789\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 13120.960241881507\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13122.845137848706\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13125.4020770292\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13164.515183389947\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 13169.24798537389\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 13178.24149301903\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 13279.424276652073\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 13291.013788275637\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: linear\n","MSE: 13332.941198205703\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 13340.72493763963\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 13350.349320440668\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 13359.670697266434\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 13424.168993058123\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13438.970817663487\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 13450.97275798297\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 13486.52977845853\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 13527.917727507946\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13561.650204453454\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 13584.900947588045\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13588.896835584303\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13593.49688472847\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 13624.23778848373\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 13627.390197094051\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 13629.024085487992\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13646.513167059897\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13676.748888277874\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 13676.900901160338\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 13684.51124734699\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13687.502347365318\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 13689.261508068746\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 13768.340448467638\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 13773.72720200012\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13789.176088683173\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13803.11501745145\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 13815.385774294282\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 13927.256544323402\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13941.587668838232\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 13953.184842040599\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 14017.723798427834\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 14072.936797950726\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 14089.343302650343\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 14166.840731167935\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 14226.96906881349\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 14269.33415053344\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: relu\n","MSE: 14284.937421412647\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 14303.781618132196\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: selu\n","MSE: 14310.930432618068\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 14395.194988768095\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 14409.224618002521\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 14427.514740936684\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 14433.022090815508\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 14471.400006230188\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 14481.37141169602\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 14549.812757317126\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 14591.249410473705\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 14595.882999060661\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 14603.315804452373\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 14638.91784076163\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 14698.34260092407\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 14711.785732162867\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 14718.56264700127\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 14727.62353072984\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 14894.407008892093\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 14917.011794592378\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 15054.169574376128\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 15096.19187433686\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 15101.24246573776\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 15135.00731190779\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 15179.726316207834\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 15252.138637175894\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 15299.37979400366\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 15379.11920319301\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 15406.30604229696\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 15490.394532238897\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 15529.916350533425\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 15558.102776426405\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 15561.681120787794\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 15608.92906527039\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 15657.94770294585\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: linear\n","MSE: 15775.864338453166\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 15830.58240460636\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 15840.893967027458\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 15894.370231640858\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 15946.110958533265\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: relu\n","MSE: 15972.572636975781\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 15983.113314818373\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 16009.26614837448\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 16053.208800176824\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 16088.260434313346\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 16217.916510251207\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: selu\n","MSE: 16430.01334350506\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 16535.80029503361\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 16598.826152538575\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 16657.654765381478\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 16675.895508086494\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 16750.879545748117\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 16798.583740041173\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 16916.21981194171\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 17188.462377665248\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 17285.138553212753\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 17341.73404349897\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 17376.403274140488\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 17479.121637926914\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 17563.106404942042\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 17663.50881175395\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 17681.06676868125\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 17778.265135951176\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 17802.24679093008\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 17832.334463765572\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: linear\n","MSE: 17973.447198607504\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 18031.647124176747\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 18108.798893655003\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 18246.406146436268\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: selu\n","MSE: 18425.437054875234\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 18587.963958553035\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 18671.70298551041\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 18680.43149578533\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 18806.868640946886\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 18809.631876917243\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 18830.339742382894\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 18837.772965558368\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 18856.469018668016\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 18913.32919110691\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 18926.986615225946\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 19015.135861872597\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 19060.448448149662\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 19233.18341100022\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 19277.58020104299\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 19311.20565955734\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 19362.812819735133\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 19643.35907062481\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: relu\n","MSE: 19728.15948084914\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 19744.571488467245\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 19857.08533535422\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 19974.433331613254\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 20010.462426929633\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 20240.201059124374\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 20251.20302546763\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 21244.17685200855\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 21545.43078806394\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 21556.646319210267\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 21678.21781598293\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 21733.85073576144\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 21865.675037652865\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 21963.39859021905\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: linear\n","MSE: 22028.424241748577\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 22065.884918728854\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 22286.03687859211\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 22524.308233011747\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 22707.71993309049\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 22885.557183127283\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 23169.241696703975\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 23471.10950938644\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 23513.740800320436\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 23658.53275899323\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: selu\n","MSE: 23666.188080984884\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 23828.057079913404\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 23839.787063508236\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: relu\n","MSE: 24038.4388465903\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 24062.364543825075\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 25949.727678403447\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 25989.01305894084\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 26060.465486653055\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 26229.42729744809\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 26293.318938714143\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 26403.10213157856\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 26564.0015182441\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 26625.635402234348\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 26694.27229363809\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 26786.0154982071\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 27023.641917129014\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 27047.60576519442\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 27112.103651651316\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 27130.07017553237\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 27153.16535271673\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 27205.337666767897\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 27633.542082749955\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 27996.90749813433\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 28287.33857037658\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 28291.774903803424\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 28567.824546692766\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 28625.130836420478\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 28759.8270087366\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 28854.9571465648\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 28936.127520069098\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: linear\n","MSE: 28988.63932425122\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 29020.871906111694\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 29152.618388768456\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 29446.51047413781\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 29593.103700958134\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 29913.411641610895\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 30001.57738646927\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 30114.095318022544\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 30719.458579595543\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 31276.602816301445\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 31743.120824845748\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 32520.292843742256\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: selu\n","MSE: 32563.111597011888\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 32702.482887881884\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 10\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 34141.18915609452\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 34238.6599050861\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 34270.51152290933\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: relu\n","MSE: 36209.33066419975\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 43208.46297987275\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 43231.847800226096\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 43581.04700654701\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 45140.11253074207\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 45269.93955385108\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 45402.591193555\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 45458.964587613045\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 46400.028544121364\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 46653.53174281515\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 47547.064367817184\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 47902.99470953436\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 47995.47157474287\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 49409.12853897761\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 49487.88221185369\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 49624.44053002039\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 49652.259484747876\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 50110.49180624653\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 50235.55699994034\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 50566.21852000854\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 50968.43269169341\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64]\n","Activation: tanh\n","MSE: 51167.75808918728\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 51940.85075784592\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 52007.751310881446\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 52162.96412685917\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 52230.46823832229\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64]\n","Activation: tanh\n","MSE: 52340.22409892795\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 52702.104042734434\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 53041.220391412\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 53228.03947693896\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 53289.90319448389\n","Dropout Rate: 0.4\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 53416.735760124684\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 53768.38050948375\n","Dropout Rate: 0.6\n","Batch Size: 8\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 54235.66781679048\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 55721.82834345801\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 55870.354475809094\n","Dropout Rate: 0.2\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 56342.57474545281\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 56350.33976350027\n","Dropout Rate: 0.6\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 56374.0566238834\n","Dropout Rate: 0.4\n","Batch Size: 12\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 56427.94153276288\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 57139.14146452534\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 57345.6565390395\n","Dropout Rate: 0.2\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 57546.41012060148\n","Dropout Rate: 0.4\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 57831.57374712459\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [64, 32]\n","Activation: tanh\n","MSE: 57952.909839067026\n","Dropout Rate: 0.6\n","Batch Size: 16\n","Number of Epochs: 1\n","Dense Layers: [128, 64, 32]\n","Activation: tanh\n","MSE: 58085.65332271628\n","Best Model Parameters:\n","Dropout Rate: 0.2\n","Batch Size: 8\n","Number of Epochs: 10\n","Dense Layers: [256, 128, 64]\n","Activation: tanh\n","MSE: 6412.595127330708\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Elapsed time: 75 minutes 52 seconds\n"]}],"source":["start_time = time.time()\n","\n","input_dim = 11\n","dropout_rate = [0.2, 0.4, 0.6]\n","batch_sizes = [8, 12, 16]\n","num_epochs = [1, 10]\n","dense_layers =  [[64], [128, 64], [256, 128, 64], [64, 32], [128, 64, 32]]\n","activations = ['relu','tanh','selu','relu','linear']\n","\n","def build_model(input_dim, dense_layers, activation, dropout):\n","    model = Sequential()\n","    model.add(Dense(dense_layers[0], activation=activation, input_dim=input_dim))\n","    for units in dense_layers[1:]:\n","        model.add(Dense(units, activation=activation))\n","        model.add(Dropout(dropout))\n","    model.add(Dense(1))\n","    return model\n","\n","def train_model(model, X_train_scal, y_train, X_valid_scal, y_valid, batch_size, num_epochs, early_stop):\n","    callbacks = []\n","    if early_stop:\n","        early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n","        callbacks.append(early_stop)\n","    model.compile(optimizer='adam', loss='mse', metrics=['mse','mae'])\n","    history = model.fit(X_train_scal, y_train, epochs=num_epochs, batch_size=batch_size,\n","                        validation_data=(X_valid_scal, y_valid), callbacks=callbacks, verbose=1)\n","    return history\n","\n","def evaluate_model(model, X_test_scal, y_test):\n","    y_pred = model.predict(X_test_scal)\n","    score = mean_squared_error(y_test, y_pred)\n","    return score\n","\n","def visualize_history(history):\n","    plt.plot(history.history['loss'], label='Train Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","best_model = None\n","best_score = float('inf')\n","\n","report = []\n","\n","for dropout in dropout_rate:\n","    for batch_size in batch_sizes:\n","        for num_epoch in num_epochs:\n","            for dense_layer in dense_layers:\n","                for activation in activations:\n","# for dropout, batch_size, num_epoch, dense_layer, activation in itertools.product(dropout_rate, batch_sizes, num_epochs, dense_layers, activations):                    \n","                    model = build_model(input_dim, dense_layer, activation, dropout)\n","                    model.summary()  \n","                    history = train_model(model, X_train_scal, y_train, X_valid_scal, y_valid, batch_size, num_epoch, early_stop=True)\n","\n","                    score = evaluate_model(model, X_test_scal, y_test)\n","\n","                    if score < best_score:\n","                        best_score = score\n","                        best_model = model\n","                    \n","                    print(f\"Epoch {num_epoch}/{num_epoch}\")\n","                    print(f\"{batch_size}/{batch_size} loss: {history.history['loss'][-1]:.4f} mean_squared_error: {history.history['mse'][-1]:.4f} mean_absolute_error: {history.history['mae'][-1]:.4f} val_loss: {history.history['val_loss'][-1]:.4f} val_mean_squared_error: {history.history['val_mse'][-1]:.4f} val_mean_absolute_error: {history.history['val_mae'][-1]:.4f}\")\n","\n","                    report.append({'Dropout Rate': dropout,\n","                                   'Batch Size': batch_size,\n","                                   'Number of Epochs': num_epoch,\n","                                   'Dense Layers': dense_layer,\n","                                   'Activation': activation,\n","                                   'MSE': score})\n","\n","report = sorted(report, key=lambda x: x['MSE'])\n","\n","for entry in report:\n","    print(f\"Dropout Rate: {entry['Dropout Rate']}\")\n","    print(f\"Batch Size: {entry['Batch Size']}\")\n","    print(f\"Number of Epochs: {entry['Number of Epochs']}\")\n","    print(f\"Dense Layers: {entry['Dense Layers']}\")\n","    print(f\"Activation: {entry['Activation']}\")\n","    print(f\"MSE: {entry['MSE']}\")\n","\n","best_params = report[0]\n","print(\"Best Model Parameters:\")\n","print(f\"Dropout Rate: {best_params['Dropout Rate']}\")\n","print(f\"Batch Size: {best_params['Batch Size']}\")\n","print(f\"Number of Epochs: {best_params['Number of Epochs']}\")\n","print(f\"Dense Layers: {best_params['Dense Layers']}\")\n","print(f\"Activation: {best_params['Activation']}\")\n","print(f\"MSE: {best_params['MSE']}\")\n","\n","visualize_history(history)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","\n","minutes = int(elapsed_time // 60)\n","seconds = int(elapsed_time % 60)\n","\n","print(f\"Elapsed time: {minutes} minutes {seconds} seconds\")"]},{"cell_type":"markdown","id":"05d4fb64","metadata":{"id":"05d4fb64"},"source":["#### SE PREGORE GRAFICKATA :)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}